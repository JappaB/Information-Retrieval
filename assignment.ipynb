{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Information Retrieval 1#\n",
    "## Assignment 2: Retrieval models [100 points] ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment you will get familiar with basic and advanced information retrieval concepts. You will implement different information retrieval ranking models and evaluate their performance.\n",
    "\n",
    "We provide you with a Indri index. To query the index, you'll use a Python package ([pyndri](https://github.com/cvangysel/pyndri)) that allows easy access to the underlying document statistics.\n",
    "\n",
    "For evaluation you'll use the [TREC Eval](https://github.com/usnistgov/trec_eval) utility, provided by the National Institute of Standards and Technology of the United States. TREC Eval is the de facto standard way to compute Information Retrieval measures and is frequently referenced in scientific papers.\n",
    "\n",
    "This is a **groups-of-three assignment**, the deadline is **Wednesday, January 31st**. Code quality, informative comments and convincing analysis of the results will be considered when grading. Submission should be done through blackboard, questions can be asked on the course [Piazza](piazza.com/university_of_amsterdam/spring2018/52041inr6y/home).\n",
    "\n",
    "### Technicalities (must-read!) ###\n",
    "\n",
    "The assignment directory is organized as follows:\n",
    "   * `./assignment.ipynb` (this file): the description of the assignment.\n",
    "   * `./index/`: the index we prepared for you.\n",
    "   * `./ap_88_90/`: directory with ground-truth and evaluation sets:\n",
    "      * `qrel_test`: test query relevance collection (**test set**).\n",
    "      * `qrel_validation`: validation query relevance collection (**validation set**).\n",
    "      * `topics_title`: semicolon-separated file with query identifiers and terms.\n",
    "\n",
    "You will need the following software packages (tested with Python 3.5 inside [Anaconda](https://conda.io/docs/user-guide/install/index.html)):\n",
    "   * Python 3.5 and Jupyter\n",
    "   * Indri + Pyndri (Follow the installation instructions [here](https://github.com/nickvosk/pyndri/blob/master/README.md))\n",
    "   * gensim [link](https://radimrehurek.com/gensim/install.html)\n",
    "   * TREC Eval [link](https://github.com/usnistgov/trec_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TREC Eval primer ###\n",
    "The TREC Eval utility can be downloaded and compiled as follows:\n",
    "\n",
    "    git clone https://github.com/usnistgov/trec_eval.git\n",
    "    cd trec_eval\n",
    "    make\n",
    "\n",
    "TREC Eval computes evaluation scores given two files: ground-truth information regarding relevant documents, named *query relevance* or *qrel*, and a ranking of documents for a set of queries, referred to as a *run*. The *qrel* will be supplied by us and should not be changed. For every retrieval model (or combinations thereof) you will generate a run of the top-1000 documents for every query. The format of the *run* file is as follows:\n",
    "\n",
    "    $query_identifier Q0 $document_identifier $rank_of_document_for_query $query_document_similarity $run_identifier\n",
    "    \n",
    "where\n",
    "   * `$query_identifier` is the unique identifier corresponding to a query (usually this follows a sequential numbering).\n",
    "   * `Q0` is a legacy field that you can ignore.\n",
    "   * `$document_identifier` corresponds to the unique identifier of a document (e.g., APXXXXXXX where AP denotes the collection and the Xs correspond to a unique numerical identifier).\n",
    "   * `$rank_of_document_for_query` denotes the rank of the document for the particular query. This field is ignored by TREC Eval and is only maintained for legacy support. The ranks are computed by TREC Eval itself using the `$query_document_similarity` field (see next). However, it remains good practice to correctly compute this field.\n",
    "   * `$query_document_similarity` is a score indicating the similarity between query and document where a higher score denotes greater similarity.\n",
    "   * `$run_identifier` is an identifier of the run. This field is for your own convenience and has no purpose beyond bookkeeping.\n",
    "   \n",
    "For example, say we have two queries: `Q1` and `Q2` and we rank three documents (`DOC1`, `DOC2`, `DOC3`). For query `Q1`, we find the following similarity scores `score(Q1, DOC1) = 1.0`, `score(Q1, DOC2) = 0.5`, `score(Q1, DOC3) = 0.75`; and for `Q2`: `score(Q2, DOC1) = -0.1`, `score(Q2, DOC2) = 1.25`, `score(Q1, DOC3) = 0.0`. We can generate run using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 Q0 DOC1 1 1.0 example\n",
      "Q1 Q0 DOC3 2 0.75 example\n",
      "Q1 Q0 DOC2 3 0.5 example\n",
      "Q2 Q0 DOC2 1 1.25 example\n",
      "Q2 Q0 DOC3 2 0.0 example\n",
      "Q2 Q0 DOC1 3 -0.1 example\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import os\n",
    "\n",
    "def write_run(model_name, data, out_f,\n",
    "              max_objects_per_query=sys.maxsize,\n",
    "              skip_sorting=False):\n",
    "    \"\"\"\n",
    "    Write a run to an output file.\n",
    "    Parameters:\n",
    "        - model_name: identifier of run.\n",
    "        - data: dictionary mapping topic_id to object_assesments;\n",
    "            object_assesments is an iterable (list or tuple) of\n",
    "            (relevance, object_id) pairs.\n",
    "            The object_assesments iterable is sorted by decreasing order.\n",
    "        - out_f: output file stream.\n",
    "        - max_objects_per_query: cut-off for number of objects per query.\n",
    "    \"\"\"\n",
    "\n",
    "    for subject_id, object_assesments in data.items():\n",
    "        if not object_assesments:\n",
    "            logging.warning('Received empty ranking for %s; ignoring.',\n",
    "                            subject_id)\n",
    "\n",
    "            continue\n",
    "\n",
    "        # Probe types, to make sure everything goes alright.\n",
    "        # assert isinstance(object_assesments[0][0], float) or \\\n",
    "        #     isinstance(object_assesments[0][0], np.float32)\n",
    "        assert isinstance(object_assesments[0][1], str) or \\\n",
    "            isinstance(object_assesments[0][1], bytes)\n",
    "\n",
    "        if not skip_sorting:\n",
    "            object_assesments = sorted(object_assesments, reverse=True)\n",
    "\n",
    "        if max_objects_per_query < sys.maxsize:\n",
    "            object_assesments = object_assesments[:max_objects_per_query]\n",
    "\n",
    "        if isinstance(subject_id, bytes):\n",
    "            subject_id = subject_id.decode('utf8')\n",
    "\n",
    "        for rank, (relevance, object_id) in enumerate(object_assesments):\n",
    "            if isinstance(object_id, bytes):\n",
    "                object_id = object_id.decode('utf8')\n",
    "\n",
    "            out_f.write(\n",
    "                '{subject} Q0 {object} {rank} {relevance} '\n",
    "                '{model_name}\\n'.format(\n",
    "                    subject=subject_id,\n",
    "                    object=object_id,\n",
    "                    rank=rank + 1,\n",
    "                    relevance=relevance,\n",
    "                    model_name=model_name))\n",
    "            \n",
    "# The following writes the run to standard output.\n",
    "# In your code, you should write the runs to local\n",
    "# storage in order to pass them to trec_eval.\n",
    "write_run(\n",
    "    model_name='example',\n",
    "    data={\n",
    "        'Q1': ((1.0, 'DOC1'), (0.5, 'DOC2'), (0.75, 'DOC3')),\n",
    "        'Q2': ((-0.1, 'DOC1'), (1.25, 'DOC2'), (0.0, 'DOC3')),\n",
    "    },\n",
    "    out_f=sys.stdout,\n",
    "    max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".DS_Store\n",
      "already_run\n",
      "run old\n",
      "TREC_results_on_test_set\n",
      "TREC_results_on_validation_set\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import subprocess\n",
    "from collections import defaultdict \n",
    "\n",
    "# Run evaluation bash script...\n",
    "# subprocess.call([\"./assignment_evals.sh\"])\n",
    "\n",
    "\n",
    "# ... And retrieve again\n",
    "eval_data = defaultdict(list)\n",
    "\n",
    "for file in os.listdir(\"run\"):\n",
    "    print(file)\n",
    "    if file == \"TF-IDF.txt\":\n",
    "        with open(\"run/\" + file) as file:\n",
    "            content = [line.strip().split() for line in file.readlines()]\n",
    "#             print(content)\n",
    "            for metric, query, score in content:\n",
    "                eval_data[metric].append((query,score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(list, {})"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, imagine that we know that `DOC1` is relevant and `DOC3` is non-relevant for `Q1`. In addition, for `Q2` we only know of the relevance of `DOC3`. The query relevance file looks like:\n",
    "\n",
    "    Q1 0 DOC1 1\n",
    "    Q1 0 DOC3 0\n",
    "    Q2 0 DOC3 1\n",
    "    \n",
    "We store the run and qrel in files `example.run` and `example.qrel` respectively on disk. We can now use TREC Eval to compute evaluation measures. In this example, we're only interested in Mean Average Precision and we'll only show this below for brevity. However, TREC Eval outputs much more information such as NDCG, recall, precision, etc.\n",
    "    $ ./trec_eval/trec_eval -q ap_88_89/qrel_test ap_88_89/TF-IDF.run | grep -E \"^map\\s\"\n",
    "    $ trec_eval -m all_trec -q example.qrel example.run | grep -E \"^map\\s\"\n",
    "    > map                   \tQ1\t1.0000\n",
    "    > map                   \tQ2\t0.5000\n",
    "    > map                   \tall\t0.7500\n",
    "    \n",
    "Now that we've discussed the output format of rankings and how you can compute evaluation measures from these rankings, we'll now proceed with an overview of the indexing framework you'll use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pyndri primer ###\n",
    "For this assignment you will use [Pyndri](https://github.com/cvangysel/pyndri) [[1](https://arxiv.org/abs/1701.00749)], a python interface for [Indri](https://www.lemurproject.org/indri.php). We have indexed the document collection and you can query the index using Pyndri. We will start by giving you some examples of what Pyndri can do:\n",
    "\n",
    "First we read the document collection index with Pyndri:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pyndri\n",
    "\n",
    "index = pyndri.Index('index/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The loaded index can be used to access a collection of documents in an easy manner. We'll give you some examples to get some idea of what it can do, it is up to you to figure out how to use it for the remainder of the assignment.\n",
    "\n",
    "First let's look at the number of documents, since Pyndri indexes the documents using incremental identifiers we can simply take the lowest index and the maximum document and consider the difference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164598\n",
      "1\n",
      "There are 164597 documents in this collection.\n"
     ]
    }
   ],
   "source": [
    "print(index.maximum_document())\n",
    "print(index.document_base())\n",
    "\n",
    "print(\"There are %d documents in this collection.\" % (index.maximum_document() - index.document_base()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take the first document out of the collection and take a look at it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('AP890425-0001', (1360, 192, 363, 0, 880, 0, 200, 0, 894, 412, 92160, 3, 192, 0, 363, 34, 1441, 0, 174134, 0, 200, 0, 894, 412, 2652, 0, 810, 107, 49, 4903, 420, 0, 1, 48, 35, 489, 0, 35, 687, 192, 243, 0, 249311, 1877, 0, 1651, 1174, 0, 2701, 117, 412, 0, 810, 391, 245233, 1225, 5838, 16, 0, 233156, 3496, 0, 393, 17, 0, 2435, 4819, 930, 0, 0, 200, 0, 894, 0, 22, 398, 145, 0, 3, 271, 115, 0, 1176, 2777, 292, 0, 725, 192, 0, 0, 50046, 0, 1901, 1130, 0, 192, 0, 408, 0, 243779, 0, 0, 553, 192, 0, 363, 0, 3747, 0, 0, 0, 0, 1176, 0, 1239, 0, 0, 1115, 17, 0, 0, 585, 192, 1963, 0, 0, 412, 54356, 0, 773, 0, 0, 0, 192, 0, 0, 1130, 0, 363, 0, 545, 192, 0, 1174, 1901, 1130, 0, 4, 398, 145, 39, 0, 577, 0, 355, 0, 491, 0, 6025, 0, 0, 193156, 88, 34, 437, 0, 0, 1852, 0, 828, 0, 1588, 0, 0, 0, 2615, 0, 0, 107, 49, 420, 0, 0, 190, 7, 714, 2701, 0, 237, 192, 157, 0, 412, 34, 437, 0, 0, 200, 6025, 26, 0, 0, 0, 0, 363, 0, 22, 398, 145, 0, 200, 638, 126222, 6018, 0, 880, 0, 0, 161, 0, 0, 319, 894, 2701, 0, 0, 0, 301, 1200, 0, 363, 251, 430, 0, 207, 0, 76143, 1773, 0, 243779, 0, 0, 72030, 0, 55, 4903, 420, 0, 2701, 1496, 420, 0, 25480, 0, 420, 0, 0, 200, 0, 392, 2949, 0, 1738, 0, 61, 0, 71, 79, 0, 200, 903, 0, 188, 53, 6, 0, 476, 2, 0, 2028, 97, 334, 0, 0, 200, 178, 0, 0, 107, 49, 0, 214, 0, 0, 0, 114, 3866, 1505, 195, 79893, 574, 0, 198, 2160, 0, 192, 0, 420, 0, 384, 0, 2701, 0, 114, 6025, 1549, 74627, 0, 238, 0, 0, 0, 3729, 0, 192, 0, 79893, 0, 0, 729, 3141, 129, 0, 192, 196764, 39, 0, 0, 714, 63, 0, 55, 420, 3356, 0, 0, 117, 412, 0, 0, 79758, 0, 1901, 1130, 4067, 2133, 0, 0, 875, 72, 0, 0, 336, 2789, 0, 0, 25, 920, 121, 104, 0, 3162, 0, 0, 420, 0, 2178, 0, 0, 386, 192545, 159306, 0, 0, 0, 1914, 0, 200, 0, 1794, 0, 2654, 0, 0, 25480, 420, 0, 2795, 0, 0, 229690, 0, 32559, 0, 0, 392, 253919, 0, 0, 0, 0, 379, 0, 0, 114, 0, 553, 10, 0, 1128, 0, 23610, 248, 151, 0, 418, 0, 651, 0, 36, 0, 0, 645, 0, 0, 513, 0, 0, 25480, 420, 34, 0, 0, 0, 15, 0, 3348, 0, 3496, 0, 35, 687, 0, 1, 48, 0, 0, 2803, 0, 0, 714, 1274, 0, 114, 62, 1006, 70268, 1200, 2357, 0, 497, 0, 497, 125, 0, 913, 4647, 3985, 0, 0, 3370, 245233, 0, 0, 687, 0, 4, 1288, 0, 0, 0, 0, 715, 0, 0, 687, 583, 0, 0, 1627, 0, 0, 11, 357, 1359, 0, 849, 0, 0, 1518, 462, 245233, 0, 0, 0, 0, 0, 0, 171, 70268, 0))\n",
      "521\n"
     ]
    }
   ],
   "source": [
    "# APXXXXXXXXX corresponds to the unique identifier of a document:\n",
    "# e.g., APXXXXXXX where AP denotes the collection and the Xs correspond to a unique numerical identifier.\n",
    "\n",
    "example_document = index.document(1)\n",
    "print(example_document)\n",
    "print(len(example_document[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see a document consists of two things, a string representing the external document identifier and an integer list representing the identifiers of words that make up the document. Pyndri uses integer representations for words or terms, thus a token_id is an integer that represents a word whereas the token is the actual text of the word/term. Every id has a unique token and vice versa with the exception of stop words: words so common that there are uninformative, all of these receive the zero id.\n",
    "\n",
    "To see what some ids and their matching tokens we take a look at the dictionary of the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 'new'), (2, 'percent'), (3, 'two'), (4, '1'), (5, 'people'), (6, 'million'), (7, '000'), (8, 'government'), (9, 'president'), (10, 'years'), (11, 'state'), (12, '2'), (13, 'states'), (14, 'three'), (15, 'time')]\n",
      "267318\n"
     ]
    }
   ],
   "source": [
    "token2id, id2token, _ = index.get_dictionary()\n",
    "print(list(id2token.items())[:15])\n",
    "print(len(id2token))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this dictionary we can see the tokens for the (non-stop) words in our example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['52', 'students', 'arrested', 'takeover', 'university', 'massachusetts', 'building', 'fifty', 'two', 'students', 'arrested', 'tuesday', 'evening', 'occupying', 'university', 'massachusetts', 'building', 'overnight', 'protest', 'defense', 'department', 'funded', 'research', 'new', 'york', 'city', 'thousands', 'city', 'college', 'students', 'got', 'unscheduled', 'holiday', 'demonstrators', 'occupied', 'campus', 'administration', 'building', 'protest', 'possible', 'tuition', 'increases', 'prompting', 'officials', 'suspend', 'classes', '60', 'police', 'riot', 'gear', 'arrived', 'university', 'massachusetts', '5', 'p', 'm', 'two', 'hours', 'later', 'bus', 'drove', 'away', '29', 'students', 'camped', 'memorial', 'hall', 'students', 'charged', 'trespassing', '23', 'students', 'arrested', 'lying', 'bus', 'prevent', 'leaving', 'police', '300', 'students', 'stood', 'building', 'chanting', 'looking', 'students', 'hall', 'arrested', '35', 'students', 'occupied', 'memorial', 'hall', '1', 'p', 'm', 'monday', 'declined', 'offer', 'meet', 'administrators', 'provosts', 'office', 'tuesday', 'morning', 'presented', 'list', 'demands', 'halt', 'defense', 'department', 'research', '25', '000', 'student', 'campus', '40', 'students', 'left', 'building', 'tuesday', 'morning', 'university', 'administrators', 'told', 'arrested', '5', 'p', 'm', 'university', 'spokeswoman', 'jeanne', 'hopkins', 'takeover', 'second', 'western', 'massachusetts', 'campus', 'seven', 'protesters', 'arrested', 'april', '19', 'charges', 'disorderly', 'conduct', 'trespassing', 'demonstrating', 'military', 'funded', 'research', 'campus', 'particularly', 'research', 'anthrax', 'research', 'university', 'non', 'classified', 'researchers', 'make', 'work', 'public', 'university', 'rules', '11', '6', 'million', '22', 'percent', 'grant', 'money', 'received', 'university', 'came', 'defense', 'department', '1988', 'school', 'chancellor', 'joseph', 'd', 'duffey', 'issued', 'statement', 'telling', 'students', 'research', 'continue', 'campus', 'school', 'administrators', 'decide', 'differently', 'policy', 'negotiated', 'students', 'duffey', 'latest', 'occupation', 'began', 'students', 'rallying', 'monday', 'student', 'union', 'military', 'research', 'marched', 'administration', 'building', 'ducked', 'memorial', 'hall', 'en', 'route', 'followed', 'members', 'local', 'chapter', 'american', 'friends', 'service', 'committee', 'contended', 'research', 'dangerous', 'town', 'promotes', 'militarism', 'banned', 'university', 'argued', 'purpose', 'anthrax', 'research', 'peaceful', 'strain', 'bacteria', 'non', 'virulent', 'study', 'school', '23', 'years', 'incident', 'amherst', 'health', 'board', 'scheduled', 'hearing', 'wednesday', 'question', 'safety', 'anthrax', 'research', 'tuesday', 'time', '1969', 'classes', 'city', 'college', 'new', 'york', 'canceled', 'student', 'protests', 'school', 'spokesman', 'charles', 'deciccio', 'protesters', 'demanding', 'face', 'face', 'meeting', 'gov', 'mario', 'cuomo', 'feared', 'tuition', 'college', '1', '250', 'increased', 'college', 'staff', 'reduced', 'state', 'budget', 'cuts', 'governor', 'immediate', 'comment', 'tuition', 'set', 'deciccio']\n"
     ]
    }
   ],
   "source": [
    "print([id2token[word_id] for word_id in example_document[1] if word_id > 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reverse can also be done, say we want to look for news about the \"University of Massachusetts\", the tokens of that query can be converted to ids using the reverse dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by tokens: ['university', '', 'massachusetts']\n",
      "Query by ids with stopwords: [200, 0, 894]\n",
      "Query by ids without stopwords: [200, 894]\n"
     ]
    }
   ],
   "source": [
    "query_tokens = index.tokenize(\"University of Massachusetts\")\n",
    "print(\"Query by tokens:\", query_tokens)\n",
    "query_id_tokens = [token2id.get(query_token,0) for query_token in query_tokens]\n",
    "print(\"Query by ids with stopwords:\", query_id_tokens)\n",
    "query_id_tokens = [word_id for word_id in query_id_tokens if word_id > 0]\n",
    "print(\"Query by ids without stopwords:\", query_id_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally we can now match the document and query in the id space, let's see how often a word from the query occurs in our example document:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document AP890425-0001 has 13 word matches with query: \"university  massachusetts\".\n",
      "Document AP890425-0001 and query \"university  massachusetts\" have a 2.5% overlap.\n"
     ]
    }
   ],
   "source": [
    "matching_words = sum([True for word_id in example_document[1] if word_id in query_id_tokens])\n",
    "print(\"Document %s has %d word matches with query: \\\"%s\\\".\" % (example_document[0], matching_words, ' '.join(query_tokens)))\n",
    "print(\"Document %s and query \\\"%s\\\" have a %.01f%% overlap.\" % (example_document[0], ' '.join(query_tokens),matching_words/float(len(example_document[1]))*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this is certainly not everything Pyndri can do, it should give you an idea of how to use it. Please take a look at the [examples](https://github.com/cvangysel/pyndri) as it will help you a lot with this assignment.\n",
    "\n",
    "**CAUTION**: Avoid printing out the whole index in this Notebook as it will generate a lot of output and is likely to corrupt the Notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing the query file\n",
    "You can parse the query file (`ap_88_89/topics_title`) using the following snippet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OrderedDict([('51', 'Airbus Subsidies'), ('52', 'South African Sanctions'), ('53', 'Leveraged Buyouts'), ('54', 'Satellite Launch Contracts'), ('55', 'Insider Trading'), ('56', 'Prime (Lending) Rate Moves, Predictions'), ('57', 'MCI'), ('58', 'Rail Strikes'), ('59', 'Weather Related Fatalities'), ('60', 'Merit-Pay vs. Seniority'), ('61', 'Israeli Role in Iran-Contra Affair'), ('62', \"Military Coups D'etat\"), ('63', 'Machine Translation'), ('64', 'Hostage-Taking'), ('65', 'Information Retrieval Systems'), ('66', 'Natural Language Processing'), ('67', 'Politically Motivated Civil Disturbances'), ('68', 'Health Hazards from Fine-Diameter Fibers'), ('69', 'Attempts to Revive the SALT II Treaty'), ('70', 'Surrogate Motherhood'), ('71', 'Border Incursions'), ('72', 'Demographic Shifts in the U.S.'), ('73', 'Demographic Shifts across National Boundaries'), ('74', 'Conflicting Policy'), ('75', 'Automation'), ('76', 'U.S. Constitution - Original Intent'), ('77', 'Poaching'), ('78', 'Greenpeace'), ('79', 'FRG Political Party Positions'), ('80', '1988 Presidential Candidates Platforms'), ('81', 'Financial crunch for televangelists in the wake of the PTL scandal'), ('82', 'Genetic Engineering'), ('83', 'Measures to Protect the Atmosphere'), ('84', 'Alternative/renewable Energy Plant & Equipment Installation'), ('85', 'Official Corruption'), ('86', 'Bank Failures'), ('87', 'Criminal Actions Against Officers of Failed Financial Institutions'), ('88', 'Crude Oil Price Trends'), ('89', '\"Downstream\" Investments by OPEC Member States'), ('90', 'Data on Proven Reserves of Oil & Natural Gas Producers'), ('91', 'U.S. Army Acquisition of Advanced Weapons Systems'), ('92', 'International Military Equipment Sales'), ('93', 'What Backing Does the National Rifle Association Have?'), ('94', 'Computer-aided Crime'), ('95', 'Computer-aided Crime Detection'), ('96', 'Computer-Aided Medical Diagnosis'), ('97', 'Fiber Optics Applications'), ('98', 'Fiber Optics Equipment Manufacturers'), ('99', 'Iran-Contra Affair'), ('100', 'Controlling the Transfer of High Technology'), ('101', 'Design of the \"Star Wars\" Anti-missile Defense System'), ('102', \"Laser Research Applicable to the U.S.'s Strategic Defense Initiative\"), ('103', 'Welfare Reform'), ('104', 'Catastrophic Health Insurance'), ('105', '\"Black Monday\"'), ('106', 'U.S. Control of Insider Trading'), ('107', 'Japanese Regulation of Insider Trading'), ('108', 'Japanese Protectionist Measures'), ('109', 'Find Innovative Companies'), ('110', 'Black Resistance Against the South African Government'), ('111', 'Nuclear Proliferation'), ('112', 'Funding Biotechnology'), ('113', 'New Space Satellite Applications'), ('114', 'Non-commercial Satellite Launches'), ('115', 'Impact of the 1986 Immigration Law'), ('116', 'Generic Drug Substitutions'), ('117', 'Capacity of the U.S. Cellular Telephone Network'), ('118', 'International Terrorists'), ('119', 'Actions Against International Terrorists'), ('120', 'Economic Impact of International Terrorism'), ('121', 'Death from Cancer'), ('122', 'RDT&E of New Cancer Fighting Drugs'), ('123', 'Research into & Control of Carcinogens'), ('124', 'Alternatives to Traditional Cancer Therapies'), ('125', 'Anti-smoking Actions by Government'), ('126', 'Medical Ethics and Modern Technology'), ('127', 'U.S.-U.S.S.R. Arms Control Agreements'), ('128', 'Privatization of State Assets'), ('129', 'Soviet Spying on the U.S.'), ('130', 'Jewish Emigration and U.S.-USSR Relations'), ('131', 'McDonnell Douglas Contracts for Military Aircraft'), ('132', '\"Stealth\" Aircraft'), ('133', 'Hubble Space Telescope'), ('134', 'The Human Genome Project'), ('135', 'Possible Contributions of Gene Mapping to Medicine'), ('136', 'Diversification by Pacific Telesis'), ('137', 'Expansion in the U.S. Theme Park Industry'), ('138', 'Iranian Support for Lebanese Hostage-takers'), ('139', \"Iran's Islamic Revolution - Domestic and Foreign Social Consequences\"), ('140', 'Political Impact of Islamic Fundamentalism'), ('141', \"Japan's Handling of its Trade Surplus with the U.S.\"), ('142', 'Impact of Government Regulated Grain Farming on International Relations'), ('143', 'Why Protect U.S. Farmers?'), ('144', 'Management Problems at the United Nations'), ('145', 'Influence of the \"Pro-Israel Lobby\"'), ('146', 'Negotiating an End to the Nicaraguan Civil War'), ('147', 'Productivity Trends in the U.S. Economy'), ('148', 'Conflict in the Horn of Africa'), ('149', 'Industrial Espionage'), ('150', 'U.S. Political Campaign Financing'), ('151', 'Coping with overcrowded prisons'), ('152', 'Accusations of Cheating by Contractors on U.S. Defense Projects'), ('153', 'Insurance Coverage which pays for Long Term Care'), ('154', 'Oil Spills'), ('155', 'Right Wing Christian Fundamentalism in U.S.'), ('156', 'Efforts to enact Gun Control Legislation'), ('157', 'Causes and treatments of multiple sclerosis (MS)'), ('158', 'Term limitations for members of the U.S. Congress'), ('159', 'Electric Car Development'), ('160', 'Vitamins - The Cure for or Cause of Human Ailments'), ('161', 'Acid Rain'), ('162', 'Automobile Recalls'), ('163', 'Vietnam Veterans and Agent Orange'), ('164', 'Generic Drugs - Illegal Activities by Manufacturers'), ('165', 'Tobacco company advertising and the young'), ('166', 'Standardized testing and cultural bias'), ('167', 'Regulation of the showing of violence and explicit sex in motion picture theaters, on television, and on video cassettes.'), ('168', 'Financing AMTRAK'), ('169', 'Cost of Garbage/Trash Removal'), ('170', 'The Consequences of Implantation of Silicone Gel Breast Devices'), ('171', \"Use of Mutual Funds in an Individual's Retirement Strategy\"), ('172', 'The Effectiveness of Medical Products and Related Programs Utilized in the Cessation of Smoking.'), ('173', 'Smoking Bans'), ('174', 'Hazardous Waste Cleanup'), ('175', 'NRA Prevention of Gun Control Legislation'), ('176', 'Real-life private investigators'), ('177', 'English as the Official Language in U.S.'), ('178', 'Dog Maulings'), ('179', 'U. S. Restaurants in Foreign Lands'), ('180', 'Ineffectiveness of U.S. Embargoes/Sanctions'), ('181', 'Abuse of the Elderly by Family Members, and Medical and Nonmedical Personnel, and Initiatives Being Taken to Minimize This Mistreatment'), ('182', 'Commercial Overfishing Creates Food Fish Deficit'), ('183', 'Asbestos Related Lawsuits'), ('184', 'Corporate Pension Plans/Funds'), ('185', 'Reform of the U.S. Welfare System'), ('186', 'Difference of Learning Levels Among Inner City and More Suburban School Students'), ('187', 'Signs of the Demise of Independent Publishing'), ('188', 'Beachfront Erosion'), ('189', 'Real Motives for Murder'), ('190', 'Instances of Fraud Involving the Use of a Computer'), ('191', 'Efforts to Improve U.S. Schooling'), ('192', 'Oil Spill Cleanup'), ('193', 'Toys R Dangerous'), ('194', 'The Amount of Money Earned by Writers'), ('195', 'Stock Market Perturbations Attributable to Computer Initiated Trading'), ('196', 'School Choice Voucher System and its effects upon the entire U.S. educational program'), ('197', 'Reform of the jurisprudence system to stop juries from granting unreasonable monetary awards'), ('198', 'Gene Therapy and Its Benefits to Humankind'), ('199', 'Legality of Medically Assisted Suicides'), ('200', 'Impact of foreign textile imports on U.S. textile industry')])\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "import io\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "def parse_topics(file_or_files,\n",
    "                 max_topics=sys.maxsize, delimiter=';'):\n",
    "    assert max_topics >= 0 or max_topics is None\n",
    "\n",
    "    topics = collections.OrderedDict()\n",
    "\n",
    "    if not isinstance(file_or_files, list) and \\\n",
    "            not isinstance(file_or_files, tuple):\n",
    "        if hasattr(file_or_files, '__iter__'):\n",
    "            file_or_files = list(file_or_files)\n",
    "        else:\n",
    "            file_or_files = [file_or_files]\n",
    "\n",
    "    for f in file_or_files:\n",
    "        assert isinstance(f, io.IOBase)\n",
    "\n",
    "        for line in f:\n",
    "            assert(isinstance(line, str))\n",
    "\n",
    "            line = line.strip()\n",
    "\n",
    "            if not line:\n",
    "                continue\n",
    "\n",
    "            topic_id, terms = line.split(delimiter, 1)\n",
    "\n",
    "            if topic_id in topics and (topics[topic_id] != terms):\n",
    "                    logging.error('Duplicate topic \"%s\" (%s vs. %s).',\n",
    "                                  topic_id,\n",
    "                                  topics[topic_id],\n",
    "                                  terms)\n",
    "\n",
    "            topics[topic_id] = terms\n",
    "\n",
    "            if max_topics > 0 and len(topics) >= max_topics:\n",
    "                print(\"Max capacity reached... Breaking...\")\n",
    "                break\n",
    "\n",
    "    return topics\n",
    "\n",
    "with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "    print(parse_topics([f_topics]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement and compare lexical IR methods [35 points] ### \n",
    "\n",
    "In this task you will implement a number of lexical methods for IR using the **Pyndri** framework. Then you will evaluate these methods on the dataset we have provided using **TREC Eval**.\n",
    "\n",
    "Use the **Pyndri** framework to get statistics of the documents (term frequency, document frequency, collection frequency; **you are not allowed to use the query functionality of Pyndri**) and implement the following scoring methods in **Python**:\n",
    "\n",
    "- [TF-IDF](http://nlp.stanford.edu/IR-book/html/htmledition/tf-idf-weighting-1.html) and \n",
    "- [BM25](http://nlp.stanford.edu/IR-book/html/htmledition/okapi-bm25-a-non-binary-model-1.html) with k1=1.2 and b=0.75. **[5 points]**\n",
    "- Language models ([survey](https://drive.google.com/file/d/0B-zklbckv9CHc0c3b245UW90NE0/view))\n",
    "    - Jelinek-Mercer (explore different values of 𝛌 in the range [0.1, 0.5, 0.9]). **[5 points]**\n",
    "    - Dirichlet Prior (explore different values of 𝛍 [500, 1000, 1500]). **[5 points]**\n",
    "    - Absolute discounting (explore different values of 𝛅 in the range [0.1, 0.5, 0.9]). **[5 points]**\n",
    "    - [Positional Language Models](http://sifaka.cs.uiuc.edu/~ylv2/pub/sigir09-plm.pdf) define a language model for each position of a document, and score a document based on the scores of its PLMs. The PLM is estimated based on propagated counts of words within a document through a proximity-based density function, which both captures proximity heuristics and achieves an effect of “soft” passage retrieval. Implement the PLM, all five kernels, but only the Best position strategy to score documents. Use 𝛔 equal to 50, and Dirichlet smoothing with 𝛍 optimized on the validation set (decide how to optimize this value yourself and motivate your decision in the report). **[10 points]**\n",
    "    \n",
    "Implement the above methods and report evaluation measures (on the test set) using the hyper parameter values you optimized on the validation set (also report the values of the hyper parameters). Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "For the language models, create plots showing `NDCG@10` with varying values of the parameters. You can do this by chaining small scripts using shell scripting (preferred) or execute trec_eval using Python's `subprocess`.\n",
    "\n",
    "Compute significance of the results using a [two-tailed paired Student t-test](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_rel.html) **[5 points]**. Be wary of false rejection of the null hypothesis caused by the [multiple comparisons problem](https://en.wikipedia.org/wiki/Multiple_comparisons_problem). There are multiple ways to mitigate this problem and it is up to you to choose one.\n",
    "\n",
    "Analyse the results by identifying specific queries where different methods succeed or fail and discuss possible reasons that cause these differences. This is *very important* in order to understand how the different retrieval functions behave.\n",
    "\n",
    "**NOTE**: Don’t forget to use log computations in your calculations to avoid underflows. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT**: You should structure your code around the helper functions we provide below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of documents:  164597\n",
      "Gathering statistics about 456 terms.\n",
      "Inverted index creation took 68.31635904312134 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from collections import defaultdict\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "    queries = parse_topics([f_topics])\n",
    "\n",
    "index = pyndri.Index('index/')\n",
    "\n",
    "num_documents = index.maximum_document() - index.document_base()\n",
    "\n",
    "print('Total number of documents: ', num_documents)\n",
    "\n",
    "dictionary = pyndri.extract_dictionary(index)\n",
    "\n",
    "tokenized_queries = {\n",
    "    query_id: [dictionary.translate_token(token)\n",
    "               for token in index.tokenize(query_string)\n",
    "               if dictionary.has_token(token)]\n",
    "    for query_id, query_string in queries.items()}\n",
    "\n",
    "query_term_ids = set(\n",
    "    query_term_id\n",
    "    for query_term_ids in tokenized_queries.values()\n",
    "    for query_term_id in query_term_ids)\n",
    "\n",
    "#print('Query term IDs: ', query_term_ids)\n",
    "\n",
    "print('Gathering statistics about', len(query_term_ids), 'terms.')\n",
    "\n",
    "# inverted index creation.\n",
    "\n",
    "document_lengths = {}\n",
    "unique_terms_per_document = {}\n",
    "\n",
    "inverted_index = collections.defaultdict(dict)\n",
    "collection_frequencies = collections.defaultdict(int)\n",
    "\n",
    "# Used to build query/document relevance matrix in task 4\n",
    "ext2int = defaultdict(int)\n",
    "int2ext = {}\n",
    "\n",
    "total_terms = 0\n",
    "\n",
    "for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "    ext_doc_id, doc_token_ids = index.document(int_doc_id)\n",
    "    \n",
    "    ext2int[ext_doc_id] = int_doc_id\n",
    "\n",
    "    document_bow = collections.Counter(\n",
    "        token_id for token_id in doc_token_ids\n",
    "        if token_id > 0)\n",
    "    document_length = sum(document_bow.values())\n",
    "\n",
    "    document_lengths[int_doc_id] = document_length\n",
    "    total_terms += document_length\n",
    "\n",
    "    unique_terms_per_document[int_doc_id] = len(document_bow)\n",
    "\n",
    "    for query_term_id in query_term_ids:\n",
    "        assert query_term_id is not None\n",
    "\n",
    "        document_term_frequency = document_bow.get(query_term_id, 0)\n",
    "\n",
    "        if document_term_frequency == 0:\n",
    "            continue\n",
    "\n",
    "        collection_frequencies[query_term_id] += document_term_frequency\n",
    "        inverted_index[query_term_id][int_doc_id] = document_term_frequency\n",
    "\n",
    "# inverse of ext2int which was built in the loop above\n",
    "int2ext = {i : ext for ext, i in ext2int.items()}\n",
    "\n",
    "avg_doc_length = total_terms / num_documents\n",
    "\n",
    "print('Inverted index creation took', time.time() - start_time, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of queries:  150\n",
      "Average document length:  256.4381975370147\n"
     ]
    }
   ],
   "source": [
    "print('Total number of queries: ', len(queries))\n",
    "print('Average document length: ', avg_doc_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query by tokens: ['beachfront']\n",
      "Query by ids with stopwords: [36062]\n",
      "Query by ids without stopwords: [36062]\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "query_tokens = index.tokenize(\"Beachfront\")\n",
    "print(\"Query by tokens:\", query_tokens)\n",
    "query_id_tokens = [token2id.get(query_token,0) for query_token in query_tokens]\n",
    "print(\"Query by ids with stopwords:\", query_id_tokens)\n",
    "query_id_tokens = [word_id for word_id in query_id_tokens if word_id > 0]\n",
    "print(\"Query by ids without stopwords:\", query_id_tokens)\n",
    "print(inverted_index[query_id_tokens[0]][649])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[      0.  171350.       0.       0.       0.       0.       0.       0.\n",
      "  119771.       0.       0.   96612.       0.   84131.       0.       0.\n",
      "       0.       0.       0.   73013.   71782.   69256.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.   56945.       0.   55709.       0.       0.   54180.   53986.\n",
      "       0.       0.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.       0.       0.   46470.   46166.\n",
      "       0.   45936.       0.       0.       0.       0.       0.       0.\n",
      "       0.       0.       0.       0.   41803.   41350.       0.       0.\n",
      "   40954.       0.       0.   40696.       0.   40579.   40331.       0.\n",
      "   40019.       0.   39433.       0.       0.   38950.       0.       0.\n",
      "       0.       0.       0.       0.   37135.       0.   36935.       0.\n",
      "       0.   36376.       0.       0.]\n",
      "(267319,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\"\"\"Helper functions\"\"\"\n",
    "\n",
    "def term_frequency(term_id, document_id):\n",
    "    \"\"\"\n",
    "    Retrieves the term frequency a given word in a given document\n",
    "    \n",
    "    NB: depends on global variable 'inverted_index'\n",
    "    \n",
    "    :param term_id: The id of the word in question\n",
    "    :param document_id: The internal document_id of the document in question\n",
    "    \"\"\"\n",
    "    \n",
    "    return inverted_index[term_id].get(document_id, 0)\n",
    "\n",
    "def compute_BM25(doc_length, tf_raw, term_id, k, b):\n",
    "    \"\"\"\n",
    "    Helper function to isolate computations shared by both query and document versions of BM25 method\n",
    "    \"\"\"\n",
    "    \n",
    "    inv_norm = doc_length / avg_doc_length\n",
    "    document_freq = len(inverted_index[term_id])\n",
    "    \n",
    "    tf_normalized = tf_raw * (avg_doc_length / doc_length)\n",
    "\n",
    "    # Note: slides are not particularly clear about whether to still use the normalized TF or not.\n",
    "    # In this case we will continue with this normalized variable.\n",
    "    tf = ((1.0 + k) * tf_normalized) / (k * ((b - 1.0) + b * (inv_norm)) + tf_normalized)\n",
    "    \n",
    "    idf = np.log(num_documents / document_freq)\n",
    "    \n",
    "    return tf * idf\n",
    "\n",
    "def build_document_vector(document_id, vocabulary_size):\n",
    "    '''\n",
    "    Creates a vector of length V with the term frequency for each word in the vocabulary at its\n",
    "    corresponding index\n",
    "    \n",
    "    :param document_id: The internal document id\n",
    "    :param vocabulary_size: The number of words in the vocabulary\n",
    "    '''\n",
    "    \n",
    "    vector = np.zeros(vocabulary_size)\n",
    "    \n",
    "    for token_id in inverted_index:\n",
    "        documents_for_term = inverted_index[token_id]\n",
    "        \n",
    "        if document_id in documents_for_term:\n",
    "            vector[token_id] = documents_for_term[document_id]\n",
    "        \n",
    "    return vector\n",
    "        \n",
    "def build_query_vector(query_terms, vocabulary_size):\n",
    "    '''\n",
    "    Creates a vector of length V with the term frequency for each word in the vocabulary at its\n",
    "    corresponding index\n",
    "    \n",
    "    :param query_terms: A list of query term ids\n",
    "    :param vocabulary_size: The number of words in the vocabulary\n",
    "    '''\n",
    "    \n",
    "    vector = np.zeros(vocabulary_size)\n",
    "    counts = collections.Counter(query_terms)\n",
    "    \n",
    "    for token_id in counts:\n",
    "        vector[token_id] = counts[token_id]\n",
    "        \n",
    "    return vector\n",
    "\n",
    "# Vector representation of the collection frequencies dictionary\n",
    "collection_freq_matrix = np.zeros(len(id2token) + 1)\n",
    "for key in sorted(collection_frequencies.keys()):\n",
    "    if key > 0:\n",
    "        collection_freq_matrix[key] = collection_frequencies[key]\n",
    "\n",
    "print(collection_freq_matrix[:100])\n",
    "print(collection_freq_matrix.shape)\n",
    "# print(collection_freq_matrix.getnnz() - len(collection_freq_matrix.nonzero()[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Scoring Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy import sparse\n",
    "from scipy.stats import norm\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "def score_similarity(query_terms, document_id, weight_fn = None, query_weight_fn = None):\n",
    "    '''\n",
    "    Scoring function for a document and a query\n",
    "    \n",
    "    :param query_terms: A list of query term ids\n",
    "    :param document_id: The internal document id\n",
    "    :param weight: A function to re-weight the vectors\n",
    "    \n",
    "    returns a score (float)\n",
    "    '''\n",
    "    \n",
    "    vocab_size = len(id2token)\n",
    "    \n",
    "    # Create query vector\n",
    "    # Create document vector\n",
    "    doc_vec = build_document_vector(document_id, vocab_size)\n",
    "    query_vec = build_query_vector(query_terms, vocab_size)\n",
    "    \n",
    "    # Combine query and document into a matrix with sparse representation (only save indices of non-zero entries)\n",
    "    paired_matrix = np.array([query_vec, doc_vec])\n",
    "    paired_matrix = sparse.csr_matrix(paired_matrix)\n",
    "    \n",
    "    if weight_fn and query_weight_fn:\n",
    "        # nonzero() returns a tuple of two lists\n",
    "        # 0 -> i dimension of non zero entries in array where i == 0 is the query vector\n",
    "        # 1 -> j dimension of non zero entries in array array where j corresponds to the term_id\n",
    "        document_type, term_ids = paired_matrix.nonzero()\n",
    "        \n",
    "        for document_type, term_id in zip(document_type, term_ids):\n",
    "            if document_type == 0:\n",
    "                # query stuff\n",
    "                paired_matrix[document_type, term_id] = query_weight_fn(query_terms, term_id)\n",
    "            else:\n",
    "                # document stuff\n",
    "                paired_matrix[document_type, term_id] = weight_fn(document_id, term_id)\n",
    "    \n",
    "    # Calculate similarity matrix\n",
    "    similarity_matrix = cosine_similarity(paired_matrix)\n",
    "    \n",
    "    # Only first row is relevant (query document similarities)\n",
    "    similarities = similarity_matrix[0, 1:]\n",
    "    \n",
    "    return similarities\n",
    "\n",
    "\n",
    "def tfidf_query(query_terms, query_term_id):\n",
    "    counts = collections.Counter(query_terms)\n",
    "    \n",
    "    tf = np.log(1 + counts[query_term_id])\n",
    "    \n",
    "    df = len(inverted_index[query_term_id])\n",
    "    idf = np.log(num_documents / df)\n",
    "    \n",
    "    score = tf * idf\n",
    "    \n",
    "    return score\n",
    "\n",
    "def tfidf(int_document_id, query_term_id):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and a query term\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_term_id: the query term id (assuming you have split the query to tokens)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Check: RAW COUNT OR NORMALIZED TF???\n",
    "    tf = np.log(1 + term_frequency(query_term_id, int_document_id))\n",
    "    \n",
    "    # inverted_index[query_term_id] consists of all the documents this term appears in\n",
    "    df = len(inverted_index[query_term_id])\n",
    "    idf = np.log(num_documents / df)\n",
    "    \n",
    "    score = tf * idf \n",
    "    \n",
    "    return score\n",
    "\n",
    "# Here we will normalize the raw TF and a different kind of damping: (1 + k)/k\n",
    "def BM25(int_document_id, query_term_id, k=1.2, b=0.75):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and all terms of a single query\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_term_id: Token id of the term to be re-weighted\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    doc_length = len(index.document(int_document_id)[1])\n",
    "    tf_raw = term_frequency(query_term_id, int_document_id)\n",
    "    \n",
    "    return compute_BM25(doc_length, tf_raw, query_term_id, k, b)\n",
    "\n",
    "def BM25_query(query_terms, query_term_id, k=1.2, b=0.75):\n",
    "    \"\"\"\n",
    "    Scoring function for a document and all terms of a single query\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_term_id: Token id of the term to be re-weighted\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    doc_length = len(query_terms) \n",
    "    counts = collections.Counter(query_terms)\n",
    "    tf_raw = counts[query_term_id]\n",
    "    \n",
    "    return compute_BM25(doc_length, tf_raw, query_term_id, k, b)\n",
    "\n",
    "def absolute_discounting(int_document_id, query_term_id, delta=0.5):\n",
    "    \n",
    "    # TODO: figure our if tf should be raw or not. Max to ensure tf in range [0,1]\n",
    "    tf_raw = max(term_frequency(query_term_id, int_document_id) - delta, 0)\n",
    "    tot_nr_terms_in_doc = len(index.document(int_document_id)[1])\n",
    "    unique_terms_in_doc = unique_terms_per_document[int_document_id]\n",
    "    \n",
    "    corpus_size = total_terms\n",
    "    word_frequency = collection_frequencies[query_term_id]\n",
    "    p_w_c = word_frequency / corpus_size\n",
    "    \n",
    "    score = tf_raw / tot_nr_terms_in_doc + ((delta * tot_nr_terms_in_doc) / tot_nr_terms_in_doc) * p_w_c\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "def dirichlet_prior_smoothing(int_document_id, query_term_id, mu=1000):\n",
    "    ''' input: one document id, one query term id, mu\n",
    "        output: for one query word , the dirichlet smoothed prior\n",
    "    '''\n",
    "\n",
    "    # Calculate the components of the model: tf, |d|, p(w|c)\n",
    "    tf = term_frequency(query_term_id, int_document_id)\n",
    "    document_length = document_lengths[int_document_id]\n",
    "    # TODO: functie van tf en p_wc maken (alhoewel de dict lookup voor TF best clean is)\n",
    "    # TODO: Checken of p_wc klopt bij docenten\n",
    "    p_wc = collection_frequencies[query_term_id]/total_terms\n",
    "#     print('tf',tf)\n",
    "#     print('doc length',document_lengths[int_document_id])\n",
    "#     print('p(w|C),', collection_frequencies[query_term_id],'/',sum(collection_frequencies.values()))\n",
    "    dir_smoothed_prior = ((document_length/(document_length+mu))*(tf/document_length))+ ((mu/(document_length + mu))*p_wc)\n",
    "    return dir_smoothed_prior\n",
    "\n",
    "def jelinek_mercer(int_document_id, query_term_id, lambd=0.5):\n",
    "    \"\"\"\n",
    "    Calcuate probabilty of a term by linearly interpolating with background language model.\n",
    "    \n",
    "    NB: Background probablity is calculated by weighting all words equally.\n",
    "    \n",
    "    :param int_document_id: the document id\n",
    "    :param query_token_id: the query term id (assuming you have split the query to tokens)\n",
    "    :param lambd: the lambda paramter for the function\n",
    "    \"\"\"\n",
    "    \n",
    "    # TODO: Checken of het klopt (was vet moe toen ik dit implementeerde)\n",
    "    \n",
    "    doc_length = len(index.document(int_document_id)[1])\n",
    "    \n",
    "    term_freq_doc = term_frequency(query_term_id, int_doc_id)\n",
    "    term_freq_corpus = sum(inverted_index[query_term_id].values())\n",
    "    \n",
    "    signal = (term_freq_doc / doc_length)\n",
    "    background = (term_freq_corpus / total_terms)\n",
    "    \n",
    "    return lambd * signal  + (1 - lambd) * background\n",
    "\n",
    "\n",
    "\n",
    "# TODO implement tools to help you with the analysis of the results.\n",
    "def PLM_score_old(query_id_tokens, int_document_id, kernel_func, mu, sigma = 50, return_argmax=False):\n",
    "    '''input: one document id, one query id (so the id of one whole query)(ranging from 1-150) ,\n",
    "        a kernel function, mu, sigma (=50)\n",
    "    output: a language model for the document with a best position scoring strategy\n",
    "\n",
    "    assumption: following the paper 'Positional Language Models for Information Retrieval - Yuanhua Lv, ChengXiang Zhai'\n",
    "    \n",
    "    Given a query, suppose all terms in a document have the\n",
    "    same propagation function with the same σ, and the curve\n",
    "    of the kernel density function is symmetric. Then we have\n",
    "    k(i, j) = k(j, i). '''\n",
    "    \n",
    "    # document variables\n",
    "    document = index.document(int_document_id)[1]\n",
    "    doc_length = len(document)\n",
    "    \n",
    "    # Query id tokens without stopwords\n",
    "\n",
    "    query_id_no_stopwrds = [word_id for word_id in query_id_tokens if word_id > 0]\n",
    "    query_length = len(query_id_no_stopwrds)\n",
    "        \n",
    "    # Create a matrix to store all c(w,i)' values that matter\n",
    "    c_wi_prime_matrix = np.zeros((query_length,doc_length))\n",
    "    \n",
    "    # Todo: matrix maken van kernel\n",
    "    one_sided_kernel = [kernel_func(0, j) for j in range(doc_length)]\n",
    "    kernel = np.array(list(reversed(one_sided_kernel))[:-1] + one_sided_kernel)\n",
    "    \n",
    "    # Loop over all positions in the document\n",
    "    for i, word_id_i in enumerate(document):\n",
    "        # If a word occurs in the query we should propagate its frequency to other positions\n",
    "        # TODO: check how to handle multiple occurences of word in query\n",
    "        for q, wrd in enumerate(query_id_no_stopwrds):\n",
    "            if word_id_i == wrd:\n",
    "                # Loop over all positions in the document as to have a distance from position i to j\n",
    "                # for positions where i is a query word\n",
    "                for j in max_usefull_range(one_sided_kernel, i, doc_length):\n",
    "                    c_wi_prime_matrix[q][j] += kernel[i - j]\n",
    "    \n",
    "    # Go through all positions in the document again now all the \n",
    "    # frequencies have been propagated\n",
    "    Zi_vec = np.sum(c_wi_prime_matrix,axis=0)\n",
    "\n",
    "    # Dirichlet smoothed probability of a query word on a position in the document\n",
    "    p_wc_vec = collection_freq_matrix[np.array(query_id_tokens)] / total_terms\n",
    "    p_wc_vec = np.expand_dims(p_wc_vec, axis=1)\n",
    "    \n",
    "    smooth_pos_values = (c_wi_prime_matrix + mu * p_wc_vec) / (Zi_vec + mu)\n",
    "    \n",
    "    # Calculate p(w|Q)\n",
    "    q_language = ml_query_word_language_model(query_id_tokens) \n",
    "    \n",
    "    # log( P(w|D,i) ) for all w, i pairs\n",
    "    log_pos_values = np.log(smooth_pos_values)\n",
    "    \n",
    "    # Simplified KL-divergence formula (proportional to original for the same query)\n",
    "    kl_divergence_scores = np.sum(q_language * log_pos_values.T, axis=1)\n",
    "    \n",
    "    if return_argmax:\n",
    "        return np.argmax(kl_divergence_scores)\n",
    "    else:\n",
    "        return np.amax(kl_divergence_scores)\n",
    "\n",
    "def max_usefull_range(kernel_vector, i, N):\n",
    "    \n",
    "    try:\n",
    "        max_distance = kernel_vector.index(0)\n",
    "    except:\n",
    "        max_distance = len(kernel_vector)\n",
    "        \n",
    "    minimum = max(0, i - max_distance)\n",
    "    maximum = min(N, i + max_distance)\n",
    "    \n",
    "    return range(minimum, maximum)\n",
    "\n",
    "def quick_mats(i, N, sigma):\n",
    "        normalize = np.sqrt(2*np.pi*sigma**2)\n",
    "        big_area = norm.cdf( (N - i) / sigma )\n",
    "        small_area = norm.cdf( (1 - i) / sigma )\n",
    "        \n",
    "        return normalize * (big_area - small_area)\n",
    "\n",
    "def gaussian_kernel(i, j, sigma=50):\n",
    "    return np.exp(-(i-j)**2 / (2 * sigma**2))\n",
    "\n",
    "def triangle_kernel(i, j, sigma=50):\n",
    "    return 1-abs(i - j)/sigma if abs(i - j) <= sigma else 0\n",
    "\n",
    "def cosine_kernel(i, j, sigma=50):\n",
    "    return 0.5 * (1 + np.cos((abs(i - j) * np.pi) / sigma)) if abs(i - j) <= sigma else 0\n",
    "\n",
    "def circle_kernel(i, j, sigma=50):\n",
    "    return np.sqrt(1-(abs(i - j)/sigma)**2) if abs(i - j) <= sigma else 0\n",
    "\n",
    "def passage_kernel(i, j, sigma=50):\n",
    "    return int(abs(i - j) < sigma/2)\n",
    "\n",
    "def ml_query_word_language_model(query_term_ids):\n",
    "    counts = collections.Counter(query_term_ids)\n",
    "    return np.array([counts[term_id] / len(query_term_ids) for term_id in query_term_ids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['leveraged', 'buyouts']\n",
      "['nwa', 'board', 'rejects', 'davis', 'offer', 'amends', 'court', 'complaint', 'calling', 'parts', 'oilman', 'marvin', 'davis', '2', '7', 'billion', 'bid', 'northwest', 'airlines', 'illegal', 'unfinanced', 'nwa', 's', 'board', 'directors', 'unanimously', 'rejected', 'offer', 'moved', 'take', 'court', 'action', 'block', 'efforts', 'board', 'monday', 'reaffirmed', 'willingness', 'negotiate', 'suitors', 'davis', 'interest', 'producing', 'transaction', 'best', 'interests', 'nwa', 'shareholders', 'seek', 'quick', 'hearing', 'motion', 'enjoin', 'davis', '90', 'share', 'tender', 'offer', 'board', 'working', 'undisclosed', 'number', 'parties', 'indicated', 'interest', 'acquiring', 'northwest', 'nations', 'fourth', 'largest', 'carrier', 'nwa', 'stock', 'closed', '102', '75', 'monday', '25', 'cents', 'share', 'new', 'york', 'stock', 'exchange', 'composite', 'trading', 'amended', 'complaint', 'district', 'court', 'minneapolis', 'nwa', 'board', 'davis', 'financing', 'plan', 'exceed', 'federal', 'margin', 'rules', 'aimed', 'limiting', 'amount', 'credit', 'buy', 'stock', 'board', '1', '25', 'billion', 'preferred', 'stock', 'financing', 'planned', 'davis', 'buyout', 'actually', 'considered', 'debt', 'motion', 'claims', 'davis', 'tender', 'offer', 'actually', 'illegal', 'proxy', 'solicitation', 'provided', 'insufficient', 'information', 'shareholders', 'regarding', 'source', 'availability', '450', 'million', 'equity', 'davis', 'buyout', 'addition', 'minnesota', 'commerce', 'commissioner', 'michael', 'hatch', 'monday', 'found', 'davis', 'acquisition', 's', 'registration', 'statement', 'offering', 'purchase', 'nwa', 's', 'outstanding', 'shares', 'deficient', 'hatch', 'davis', 'failed', 'disclose', 'manner', 'operate', 'nwa', 'expand', 'operation', 'dispose', 'strategic', 'assets', 'company', 'lay', 'employees', 'additionally', 'commissioner', 'davis', 'did', 'disclose', 'plans', 'relating', 'airbus', 'maintenance', 'facility', 'intended', 'locate', 'minnesota', 'hatch', 'scheduled', 'hearing', 'matter', 'evening', 'registration', 'suspended', 'friday', 'deficiencies', 'corrected', 'jim', 'fingeroth', 'davis', 'spokesman', 'acquisition', 'company', 'comment', 'order', 'davis', 'attorneys', 'shoring', 'efforts', 'delaware', 'nwa', 'incorporated', 'lawyers', 'argued', 'wilmington', 'del', 'court', 'provision', 'nwas', 'poison', 'pill', 'takeover', 'defense', 'hindering', 'efforts', 'put', 'new', 'nwa', 'board', 'directors', 'place', 'defense', 'effectively', 'block', 'new', 'board', 'directors', 'selling', 'nwa', '180', 'days', 'prospect', 'long', 'delay', 'discourage', 'shareholders', 'supporting', 'davis', 'proxy', 'fight', 'planned', 'nwas', '15', 'annual', 'meeting', 'attorney', 'gilchrist', 'sparks', 'told', 'hearing', 'nwa', 'chairman', 'steven', 'rothmeier', 'prefers', 'airline', 'remain', 'independent', 'find', 'white', 'knight', 'investor', 'work', 'current', 'management', 'letters', '5', '000', 'union', 'pilots', 'northwest', 'rothmeier', 'alternatives', 'available', 'friendly', 'investors', 'assistance', 'contingent', 'contract', 'settlement', 'pilots', 'working', 'two', 'separate', 'contracts', 'northwest', 'acquired', 'republic', 'airlines', '1986', 'davis', 'delaware', 'court', 'action', 'altered', 'course', 'fight', 'northwest', 'poison', 'pill', 'initially', 'sought', 'invalidate', 'entire', 'poison', 'plan', 'cost', 'potential', 'acquisition', 'hostile', 'bidder', 'flooding', 'market', 'new', 'nwa', 'shares', 'sparks', 'monday', 'davis', 'retain', 'pill', 'event', 'gained', 'control', 'board', 'rothmeier', 'declined', 'identify', 'potential', 'friendly', 'investors', 'company', 'group', 'holding', '4', '9', 'percent', 'nwas', '29', '1', 'million', 'shares', 'outstanding', 'interested', 'leveraged', 'buyout', 'leveraged', 'buyout', 'company', 'bought', 'largely', 'borrowed', 'funds', 'group', 'includes', 'los', 'angeles', 'based', 'investor', 'alfred', 'checchi', 'former', 'nwa', 'board', 'member', 'gary', 'wilson', 'executive', 'walt', 'disney', 'co', 'new', 'york', 'times', 'reported', 'monday', 'kelso', 'co', 'small', 'investment', 'bank', 'based', 'new', 'york', 'considering', 'bid', 'airline', 'spokesman', 'kelso', 'northwest', 'declined', 'comment']\n",
      "-22.6882695853\n",
      "-17.8379683005\n",
      "-17.8863587182\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "Multinominal: p(q|lmodel_d) = prod( p(w_i | lmodel_d) )\n",
    "lmodel_d: argmax p(d | lmodel_d) --> the model for which d has the highest probability of occuring\n",
    "                 p(d | lmodel_d) = prod_over_w_in_doc( p(w | lmodel_d) ) (sum log)\n",
    "                 log_p(d | lmodel_d) = sum_over_w_in_vocab( tf(w;d) * log_p(w | lmodel_d ) )\n",
    "                 p_ml(w | lmodel_d) = tf(w;d) / len(d)\n",
    "'''\n",
    "\n",
    "def unigram_prob(term_id, document_id):\n",
    "    \"\"\"\n",
    "    Maximum Likelihood estimate of p(word|document_model)\n",
    "    \"\"\"\n",
    "    tf = term_frequency(term_id, document_id)\n",
    "    doc_length = len(index.document(document_id)[1])\n",
    "    \n",
    "    return tf / doc_length\n",
    "\n",
    "### Probabilistic score function\n",
    "def log_multinomial_query_language_model(query_term_ids, document_id, word_probability_func=unigram_prob):\n",
    "    \"\"\"\n",
    "    Query-likelihood model assuming uniform document prior\n",
    "    \"\"\"\n",
    "\n",
    "    counts = collections.Counter(query_term_ids)\n",
    "    # sum_over_words_in_query( tf(w;d) * log( p(w|d) ) )\n",
    "    return np.sum([counts[term_id]*np.log(word_probability_func(document_id, term_id)) \n",
    "                   for term_id in query_term_ids])\n",
    "\n",
    "def kl_divergenge(query_term_ids, document_id, word_probability_func=unigram_prob):\n",
    "    \n",
    "    p_word_given_query = ml_query_word_language_model(query_term_ids)\n",
    "    p_word_given_document = np.array([word_probability_func(term_id, document_id) for term_id in query_term_ids])\n",
    "    \n",
    "    return np.sum(p_word_given_query * np.log(p_word_given_document))\n",
    "\n",
    "# Document and query share terms\n",
    "test_query = [4886, 48553] \n",
    "test_doc = 251\n",
    "\n",
    "print([id2token[idx] for idx in test_query if idx > 0])\n",
    "print([id2token[idx] for idx in index.document(test_doc)[1] if idx > 0])\n",
    "\n",
    "for smoothing_func in [jelinek_mercer, absolute_discounting, dirichlet_prior_smoothing]:\n",
    "    print(log_multinomial_query_language_model(test_query, test_doc, smoothing_func))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  120  test queries and  30  validation queries\n"
     ]
    }
   ],
   "source": [
    "# Figure out which queries are relevant\n",
    "\n",
    "validation_queries_ids = []\n",
    "with open('./ap_88_89/qrel_validation', 'r') as validation_queries:\n",
    "    for line in validation_queries:\n",
    "        query_id = line.split(' ')[0]\n",
    "        if query_id not in validation_queries_ids:\n",
    "            validation_queries_ids.append(query_id)\n",
    "            \n",
    "            \n",
    "\n",
    "test_queries_ids = []\n",
    "with open('./ap_88_89/qrel_test', 'r') as test_queries:\n",
    "    for line in test_queries:\n",
    "        query_id = line.split(' ')[0]\n",
    "        if query_id not in test_queries_ids:\n",
    "            test_queries_ids.append(query_id)\n",
    "\n",
    "            \n",
    "print('There are ',len(test_queries_ids),' test queries and ',len(validation_queries_ids),' validation queries')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 1000 relevant documents for query 51: ['AP880731-0085', 'AP880325-0293', 'AP880706-0311', 'AP880316-0292', 'AP880721-0290', 'AP890630-0056', 'AP880406-0267', 'AP880318-0287', 'AP881118-0209', 'AP890908-0122', 'AP880627-0045', 'AP891126-0082', 'AP881108-0253', 'AP890503-0279', 'AP891010-0258', 'AP890908-0222', 'AP880627-0039', 'AP880412-0268', 'AP880627-0093', 'AP880712-0156', 'AP890629-0275', 'AP891003-0130', 'AP880311-0301', 'AP881128-0075', 'AP880517-0253', 'AP880626-0038', 'AP881028-0294', 'AP890209-0234', 'AP890106-0255', 'AP890327-0161', 'AP890817-0225', 'AP880628-0097', 'AP881129-0057', 'AP890608-0253', 'AP891117-0213', 'AP890913-0264', 'AP880704-0023', 'AP880512-0314', 'AP880831-0223', 'AP890620-0248', 'AP890724-0045', 'AP880628-0170', 'AP880407-0258', 'AP880928-0210', 'AP881219-0271', 'AP890306-0244', 'AP890410-0255', 'AP881203-0143', 'AP880629-0215', 'AP890404-0263', 'AP880520-0261', 'AP880729-0166', 'AP891211-0325', 'AP890817-0223', 'AP890216-0167', 'AP880520-0122', 'AP880626-0003', 'AP891011-0255', 'AP880905-0132', 'AP890328-0202', 'AP891126-0084', 'AP881119-0051', 'AP890216-0288', 'AP880626-0019', 'AP890705-0196', 'AP890104-0259', 'AP881119-0077', 'AP880516-0318', 'AP890418-0241', 'AP880826-0050', 'AP880405-0268', 'AP891127-0256', 'AP891120-0065', 'AP890823-0099', 'AP881231-0042', 'AP891221-0274', 'AP890731-0272', 'AP891214-0204', 'AP880628-0310', 'AP881025-0133', 'AP880915-0047', 'AP880804-0167', 'AP890601-0339', 'AP880215-0180', 'AP890306-0264', 'AP880627-0175', 'AP880714-0190', 'AP880627-0063', 'AP880707-0089', 'AP880627-0115', 'AP880405-0176', 'AP890708-0097', 'AP881207-0184', 'AP890329-0221', 'AP890622-0084', 'AP890206-0170', 'AP881230-0138', 'AP890618-0075', 'AP881104-0232', 'AP890207-0133', 'AP890724-0259', 'AP880901-0073', 'AP881021-0179', 'AP880717-0007', 'AP880814-0005', 'AP880907-0010', 'AP881021-0256', 'AP880516-0328', 'AP880708-0148', 'AP880626-0076', 'AP880301-0271', 'AP880314-0167', 'AP881130-0262', 'AP890920-0246', 'AP890209-0229', 'AP890906-0284', 'AP880716-0076', 'AP891215-0260', 'AP880922-0206', 'AP880711-0107', 'AP880813-0003', 'AP890928-0294', 'AP880707-0127', 'AP880726-0137', 'AP880217-0261', 'AP880703-0077', 'AP880703-0076', 'AP880708-0112', 'AP880706-0194', 'AP890517-0089', 'AP880503-0244', 'AP890127-0117', 'AP880711-0054', 'AP880705-0183', 'AP890427-0306', 'AP880906-0086', 'AP880706-0033', 'AP880312-0036', 'AP880621-0292', 'AP880805-0037', 'AP891221-0216', 'AP880706-0025', 'AP880705-0082', 'AP891219-0249', 'AP890821-0246', 'AP880624-0282', 'AP881221-0144', 'AP891205-0223', 'AP880711-0139', 'AP880831-0183', 'AP890702-0030', 'AP890712-0120', 'AP880819-0168', 'AP890115-0012', 'AP891117-0214', 'AP890729-0071', 'AP890426-0260', 'AP881205-0196', 'AP880706-0117', 'AP890405-0282', 'AP890901-0154', 'AP890410-0121', 'AP890911-0278', 'AP890515-0080', 'AP880909-0107', 'AP880513-0284', 'AP890723-0061', 'AP880705-0189', 'AP880818-0218', 'AP881019-0037', 'AP881222-0106', 'AP880728-0142', 'AP880712-0153', 'AP890428-0090', 'AP880513-0252', 'AP880708-0189', 'AP880622-0052', 'AP880624-0296', 'AP880428-0001', 'AP890207-0230', 'AP890914-0250', 'AP890419-0228', 'AP890418-0313', 'AP890127-0155', 'AP880621-0250', 'AP891009-0123', 'AP890518-0275', 'AP890130-0234', 'AP880831-0109', 'AP880413-0195', 'AP891208-0192', 'AP880706-0213', 'AP890721-0245', 'AP880420-0287', 'AP891017-0271', 'AP890816-0187', 'AP881017-0296', 'AP890310-0265', 'AP881111-0202', 'AP890125-0094', 'AP880708-0179', 'AP880705-0043', 'AP880720-0294', 'AP881203-0116', 'AP890612-0290', 'AP880706-0188', 'AP880718-0153', 'AP890105-0233', 'AP880312-0052', 'AP881124-0128', 'AP891002-0199', 'AP880706-0244', 'AP881004-0246', 'AP880527-0315', 'AP880623-0173', 'AP880617-0267', 'AP890506-0013', 'AP890929-0096', 'AP890523-0235', 'AP890110-0304', 'AP890703-0134', 'AP880422-0219', 'AP880229-0271', 'AP880312-0117', 'AP880624-0025', 'AP890407-0285', 'AP890703-0072', 'AP881130-0272', 'AP890502-0093', 'AP890608-0032', 'AP891121-0110', 'AP880624-0180', 'AP891002-0334', 'AP890816-0062', 'AP891002-0261', 'AP880707-0037', 'AP890614-0287', 'AP891018-0037', 'AP880706-0208', 'AP891220-0125', 'AP880926-0235', 'AP890128-0159', 'AP880728-0023', 'AP880708-0044', 'AP880621-0221', 'AP881204-0092', 'AP890426-0268', 'AP891011-0163', 'AP880803-0157', 'AP890227-0132', 'AP890607-0108', 'AP880705-0069', 'AP881019-0150', 'AP890411-0010', 'AP880708-0119', 'AP881209-0219', 'AP890323-0197', 'AP880705-0169', 'AP880815-0175', 'AP880705-0167', 'AP890723-0009', 'AP880708-0020', 'AP880623-0180', 'AP880714-0180', 'AP880227-0156', 'AP891007-0018', 'AP890606-0198', 'AP880409-0016', 'AP880618-0073', 'AP890607-0014', 'AP881121-0268', 'AP881202-0163', 'AP881117-0116', 'AP880704-0009', 'AP880706-0225', 'AP880616-0202', 'AP890929-0165', 'AP880516-0151', 'AP890428-0054', 'AP891116-0258', 'AP890918-0116', 'AP891207-0121', 'AP880908-0136', 'AP890707-0114', 'AP880818-0272', 'AP890406-0027', 'AP890406-0263', 'AP890224-0066', 'AP890520-0011', 'AP890813-0052', 'AP880623-0015', 'AP890607-0086', 'AP890208-0146', 'AP880820-0096', 'AP890504-0256', 'AP880728-0192', 'AP890428-0002', 'AP880617-0033', 'AP890812-0133', 'AP880708-0092', 'AP890108-0032', 'AP880223-0268', 'AP890727-0042', 'AP891024-0145', 'AP880229-0013', 'AP880622-0040', 'AP880706-0105', 'AP890412-0226', 'AP891003-0103', 'AP891018-0174', 'AP880506-0221', 'AP880504-0042', 'AP890908-0034', 'AP890612-0011', 'AP881229-0171', 'AP890503-0044', 'AP890310-0316', 'AP880713-0028', 'AP890907-0159', 'AP890623-0269', 'AP890305-0051', 'AP881209-0233', 'AP880719-0122', 'AP890314-0278', 'AP890315-0137', 'AP890223-0276', 'AP880720-0216', 'AP880713-0126', 'AP880709-0108', 'AP890223-0281', 'AP890223-0164', 'AP891110-0023', 'AP890628-0005', 'AP890210-0202', 'AP890418-0312', 'AP880409-0180', 'AP890522-0084', 'AP880627-0012', 'AP880513-0032', 'AP881216-0227', 'AP881214-0227', 'AP880621-0255', 'AP890601-0260', 'AP881205-0264', 'AP890103-0117', 'AP881206-0019', 'AP891002-0120', 'AP880618-0111', 'AP880509-0225', 'AP890606-0044', 'AP891209-0045', 'AP880518-0348', 'AP881002-0062', 'AP891122-0148', 'AP880804-0086', 'AP890701-0050', 'AP890119-0027', 'AP881126-0001', 'AP880720-0292', 'AP880619-0070', 'AP890707-0209', 'AP890412-0286', 'AP890509-0269', 'AP890322-0207', 'AP881207-0223', 'AP890330-0021', 'AP890506-0006', 'AP880425-0167', 'AP890306-0253', 'AP880411-0118', 'AP880302-0275', 'AP880426-0025', 'AP880705-0076', 'AP890801-0228', 'AP881223-0194', 'AP880808-0072', 'AP880708-0096', 'AP891005-0149', 'AP890811-0028', 'AP891129-0025', 'AP890404-0239', 'AP890717-0014', 'AP880415-0170', 'AP890428-0191', 'AP890619-0204', 'AP880704-0136', 'AP881115-0114', 'AP880820-0098', 'AP880417-0079', 'AP880705-0038', 'AP880812-0142', 'AP881207-0273', 'AP891128-0218', 'AP880526-0209', 'AP880705-0061', 'AP891130-0010', 'AP880716-0019', 'AP880619-0092', 'AP880617-0306', 'AP890131-0178', 'AP880819-0148', 'AP881102-0255', 'AP880829-0033', 'AP880621-0331', 'AP890519-0076', 'AP881020-0103', 'AP891020-0203', 'AP890523-0040', 'AP880705-0056', 'AP880421-0013', 'AP880905-0043', 'AP880705-0130', 'AP891103-0204', 'AP880706-0087', 'AP880517-0252', 'AP880707-0129', 'AP880418-0064', 'AP890222-0111', 'AP880519-0275', 'AP891219-0108', 'AP890920-0049', 'AP880627-0009', 'AP891004-0231', 'AP890122-0100', 'AP880613-0131', 'AP880708-0100', 'AP880704-0089', 'AP890613-0247', 'AP880729-0058', 'AP890627-0148', 'AP890104-0279', 'AP891117-0018', 'AP891129-0234', 'AP890906-0311', 'AP880921-0220', 'AP890217-0158', 'AP881205-0021', 'AP880415-0302', 'AP891030-0178', 'AP880621-0240', 'AP880818-0158', 'AP880623-0157', 'AP880415-0223', 'AP880817-0180', 'AP880808-0162', 'AP890504-0182', 'AP880520-0288', 'AP880617-0289', 'AP890121-0095', 'AP881020-0170', 'AP890301-0211', 'AP890713-0026', 'AP891018-0047', 'AP891222-0290', 'AP880901-0017', 'AP890302-0175', 'AP891003-0060', 'AP891101-0286', 'AP880519-0303', 'AP890914-0041', 'AP880523-0018', 'AP880711-0173', 'AP880706-0109', 'AP880818-0267', 'AP890413-0014', 'AP880929-0250', 'AP890313-0233', 'AP880809-0246', 'AP890418-0079', 'AP891024-0197', 'AP890117-0018', 'AP890301-0076', 'AP880704-0144', 'AP890719-0300', 'AP880704-0123', 'AP880212-0093', 'AP880729-0198', 'AP890131-0301', 'AP880706-0147', 'AP880329-0252', 'AP880710-0042', 'AP881019-0233', 'AP880621-0247', 'AP890608-0149', 'AP890605-0085', 'AP891218-0055', 'AP890624-0007', 'AP890224-0128', 'AP890609-0270', 'AP890413-0262', 'AP881014-0292', 'AP880617-0270', 'AP880704-0025', 'AP891128-0199', 'AP890724-0067', 'AP880316-0024', 'AP890808-0010', 'AP890419-0227', 'AP890114-0004', 'AP880225-0174', 'AP880709-0078', 'AP880709-0073', 'AP891006-0104', 'AP890526-0222', 'AP890502-0207', 'AP890920-0009', 'AP880610-0282', 'AP890418-0290', 'AP880709-0088', 'AP880320-0104', 'AP890722-0154', 'AP880711-0011', 'AP880503-0016', 'AP890907-0273', 'AP880513-0227', 'AP890819-0020', 'AP890503-0254', 'AP880901-0271', 'AP880621-0226', 'AP880706-0325', 'AP880622-0056', 'AP880708-0109', 'AP891219-0166', 'AP880708-0207', 'AP890920-0131', 'AP880706-0046', 'AP890526-0152', 'AP891014-0013', 'AP880708-0162', 'AP891219-0213', 'AP890210-0048', 'AP880705-0010', 'AP880628-0087', 'AP890511-0035', 'AP890108-0068', 'AP890512-0039', 'AP890103-0010', 'AP880621-0246', 'AP891221-0118', 'AP890518-0116', 'AP880805-0001', 'AP881227-0145', 'AP881222-0089', 'AP890425-0029', 'AP890427-0221', 'AP891027-0233', 'AP890913-0036', 'AP881224-0007', 'AP890623-0029', 'AP890927-0152', 'AP890411-0191', 'AP880516-0312', 'AP880628-0092', 'AP881212-0220', 'AP881126-0138', 'AP880709-0178', 'AP880714-0187', 'AP881117-0172', 'AP880707-0042', 'AP880428-0301', 'AP890726-0019', 'AP891205-0192', 'AP881205-0278', 'AP880703-0078', 'AP890805-0010', 'AP890208-0268', 'AP880928-0011', 'AP890921-0158', 'AP880526-0021', 'AP890112-0243', 'AP890727-0192', 'AP880809-0180', 'AP891221-0129', 'AP880407-0149', 'AP890830-0072', 'AP880411-0165', 'AP880217-0207', 'AP880921-0093', 'AP880301-0282', 'AP881205-0276', 'AP890110-0016', 'AP880428-0017', 'AP891002-0339', 'AP880506-0116', 'AP890510-0266', 'AP891217-0040', 'AP890511-0222', 'AP890307-0140', 'AP880818-0297', 'AP890928-0135', 'AP890329-0113', 'AP881127-0078', 'AP890518-0101', 'AP880621-0237', 'AP881007-0067', 'AP891019-0216', 'AP891002-0137', 'AP880610-0283', 'AP880704-0147', 'AP890227-0288', 'AP880316-0029', 'AP880705-0046', 'AP891006-0222', 'AP880706-0260', 'AP880925-0048', 'AP880705-0202', 'AP880526-0329', 'AP891208-0020', 'AP880512-0019', 'AP880320-0022', 'AP891013-0069', 'AP891026-0232', 'AP881105-0040', 'AP880404-0121', 'AP880622-0287', 'AP881205-0250', 'AP881130-0270', 'AP890427-0275', 'AP880704-0119', 'AP890131-0123', 'AP890111-0078', 'AP881025-0040', 'AP890219-0106', 'AP891117-0100', 'AP891030-0194', 'AP890228-0177', 'AP880921-0119', 'AP880704-0046', 'AP891219-0192', 'AP880921-0232', 'AP880709-0167', 'AP890623-0158', 'AP880711-0074', 'AP890704-0174', 'AP890621-0238', 'AP890323-0256', 'AP881214-0269', 'AP880617-0305', 'AP881019-0005', 'AP880708-0248', 'AP890804-0075', 'AP890117-0087', 'AP891112-0040', 'AP881102-0263', 'AP890130-0021', 'AP881012-0082', 'AP891219-0116', 'AP890525-0093', 'AP880427-0201', 'AP890112-0007', 'AP890605-0084', 'AP891214-0023', 'AP880901-0273', 'AP890408-0097', 'AP880620-0013', 'AP891012-0009', 'AP890125-0185', 'AP880507-0212', 'AP890317-0131', 'AP880518-0281', 'AP881130-0280', 'AP880428-0187', 'AP880827-0035', 'AP890719-0295', 'AP880704-0050', 'AP890202-0195', 'AP880427-0193', 'AP890419-0189', 'AP880708-0232', 'AP880903-0066', 'AP890108-0094', 'AP890119-0193', 'AP880623-0248', 'AP880318-0331', 'AP880317-0180', 'AP881018-0019', 'AP880709-0062', 'AP880709-0043', 'AP890626-0112', 'AP890109-0144', 'AP880729-0309', 'AP880719-0183', 'AP880622-0188', 'AP891111-0084', 'AP880704-0101', 'AP881105-0027', 'AP881213-0151', 'AP890802-0237', 'AP890301-0257', 'AP891129-0271', 'AP890803-0159', 'AP890322-0212', 'AP881222-0124', 'AP891206-0009', 'AP890526-0012', 'AP881123-0294', 'AP880710-0012', 'AP890802-0097', 'AP880712-0034', 'AP880316-0154', 'AP881002-0009', 'AP890426-0083', 'AP880707-0067', 'AP890204-0175', 'AP880415-0035', 'AP880610-0279', 'AP890110-0165', 'AP890724-0005', 'AP880714-0004', 'AP891029-0046', 'AP890117-0252', 'AP880927-0191', 'AP890720-0240', 'AP890929-0181', 'AP881102-0163', 'AP880517-0247', 'AP890215-0002', 'AP880620-0010', 'AP890407-0263', 'AP880709-0109', 'AP880920-0022', 'AP880731-0051', 'AP890726-0269', 'AP880504-0201', 'AP890927-0025', 'AP891111-0099', 'AP890125-0184', 'AP890627-0100', 'AP880613-0144', 'AP880420-0342', 'AP880420-0226', 'AP880213-0157', 'AP890914-0069', 'AP890407-0321', 'AP881031-0103', 'AP880707-0038', 'AP880321-0168', 'AP880616-0243', 'AP890628-0040', 'AP880703-0055', 'AP880909-0111', 'AP880813-0115', 'AP881121-0020', 'AP890110-0048', 'AP880618-0076', 'AP890811-0144', 'AP890812-0081', 'AP891129-0178', 'AP881215-0029', 'AP880813-0216', 'AP890726-0130', 'AP891013-0165', 'AP880423-0034', 'AP890930-0029', 'AP890518-0201', 'AP880412-0086', 'AP890628-0214', 'AP880921-0204', 'AP890201-0003', 'AP881031-0113', 'AP880714-0072', 'AP890314-0027', 'AP880729-0186', 'AP881104-0023', 'AP890111-0138', 'AP880525-0347', 'AP880724-0045', 'AP880702-0018', 'AP881230-0079', 'AP881206-0248', 'AP891102-0199', 'AP881207-0278', 'AP880725-0216', 'AP880712-0202', 'AP890614-0014', 'AP890329-0255', 'AP890111-0217', 'AP890515-0141', 'AP880922-0193', 'AP890619-0259', 'AP890614-0249', 'AP881028-0170', 'AP890624-0023', 'AP880713-0125', 'AP890322-0331', 'AP880712-0223', 'AP881207-0246', 'AP881113-0015', 'AP890427-0258', 'AP881021-0163', 'AP881206-0223', 'AP890109-0198', 'AP890919-0084', 'AP880713-0032', 'AP890107-0160', 'AP881115-0014', 'AP891129-0157', 'AP890714-0212', 'AP881026-0018', 'AP890602-0272', 'AP890823-0072', 'AP880705-0104', 'AP880531-0261', 'AP891005-0185', 'AP890917-0002', 'AP891130-0114', 'AP881123-0218', 'AP890801-0149', 'AP891013-0083', 'AP890428-0224', 'AP890619-0026', 'AP880413-0185', 'AP890127-0163', 'AP890126-0243', 'AP880627-0091', 'AP880920-0270', 'AP880421-0319', 'AP880721-0269', 'AP890109-0346', 'AP880704-0141', 'AP881008-0119', 'AP890929-0032', 'AP880803-0124', 'AP890112-0126', 'AP881212-0248', 'AP880602-0130', 'AP880729-0020', 'AP890207-0277', 'AP890109-0007', 'AP890113-0156', 'AP890228-0134', 'AP881230-0109', 'AP881013-0262', 'AP880704-0065', 'AP880315-0195', 'AP890110-0178', 'AP880704-0146', 'AP880823-0174', 'AP880314-0252', 'AP890114-0003', 'AP891101-0033', 'AP890302-0326', 'AP891111-0010', 'AP891122-0035', 'AP890403-0048', 'AP890927-0158', 'AP891208-0263', 'AP881011-0009', 'AP890816-0147', 'AP890901-0071', 'AP880721-0313', 'AP881228-0066', 'AP891124-0188', 'AP880718-0071', 'AP891130-0232', 'AP890323-0016', 'AP881228-0092', 'AP880709-0054', 'AP890816-0246', 'AP890429-0056', 'AP880714-0130', 'AP891006-0014', 'AP880318-0167', 'AP890622-0003', 'AP880703-0071', 'AP880301-0257', 'AP890628-0021', 'AP891211-0178', 'AP880709-0025', 'AP890603-0150', 'AP891110-0196', 'AP891206-0199', 'AP880607-0109', 'AP890727-0166', 'AP880803-0232', 'AP891010-0009', 'AP891011-0275', 'AP880331-0313', 'AP880706-0214', 'AP890711-0135', 'AP880618-0006', 'AP890425-0230', 'AP881202-0114', 'AP890711-0050', 'AP880616-0188', 'AP881231-0022', 'AP880703-0073', 'AP880309-0405', 'AP880222-0164', 'AP890211-0169', 'AP880927-0014', 'AP891103-0231', 'AP890509-0155', 'AP890420-0016', 'AP890605-0001', 'AP890127-0165', 'AP880923-0126', 'AP880613-0145', 'AP890711-0112', 'AP881222-0243', 'AP880503-0225', 'AP890526-0071', 'AP880708-0068', 'AP890623-0279', 'AP880217-0191', 'AP880624-0268', 'AP880714-0170', 'AP880803-0160', 'AP890807-0163', 'AP880519-0110', 'AP891211-0203', 'AP890505-0021', 'AP881209-0135', 'AP880704-0134', 'AP881110-0148', 'AP880421-0311', 'AP881222-0132', 'AP890823-0168', 'AP881130-0112', 'AP881124-0129', 'AP880705-0131', 'AP890823-0173', 'AP880704-0152', 'AP891106-0065', 'AP880325-0115', 'AP890217-0022', 'AP880711-0163', 'AP890206-0237', 'AP880421-0045', 'AP890209-0158', 'AP890216-0120', 'AP890628-0169', 'AP890516-0077', 'AP890615-0177', 'AP891110-0213', 'AP890120-0254', 'AP891211-0314', 'AP880318-0019', 'AP880224-0215', 'AP891017-0091', 'AP880531-0241', 'AP890410-0049', 'AP891115-0136', 'AP880326-0039', 'AP881118-0186', 'AP880919-0133', 'AP881216-0186', 'AP890406-0151', 'AP880708-0023', 'AP890516-0165', 'AP890521-0093', 'AP880425-0331', 'AP880615-0028', 'AP891207-0233', 'AP880701-0176', 'AP880705-0143', 'AP890310-0209', 'AP891208-0201', 'AP880705-0019', 'AP880921-0115', 'AP880714-0172', 'AP881101-0022', 'AP890129-0060', 'AP890928-0202', 'AP880705-0106', 'AP880627-0304', 'AP890816-0029', 'AP890612-0008', 'AP890524-0049', 'AP890110-0197', 'AP890710-0252', 'AP890310-0235', 'AP880304-0010', 'AP890818-0153', 'AP880325-0120', 'AP881020-0182', 'AP880702-0184', 'AP881229-0067', 'AP891110-0064', 'AP890525-0163', 'AP890811-0205', 'AP891004-0135', 'AP880226-0027', 'AP891125-0070', 'AP880719-0051', 'AP880604-0024', 'AP881124-0016', 'AP880212-0120', 'AP880715-0234', 'AP880225-0004', 'AP880215-0218', 'AP891213-0183', 'AP880707-0114', 'AP891204-0277', 'AP890626-0264', 'AP881222-0201', 'AP891101-0042', 'AP880713-0198', 'AP891012-0312', 'AP881122-0020']\n"
     ]
    }
   ],
   "source": [
    "# Only the TF-IDF top 1000 needs to be evaluated for the PLM and for the Latent Semantic Models\n",
    "from collections import defaultdict \n",
    "top_1000_per_test_query = defaultdict(list)\n",
    "\n",
    "with open('./run/already_run/TF-IDF.run', 'r') as top_docs_per_query:\n",
    "    for line in top_docs_per_query:\n",
    "        query_id = line.split(' ')[0]\n",
    "        document_name = line.split(' ')[2]\n",
    "        top_1000_per_test_query[query_id].append(document_name)\n",
    "\n",
    "\n",
    "\n",
    "print('The top 1000 relevant documents for query 51:', top_1000_per_test_query['51'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def run_retrieval(model_name, score_fn, model_type, query_set):\n",
    "    \"\"\"\n",
    "    Runs a retrieval method for all the queries and writes the TREC-friendly results in a file.\n",
    "    \n",
    "    :param model_name: the name of the model (a string)\n",
    "    :param score_fn: the scoring function (a function - see below for an example) \n",
    "    :param model_type: indicates if a vector space or a proabilistic model is run. Takes either \"Vector space\"\n",
    "                        or \"Probabilistic\"\n",
    "    :param query_set: validation_queries_ids or test_queries_ids\n",
    "    \"\"\"\n",
    "    run_out_path = 'letor_data/{}.run'.format(model_name)\n",
    "#     pickle_path = '{}_validation_queries.pickle'.format(model_name)\n",
    "    if os.path.exists(run_out_path):\n",
    "        print(\"File already exists; exiting...\")\n",
    "        return\n",
    "    \n",
    "    retrieval_start_time = time.time()\n",
    "\n",
    "    print('Retrieving using', model_name)\n",
    "\n",
    "    # The dictionary data should have the form: query_id --> (document_score, external_doc_id)\n",
    "    data = {}\n",
    "    if model_name == 'TF-IDF':\n",
    "        weight_fn = tfidf\n",
    "        query_weight_fn = tfidf_query\n",
    "    if model_name == 'BM25':\n",
    "        weight_fn = BM25\n",
    "        query_weight_fn = BM25_query\n",
    "    counter = 1\n",
    "\n",
    "    for query_id, query_terms in tokenized_queries.items():\n",
    "        # Run for uneven queries in query set\n",
    "#         if int(query_id) % 2 == 0:\n",
    "#             continue\n",
    "        if query_id not in query_set:\n",
    "            continue\n",
    "\n",
    "        for int_doc_id in range(index.document_base(), index.maximum_document()):\n",
    "            \n",
    "            ext_doc_id, doc_token_ids = index.document(int_doc_id)\n",
    "            \n",
    "            if ext_doc_id not in top_1000_per_test_query[query_id]:\n",
    "                continue\n",
    "\n",
    "            # Only calculate score of document if it contains query words,\n",
    "            # otherwise the score is zero for the vector based models\n",
    "            length_query = len(query_terms)\n",
    "\n",
    "            for i, query_term in enumerate(query_terms):\n",
    "                # Only compute score if the query word is in the document\n",
    "                \n",
    "                if int_doc_id in inverted_index[query_term].keys():\n",
    "\n",
    "                    # Calculate score for document and query terms\n",
    "                    if model_type == \"Vector space\":\n",
    "                        score = score_similarity(query_terms, int_doc_id, weight_fn, query_weight_fn)\n",
    "                    elif model_type == \"Probabilistic\":\n",
    "                        score = score_fn(query_terms, int_doc_id)\n",
    "                                        \n",
    "                \n",
    "                    if query_id in data.keys():\n",
    "                        data[query_id].append(tuple([float(score), str(ext_doc_id)]))\n",
    "                    else:\n",
    "                        data[query_id] = [((tuple([float(score),str(ext_doc_id)])))]\n",
    "\n",
    "                    # If the document has a query word, than the score is calculated and appended by this point\n",
    "                    break\n",
    "\n",
    "\n",
    "                # If up until the last query word, the query word did not appear in the \n",
    "                # document, the score is the lowerst possible (-infinity)\n",
    "                elif i == length_query-1:\n",
    "                    score = -np.inf\n",
    "                    if query_id in data.keys():\n",
    "                        data[query_id].append(tuple([float(score), str(ext_doc_id)]))\n",
    "                    else:\n",
    "                        data[query_id] = [((tuple([float(score),str(ext_doc_id)])))]\n",
    "\n",
    "\n",
    "\n",
    "        print('queries: ', counter,'/',len(query_set),'\\t this took: ', time.time() - retrieval_start_time, ' seconds in total' )\n",
    "        counter += 1\n",
    "        \n",
    "        # transform the list of tuples to a tuple of tuples, since this is the requered datastructue\n",
    "        data[query_id] = tuple(data[query_id])\n",
    "\n",
    "    # Overwrite the previous pickle and .run file with the new (accumulated) data variable\n",
    "#     with open(pickle_path, 'wb') as f_pickle:\n",
    "#         pickle.dump(data, f_pickle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run run_retrieval\n",
    "\n",
    "# '''\n",
    "# Jelinek-Mercer (explore different values of 𝛌 in the range [0.1, 0.5, 0.9]). [5 points]\n",
    "# Dirichlet Prior (explore different values of 𝛍 [500, 1000, 1500]). [5 points]\n",
    "# Absolute discounting (explore different values of 𝛅 in the range [0.1, 0.5, 0.9]). [5 points]\n",
    "# '''\n",
    "# import functools\n",
    "\n",
    "# jelinek_01 = (functools.partial(jelinek_mercer, lambd=0.1), 'jelinek_0.1')\n",
    "# jelinek_05 = (functools.partial(jelinek_mercer, lambd=0.5), 'jelinek_0.5')\n",
    "# jelinek_09 = (functools.partial(jelinek_mercer, lambd=0.9), 'jelinek_0.9')\n",
    "# dirichlet_500 = (functools.partial(dirichlet_prior_smoothing, mu=500), 'dirichlet_500')\n",
    "# dirichlet_1000 = (functools.partial(dirichlet_prior_smoothing, mu=1000), 'dirichlet_1000')\n",
    "# dirichlet_1500 = (functools.partial(dirichlet_prior_smoothing, mu=1500), 'dirichlet_1500')\n",
    "# absolute_01 = (functools.partial(absolute_discounting, delta=0.1), 'absolute_0.1')\n",
    "# absolute_05 = (functools.partial(absolute_discounting, delta=0.5), 'absolute_0.5')\n",
    "# absolute_09 = (functools.partial(absolute_discounting, delta=0.9), 'absolute_0.9')\n",
    "\n",
    "# smoothings_functions = [jelinek_01, jelinek_05, jelinek_09,\n",
    "#                         dirichlet_500,dirichlet_1000,dirichlet_1500,\n",
    "#                         absolute_01, absolute_05, absolute_09]\n",
    "\n",
    "# import cProfile, pstats\n",
    "# from io import StringIO\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "# for smoothing_func, label in smoothings_functions:\n",
    "#     run_retrieval(label, \n",
    "#                   functools.partial(log_multinomial_query_language_model, word_probability_func=smoothing_func), \n",
    "#                   \"Probabilistic\", validation_queries_ids)\n",
    "\n",
    "# pr.disable()\n",
    "# s = StringIO()\n",
    "# sortby = 'cumulative'\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "# ps.print_stats()\n",
    "# print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #!/usr/bin/env python\n",
    "# import subprocess\n",
    "# from collections import defaultdict \n",
    "\n",
    "# # Run evaluation bash script...\n",
    "# # subprocess.call([\"./assignment_evals.sh\"])\n",
    "\n",
    "\n",
    "# # ... And retrieve again\n",
    "# eval_data = defaultdict(list)\n",
    "\n",
    "# for file in os.listdir(\"run\"):\n",
    "#     if file[-4:] == \".txt\":\n",
    "#         with open(\"run/\" + file) as file:\n",
    "#             content = [line.strip().split() for line in file.readlines()]\n",
    "#             for metric, query, score in content:\n",
    "#                 eval_data[metric].append((query,score))\n",
    "                \n",
    "# # eval_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cProfile, pstats\n",
    "# from io import StringIO\n",
    "# import functools\n",
    "\n",
    "# print([id2token[x] for x in test_query if x > 0 ])\n",
    "\n",
    "# PLM_triangle = functools.partial(PLM_score_old, kernel_func=triangle_kernel, mu=1000)\n",
    "\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "# print(PLM_triangle(test_doc, test_query))\n",
    "\n",
    "# pr.disable()\n",
    "# s = StringIO()\n",
    "# sortby = 'cumulative'\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "# ps.print_stats()\n",
    "# print(s.getvalue())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Document and query share terms\n",
    "# test_query = tokenized_queries['52']\n",
    "# test_doc = 11\n",
    "\n",
    "# %time print(score_similarity(test_query, test_doc, weight_fn=tfidf, query_weight_fn=tfidf_query))\n",
    "# %time print(score_similarity(test_query, test_doc, weight_fn=BM25, query_weight_fn=BM25_query))\n",
    "# %time print(score_similarity(test_query, test_doc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# ext_doc_id, doc_token_ids = index.document(1)\n",
    "\n",
    "# # This contains the length of each document in the collection.\n",
    "# document_lengths\n",
    "\n",
    "# # This contains the number of unique terms per document in the collection.\n",
    "# unique_terms_per_document\n",
    "\n",
    "# # This contains the frequency in which the query term appears in all the documents\n",
    "# collection_frequencies[35]\n",
    "\n",
    "# # This contains the frequency in which the query term appears in a given document\n",
    "# inverted_index[880]\n",
    "\n",
    "# collection_frequencies[35]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Analysis of task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-20ee7d1a95b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m             \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m                 \u001b[0meval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 0)"
     ]
    }
   ],
   "source": [
    "# #!/usr/bin/env python\n",
    "# import subprocess\n",
    "# from collections import defaultdict \n",
    "\n",
    "# # Run evaluation bash script...\n",
    "# # subprocess.call([\"./assignment_evals.sh\"])\n",
    "\n",
    "\n",
    "# # ... And retrieve again\n",
    "# eval_data = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "# for file in os.listdir(\"run\"):\n",
    "#     if file[-4:] == \".txt\":\n",
    "#         model_name = file[:-4]\n",
    "#         with open(\"run/\" + file) as file:\n",
    "#             content = [line.strip().split() for line in file.readlines()]\n",
    "            \n",
    "#             if len(content[0]) != 3:\n",
    "#                 print(model_name)\n",
    "#             for metric, query, score in content:\n",
    "#                 eval_data[model_name][metric][query] =score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# print(eval_data['jelinek_0.1_val_queries_len_C_is_num_words']['recall_1000'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check which parameter values yield the highest values on the evaluation metrics for the language models\n",
    "\n",
    "We show the  metrics NDCG@10, MAP@1000, Precision@5 and Recall@1000 for 'all' queries. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model_names = [['jelinek_0.1_val_queries_len_C_is_num_words','lambda', '1', 'Jellinek-Mercer'], \n",
    "#                ['jelinek_0.5_val_queries_len_C_is_num_words','lambda','5','Jellinek-Mercer' ], \n",
    "#                ['jelinek_0.9_val_queries_len_C_is_num_words','lambda','9', 'Jellinek-Mercer'],\n",
    "#                ['dirichlet_500_val_queries_len_C_is_num_words','mu', '500','Dirichlet smoothing'],\n",
    "#                ['dirichlet_1000_val_queries_len_C_is_num_words','mu', '1000','Dirichlet smoothing'],\n",
    "#                ['dirichlet_1500_val_queries_len_C_is_num_words','mu', '1500', 'Dirichlet smoothing'],\n",
    "#                ['absolute_0.1_val_queries_len_C_is_num_words','delta','1', 'Absolute discounting'],\n",
    "#                ['absolute_0.5_val_queries_len_C_is_num_words','delta','5', 'Absolute discounting'],\n",
    "#                ['absolute_0.9_val_queries_len_C_is_num_words','delta','9', 'Absolute discounting']]\n",
    "\n",
    "# for model in model_names:\n",
    "#     print('With a %s of %s the %s had a NDCG@10 of %s, a MAP@1000 of %s a Precission @5 of %s and a Recall@1000 of %s'%(model[1], model[2], model[3],\n",
    "#                                                               eval_data[model[0]]['ndcg_cut_10']['all'],eval_data[model[0]]['map']['all'],\n",
    "#                                                             eval_data[model[0]]['P_5']['all'],eval_data[model[0]]['recall_1000']['all']))\n",
    "#     print()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seeing that for all models the metrics don't differ much when adjusting the parameters we looked at run files manually. We found a clear difference in the scores when adjusting the parameters, but the rankings were almost identical per model. \n",
    "\n",
    "For two of the three models there is a slight difference in NDCG@10. We consider this the most important metric because it takes into account the fact that ranking the first few documents right is more important than ranking later documents right. \n",
    "\n",
    "For Dirichlet smoothing we thus choose a mu of 500 and for Absolute discounting we choose a delta of 5.\n",
    "\n",
    "For Jellinek-Mercer we choose a lambda of 1. Note that all metrics for the three values of lambda are exactly the same and it seems to not matter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEWCAYAAABIVsEJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFCcQMzMrxQnEzMxKcQIxM7NS/j/dia3pcWz50wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11636e3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "absdisc_ndcg = [0.3662, 0.3889, 0.3754]\n",
    "absdisc_delta = [1, 5, 9]\n",
    "plt.scatter(absdisc_delta, absdisc_ndcg)\n",
    "plt.xlabel('Delta')\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.title('Absolute discounting: NDCG@10 for three different deltas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ndnD/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x128418f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "jelimerc_ndcg = [0.0504,0.0504,0.0504]\n",
    "jelimerc_lambda = [1,5,9]\n",
    "\n",
    "plt.scatter(jelimerc_lambda,jelimerc_ndcg)\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.title('Jellinek-Mercer: NDCG@10 for three different lambdas')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEWCAYAAABMoxE0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1088d3a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dirismooth_ndcg = [0.4055,0.4002,0.4026]\n",
    "dirismooth_mu = [500,1000,1500]\n",
    "\n",
    "plt.scatter(dirismooth_mu, dirismooth_ndcg)\n",
    "plt.xlabel('Mu')\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.title('Dirichlet: NDCG@10 for three different mus')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now run the language models again with their optimal parameters on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # run run_retrieval\n",
    "\n",
    "# '''\n",
    "# Jelinek-Mercer (explore different values of 𝛌 in the range [0.1, 0.5, 0.9]). [5 points]\n",
    "# Dirichlet Prior (explore different values of 𝛍 [500, 1000, 1500]). [5 points]\n",
    "# Absolute discounting (explore different values of 𝛅 in the range [0.1, 0.5, 0.9]). [5 points]\n",
    "# '''\n",
    "\n",
    "# best_smoothings_functions = [jelinek_01, dirichlet_500, absolute_05]\n",
    "\n",
    "# import cProfile, pstats\n",
    "# from io import StringIO\n",
    "# pr = cProfile.Profile()\n",
    "# pr.enable()\n",
    "\n",
    "# for smoothing_func, label in best_smoothings_functions:\n",
    "#     run_retrieval(label, \n",
    "#                   functools.partial(log_multinomial_query_language_model, word_probability_func=smoothing_func), \n",
    "#                   \"Probabilistic\", test_queries_ids)\n",
    "\n",
    "# pr.disable()\n",
    "# s = StringIO()\n",
    "# sortby = 'cumulative'\n",
    "# ps = pstats.Stats(pr, stream=s).sort_stats(sortby)\n",
    "# ps.print_stats()\n",
    "# print(s.getvalue())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Positional based language model (PLM)\n",
    "The PLM only has to be run on the top 1000 documents per query (ranked by the TF-IDF). We run it for all values of mu on the test queries instead of just for the mu of 1500. We do this to see if there might be a difference for this model or maybe if a subset is used. If a difference is found, we run the the other language models again, but just on these top-1000 queries TODO\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving using PLM_GAUS_1000\n",
      "queries:  1 / 30 \t this took:  16.9367778301239  seconds in total\n",
      "queries:  2 / 30 \t this took:  28.586894750595093  seconds in total\n",
      "queries:  3 / 30 \t this took:  44.93300676345825  seconds in total\n",
      "queries:  4 / 30 \t this took:  60.734511852264404  seconds in total\n",
      "queries:  5 / 30 \t this took:  72.6073956489563  seconds in total\n",
      "queries:  6 / 30 \t this took:  89.07094669342041  seconds in total\n",
      "queries:  7 / 30 \t this took:  106.19635677337646  seconds in total\n",
      "queries:  8 / 30 \t this took:  124.74101781845093  seconds in total\n",
      "queries:  9 / 30 \t this took:  142.2313196659088  seconds in total\n",
      "queries:  10 / 30 \t this took:  158.05508279800415  seconds in total\n",
      "queries:  11 / 30 \t this took:  174.45450067520142  seconds in total\n",
      "queries:  12 / 30 \t this took:  190.59350275993347  seconds in total\n",
      "queries:  13 / 30 \t this took:  207.04448580741882  seconds in total\n",
      "queries:  14 / 30 \t this took:  224.6468689441681  seconds in total\n",
      "queries:  15 / 30 \t this took:  241.1028847694397  seconds in total\n",
      "queries:  16 / 30 \t this took:  257.800096988678  seconds in total\n",
      "queries:  17 / 30 \t this took:  273.9699308872223  seconds in total\n",
      "queries:  18 / 30 \t this took:  290.0761528015137  seconds in total\n",
      "queries:  19 / 30 \t this took:  307.22798895835876  seconds in total\n",
      "queries:  20 / 30 \t this took:  324.05287766456604  seconds in total\n",
      "queries:  21 / 30 \t this took:  339.9572718143463  seconds in total\n",
      "queries:  22 / 30 \t this took:  357.35837268829346  seconds in total\n",
      "queries:  23 / 30 \t this took:  374.5380918979645  seconds in total\n",
      "queries:  24 / 30 \t this took:  392.5406777858734  seconds in total\n",
      "queries:  25 / 30 \t this took:  411.5680797100067  seconds in total\n",
      "queries:  26 / 30 \t this took:  427.7504098415375  seconds in total\n",
      "queries:  27 / 30 \t this took:  444.44914078712463  seconds in total\n",
      "queries:  28 / 30 \t this took:  461.13014578819275  seconds in total\n",
      "queries:  29 / 30 \t this took:  478.18822979927063  seconds in total\n",
      "queries:  30 / 30 \t this took:  500.2289779186249  seconds in total\n",
      "Retrieving using PLM_GAUS_1500\n",
      "queries:  1 / 30 \t this took:  16.499429941177368  seconds in total\n",
      "queries:  2 / 30 \t this took:  28.065737009048462  seconds in total\n",
      "queries:  3 / 30 \t this took:  44.40677809715271  seconds in total\n",
      "queries:  4 / 30 \t this took:  60.26047205924988  seconds in total\n",
      "queries:  5 / 30 \t this took:  72.3108868598938  seconds in total\n",
      "queries:  6 / 30 \t this took:  88.93180012702942  seconds in total\n",
      "queries:  7 / 30 \t this took:  106.20619702339172  seconds in total\n",
      "queries:  8 / 30 \t this took:  125.07663488388062  seconds in total\n",
      "queries:  9 / 30 \t this took:  142.395112991333  seconds in total\n",
      "queries:  10 / 30 \t this took:  158.2625229358673  seconds in total\n",
      "queries:  11 / 30 \t this took:  174.56211185455322  seconds in total\n",
      "queries:  12 / 30 \t this took:  190.9219880104065  seconds in total\n",
      "queries:  13 / 30 \t this took:  207.5502369403839  seconds in total\n",
      "queries:  14 / 30 \t this took:  226.17255187034607  seconds in total\n",
      "queries:  15 / 30 \t this took:  242.9650399684906  seconds in total\n",
      "queries:  16 / 30 \t this took:  259.6271538734436  seconds in total\n",
      "queries:  17 / 30 \t this took:  275.8781819343567  seconds in total\n",
      "queries:  18 / 30 \t this took:  293.1480801105499  seconds in total\n",
      "queries:  19 / 30 \t this took:  311.8703317642212  seconds in total\n",
      "queries:  20 / 30 \t this took:  330.458655834198  seconds in total\n",
      "queries:  21 / 30 \t this took:  346.2272708415985  seconds in total\n",
      "queries:  22 / 30 \t this took:  363.30480790138245  seconds in total\n",
      "queries:  23 / 30 \t this took:  380.48923897743225  seconds in total\n",
      "queries:  24 / 30 \t this took:  398.20536494255066  seconds in total\n",
      "queries:  25 / 30 \t this took:  417.60220098495483  seconds in total\n",
      "queries:  26 / 30 \t this took:  433.7569479942322  seconds in total\n",
      "queries:  27 / 30 \t this took:  450.2068290710449  seconds in total\n",
      "queries:  28 / 30 \t this took:  466.8076539039612  seconds in total\n",
      "queries:  29 / 30 \t this took:  483.896950006485  seconds in total\n",
      "queries:  30 / 30 \t this took:  506.12136483192444  seconds in total\n",
      "Retrieving using PLM_TRIANGLE_500\n",
      "queries:  1 / 30 \t this took:  13.43870997428894  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.611810207366943  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.97050905227661  seconds in total\n",
      "queries:  4 / 30 \t this took:  50.97815704345703  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.0826199054718  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.23677015304565  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.49877095222473  seconds in total\n",
      "queries:  8 / 30 \t this took:  102.19404006004333  seconds in total\n",
      "queries:  9 / 30 \t this took:  115.44963312149048  seconds in total\n",
      "queries:  10 / 30 \t this took:  128.49594593048096  seconds in total\n",
      "queries:  11 / 30 \t this took:  141.59075617790222  seconds in total\n",
      "queries:  12 / 30 \t this took:  154.72169303894043  seconds in total\n",
      "queries:  13 / 30 \t this took:  167.7404329776764  seconds in total\n",
      "queries:  14 / 30 \t this took:  180.85569214820862  seconds in total\n",
      "queries:  15 / 30 \t this took:  194.00114512443542  seconds in total\n",
      "queries:  16 / 30 \t this took:  207.1614809036255  seconds in total\n",
      "queries:  17 / 30 \t this took:  220.25164604187012  seconds in total\n",
      "queries:  18 / 30 \t this took:  233.40796208381653  seconds in total\n",
      "queries:  19 / 30 \t this took:  246.60126996040344  seconds in total\n",
      "queries:  20 / 30 \t this took:  259.7656660079956  seconds in total\n",
      "queries:  21 / 30 \t this took:  272.9385290145874  seconds in total\n",
      "queries:  22 / 30 \t this took:  286.3324820995331  seconds in total\n",
      "queries:  23 / 30 \t this took:  299.5614330768585  seconds in total\n",
      "queries:  24 / 30 \t this took:  312.9026710987091  seconds in total\n",
      "queries:  25 / 30 \t this took:  326.93135499954224  seconds in total\n",
      "queries:  26 / 30 \t this took:  340.381795167923  seconds in total\n",
      "queries:  27 / 30 \t this took:  353.42356419563293  seconds in total\n",
      "queries:  28 / 30 \t this took:  366.81469321250916  seconds in total\n",
      "queries:  29 / 30 \t this took:  379.98182702064514  seconds in total\n",
      "queries:  30 / 30 \t this took:  393.06689620018005  seconds in total\n",
      "Retrieving using PLM_TRIANGLE_1000\n",
      "queries:  1 / 30 \t this took:  13.28002381324768  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.33382296562195  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.5392119884491  seconds in total\n",
      "queries:  4 / 30 \t this took:  50.66194987297058  seconds in total\n",
      "queries:  5 / 30 \t this took:  61.901402711868286  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.03829884529114  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.31120777130127  seconds in total\n",
      "queries:  8 / 30 \t this took:  101.83268690109253  seconds in total\n",
      "queries:  9 / 30 \t this took:  115.14503288269043  seconds in total\n",
      "queries:  10 / 30 \t this took:  128.05869483947754  seconds in total\n",
      "queries:  11 / 30 \t this took:  141.1575198173523  seconds in total\n",
      "queries:  12 / 30 \t this took:  154.3288688659668  seconds in total\n",
      "queries:  13 / 30 \t this took:  167.3764967918396  seconds in total\n",
      "queries:  14 / 30 \t this took:  180.5890989303589  seconds in total\n",
      "queries:  15 / 30 \t this took:  193.73629069328308  seconds in total\n",
      "queries:  16 / 30 \t this took:  206.99871277809143  seconds in total\n",
      "queries:  17 / 30 \t this took:  220.10935401916504  seconds in total\n",
      "queries:  18 / 30 \t this took:  233.44229292869568  seconds in total\n",
      "queries:  19 / 30 \t this took:  246.69712781906128  seconds in total\n",
      "queries:  20 / 30 \t this took:  259.81269788742065  seconds in total\n",
      "queries:  21 / 30 \t this took:  272.8891599178314  seconds in total\n",
      "queries:  22 / 30 \t this took:  286.1569769382477  seconds in total\n",
      "queries:  23 / 30 \t this took:  299.3660087585449  seconds in total\n",
      "queries:  24 / 30 \t this took:  312.9123809337616  seconds in total\n",
      "queries:  25 / 30 \t this took:  326.68251490592957  seconds in total\n",
      "queries:  26 / 30 \t this took:  340.01880288124084  seconds in total\n",
      "queries:  27 / 30 \t this took:  353.1138107776642  seconds in total\n",
      "queries:  28 / 30 \t this took:  366.3527808189392  seconds in total\n",
      "queries:  29 / 30 \t this took:  379.58621287345886  seconds in total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries:  30 / 30 \t this took:  392.6300296783447  seconds in total\n",
      "Retrieving using PLM_TRIANGLE_1500\n",
      "queries:  1 / 30 \t this took:  14.081202983856201  seconds in total\n",
      "queries:  2 / 30 \t this took:  25.08604407310486  seconds in total\n",
      "queries:  3 / 30 \t this took:  38.21168112754822  seconds in total\n",
      "queries:  4 / 30 \t this took:  51.30946207046509  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.365756034851074  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.52635312080383  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.83703112602234  seconds in total\n",
      "queries:  8 / 30 \t this took:  102.82829093933105  seconds in total\n",
      "queries:  9 / 30 \t this took:  116.1963541507721  seconds in total\n",
      "queries:  10 / 30 \t this took:  129.13969707489014  seconds in total\n",
      "queries:  11 / 30 \t this took:  142.44656419754028  seconds in total\n",
      "queries:  12 / 30 \t this took:  155.61363911628723  seconds in total\n",
      "queries:  13 / 30 \t this took:  168.64543795585632  seconds in total\n",
      "queries:  14 / 30 \t this took:  181.75286388397217  seconds in total\n",
      "queries:  15 / 30 \t this took:  195.0093629360199  seconds in total\n",
      "queries:  16 / 30 \t this took:  208.14802312850952  seconds in total\n",
      "queries:  17 / 30 \t this took:  221.21819591522217  seconds in total\n",
      "queries:  18 / 30 \t this took:  234.38395500183105  seconds in total\n",
      "queries:  19 / 30 \t this took:  247.55645298957825  seconds in total\n",
      "queries:  20 / 30 \t this took:  260.7009310722351  seconds in total\n",
      "queries:  21 / 30 \t this took:  273.915207862854  seconds in total\n",
      "queries:  22 / 30 \t this took:  287.10709404945374  seconds in total\n",
      "queries:  23 / 30 \t this took:  300.4508259296417  seconds in total\n",
      "queries:  24 / 30 \t this took:  313.9539818763733  seconds in total\n",
      "queries:  25 / 30 \t this took:  327.8171429634094  seconds in total\n",
      "queries:  26 / 30 \t this took:  341.05485105514526  seconds in total\n",
      "queries:  27 / 30 \t this took:  354.2556369304657  seconds in total\n",
      "queries:  28 / 30 \t this took:  367.64834809303284  seconds in total\n",
      "queries:  29 / 30 \t this took:  380.96829414367676  seconds in total\n",
      "queries:  30 / 30 \t this took:  394.5495641231537  seconds in total\n",
      "Retrieving using PLM_COSINE_500\n",
      "queries:  1 / 30 \t this took:  13.568349123001099  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.554331064224243  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.842910051345825  seconds in total\n",
      "queries:  4 / 30 \t this took:  51.32930588722229  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.530999183654785  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.85590720176697  seconds in total\n",
      "queries:  7 / 30 \t this took:  89.4559121131897  seconds in total\n",
      "queries:  8 / 30 \t this took:  103.32558226585388  seconds in total\n",
      "queries:  9 / 30 \t this took:  116.89588618278503  seconds in total\n",
      "queries:  10 / 30 \t this took:  130.05910205841064  seconds in total\n",
      "queries:  11 / 30 \t this took:  143.3891270160675  seconds in total\n",
      "queries:  12 / 30 \t this took:  156.85690712928772  seconds in total\n",
      "queries:  13 / 30 \t this took:  170.02075290679932  seconds in total\n",
      "queries:  14 / 30 \t this took:  183.44378399848938  seconds in total\n",
      "queries:  15 / 30 \t this took:  196.83304619789124  seconds in total\n",
      "queries:  16 / 30 \t this took:  210.3537139892578  seconds in total\n",
      "queries:  17 / 30 \t this took:  223.7368290424347  seconds in total\n",
      "queries:  18 / 30 \t this took:  237.1196732521057  seconds in total\n",
      "queries:  19 / 30 \t this took:  250.5029582977295  seconds in total\n",
      "queries:  20 / 30 \t this took:  263.9645230770111  seconds in total\n",
      "queries:  21 / 30 \t this took:  277.25899505615234  seconds in total\n",
      "queries:  22 / 30 \t this took:  290.8244950771332  seconds in total\n",
      "queries:  23 / 30 \t this took:  304.3224561214447  seconds in total\n",
      "queries:  24 / 30 \t this took:  318.17103815078735  seconds in total\n",
      "queries:  25 / 30 \t this took:  332.34939193725586  seconds in total\n",
      "queries:  26 / 30 \t this took:  345.9002242088318  seconds in total\n",
      "queries:  27 / 30 \t this took:  359.1892309188843  seconds in total\n",
      "queries:  28 / 30 \t this took:  372.63372707366943  seconds in total\n",
      "queries:  29 / 30 \t this took:  386.1533441543579  seconds in total\n",
      "queries:  30 / 30 \t this took:  399.58008003234863  seconds in total\n",
      "Retrieving using PLM_COSINE_1000\n",
      "queries:  1 / 30 \t this took:  13.405877828598022  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.386918783187866  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.62730073928833  seconds in total\n",
      "queries:  4 / 30 \t this took:  50.82241487503052  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.30411696434021  seconds in total\n",
      "queries:  6 / 30 \t this took:  76.59165382385254  seconds in total\n",
      "queries:  7 / 30 \t this took:  91.74349689483643  seconds in total\n",
      "queries:  8 / 30 \t this took:  106.25415086746216  seconds in total\n",
      "queries:  9 / 30 \t this took:  120.32175588607788  seconds in total\n",
      "queries:  10 / 30 \t this took:  138.21303391456604  seconds in total\n",
      "queries:  11 / 30 \t this took:  155.51392793655396  seconds in total\n",
      "queries:  12 / 30 \t this took:  170.49173498153687  seconds in total\n",
      "queries:  13 / 30 \t this took:  184.10950684547424  seconds in total\n",
      "queries:  14 / 30 \t this took:  197.56838393211365  seconds in total\n",
      "queries:  15 / 30 \t this took:  210.8192539215088  seconds in total\n",
      "queries:  16 / 30 \t this took:  224.21868586540222  seconds in total\n",
      "queries:  17 / 30 \t this took:  237.50001668930054  seconds in total\n",
      "queries:  18 / 30 \t this took:  250.93728375434875  seconds in total\n",
      "queries:  19 / 30 \t this took:  264.49802803993225  seconds in total\n",
      "queries:  20 / 30 \t this took:  277.9099760055542  seconds in total\n",
      "queries:  21 / 30 \t this took:  291.1751048564911  seconds in total\n",
      "queries:  22 / 30 \t this took:  304.5864939689636  seconds in total\n",
      "queries:  23 / 30 \t this took:  318.02075481414795  seconds in total\n",
      "queries:  24 / 30 \t this took:  331.77396297454834  seconds in total\n",
      "queries:  25 / 30 \t this took:  345.84252166748047  seconds in total\n",
      "queries:  26 / 30 \t this took:  359.28068685531616  seconds in total\n",
      "queries:  27 / 30 \t this took:  372.51787066459656  seconds in total\n",
      "queries:  28 / 30 \t this took:  385.96743178367615  seconds in total\n",
      "queries:  29 / 30 \t this took:  399.4980857372284  seconds in total\n",
      "queries:  30 / 30 \t this took:  412.8822238445282  seconds in total\n",
      "Retrieving using PLM_COSINE_1500\n",
      "queries:  1 / 30 \t this took:  13.598269939422607  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.64061999320984  seconds in total\n",
      "queries:  3 / 30 \t this took:  38.06920027732849  seconds in total\n",
      "queries:  4 / 30 \t this took:  51.2345290184021  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.33941030502319  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.70861411094666  seconds in total\n",
      "queries:  7 / 30 \t this took:  89.30986499786377  seconds in total\n",
      "queries:  8 / 30 \t this took:  103.11082696914673  seconds in total\n",
      "queries:  9 / 30 \t this took:  116.79001712799072  seconds in total\n",
      "queries:  10 / 30 \t this took:  130.1751091480255  seconds in total\n",
      "queries:  11 / 30 \t this took:  143.66150403022766  seconds in total\n",
      "queries:  12 / 30 \t this took:  157.09551000595093  seconds in total\n",
      "queries:  13 / 30 \t this took:  170.43703031539917  seconds in total\n",
      "queries:  14 / 30 \t this took:  183.84877228736877  seconds in total\n",
      "queries:  15 / 30 \t this took:  197.23432326316833  seconds in total\n",
      "queries:  16 / 30 \t this took:  210.66037607192993  seconds in total\n",
      "queries:  17 / 30 \t this took:  223.853374004364  seconds in total\n",
      "queries:  18 / 30 \t this took:  237.4222071170807  seconds in total\n",
      "queries:  19 / 30 \t this took:  250.94725608825684  seconds in total\n",
      "queries:  20 / 30 \t this took:  264.57994508743286  seconds in total\n",
      "queries:  21 / 30 \t this took:  277.8884620666504  seconds in total\n",
      "queries:  22 / 30 \t this took:  291.6208481788635  seconds in total\n",
      "queries:  23 / 30 \t this took:  305.11318016052246  seconds in total\n",
      "queries:  24 / 30 \t this took:  318.8918342590332  seconds in total\n",
      "queries:  25 / 30 \t this took:  332.9313542842865  seconds in total\n",
      "queries:  26 / 30 \t this took:  346.4787931442261  seconds in total\n",
      "queries:  27 / 30 \t this took:  359.8960540294647  seconds in total\n",
      "queries:  28 / 30 \t this took:  373.44814801216125  seconds in total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries:  29 / 30 \t this took:  386.9829671382904  seconds in total\n",
      "queries:  30 / 30 \t this took:  400.4184761047363  seconds in total\n",
      "Retrieving using PLM_CIRCLE_500\n",
      "queries:  1 / 30 \t this took:  13.428132772445679  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.409255981445312  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.89886689186096  seconds in total\n",
      "queries:  4 / 30 \t this took:  51.24000692367554  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.36094903945923  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.65645289421082  seconds in total\n",
      "queries:  7 / 30 \t this took:  89.13651895523071  seconds in total\n",
      "queries:  8 / 30 \t this took:  103.067636013031  seconds in total\n",
      "queries:  9 / 30 \t this took:  116.56256580352783  seconds in total\n",
      "queries:  10 / 30 \t this took:  129.8915309906006  seconds in total\n",
      "queries:  11 / 30 \t this took:  143.27980589866638  seconds in total\n",
      "queries:  12 / 30 \t this took:  156.5774118900299  seconds in total\n",
      "queries:  13 / 30 \t this took:  169.8220911026001  seconds in total\n",
      "queries:  14 / 30 \t this took:  183.41684985160828  seconds in total\n",
      "queries:  15 / 30 \t this took:  196.62869095802307  seconds in total\n",
      "queries:  16 / 30 \t this took:  210.29644799232483  seconds in total\n",
      "queries:  17 / 30 \t this took:  223.69236087799072  seconds in total\n",
      "queries:  18 / 30 \t this took:  237.22457671165466  seconds in total\n",
      "queries:  19 / 30 \t this took:  250.7118890285492  seconds in total\n",
      "queries:  20 / 30 \t this took:  264.09215688705444  seconds in total\n",
      "queries:  21 / 30 \t this took:  277.47199177742004  seconds in total\n",
      "queries:  22 / 30 \t this took:  290.8956549167633  seconds in total\n",
      "queries:  23 / 30 \t this took:  304.3030118942261  seconds in total\n",
      "queries:  24 / 30 \t this took:  317.9755709171295  seconds in total\n",
      "queries:  25 / 30 \t this took:  332.19477581977844  seconds in total\n",
      "queries:  26 / 30 \t this took:  345.8493149280548  seconds in total\n",
      "queries:  27 / 30 \t this took:  359.5647978782654  seconds in total\n",
      "queries:  28 / 30 \t this took:  373.03008794784546  seconds in total\n",
      "queries:  29 / 30 \t this took:  386.4196810722351  seconds in total\n",
      "queries:  30 / 30 \t this took:  399.828736782074  seconds in total\n",
      "Retrieving using PLM_CIRCLE_1000\n",
      "queries:  1 / 30 \t this took:  13.505335092544556  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.40225601196289  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.611863136291504  seconds in total\n",
      "queries:  4 / 30 \t this took:  50.784271240234375  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.001988887786865  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.30671405792236  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.85490107536316  seconds in total\n",
      "queries:  8 / 30 \t this took:  102.73899507522583  seconds in total\n",
      "queries:  9 / 30 \t this took:  116.19523906707764  seconds in total\n",
      "queries:  10 / 30 \t this took:  129.4064531326294  seconds in total\n",
      "queries:  11 / 30 \t this took:  142.79348516464233  seconds in total\n",
      "queries:  12 / 30 \t this took:  156.17117595672607  seconds in total\n",
      "queries:  13 / 30 \t this took:  169.39318013191223  seconds in total\n",
      "queries:  14 / 30 \t this took:  182.87082815170288  seconds in total\n",
      "queries:  15 / 30 \t this took:  196.25918126106262  seconds in total\n",
      "queries:  16 / 30 \t this took:  209.79693913459778  seconds in total\n",
      "queries:  17 / 30 \t this took:  223.05907702445984  seconds in total\n",
      "queries:  18 / 30 \t this took:  236.5930519104004  seconds in total\n",
      "queries:  19 / 30 \t this took:  250.24263215065002  seconds in total\n",
      "queries:  20 / 30 \t this took:  263.63669300079346  seconds in total\n",
      "queries:  21 / 30 \t this took:  276.8662130832672  seconds in total\n",
      "queries:  22 / 30 \t this took:  290.38177514076233  seconds in total\n",
      "queries:  23 / 30 \t this took:  303.85486602783203  seconds in total\n",
      "queries:  24 / 30 \t this took:  317.49192094802856  seconds in total\n",
      "queries:  25 / 30 \t this took:  331.5416030883789  seconds in total\n",
      "queries:  26 / 30 \t this took:  345.00369811058044  seconds in total\n",
      "queries:  27 / 30 \t this took:  358.2122130393982  seconds in total\n",
      "queries:  28 / 30 \t this took:  371.8949031829834  seconds in total\n",
      "queries:  29 / 30 \t this took:  385.43588423728943  seconds in total\n",
      "queries:  30 / 30 \t this took:  398.7984142303467  seconds in total\n",
      "Retrieving using PLM_CIRCLE_1500\n",
      "queries:  1 / 30 \t this took:  13.380247831344604  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.439165115356445  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.75127100944519  seconds in total\n",
      "queries:  4 / 30 \t this took:  50.96787905693054  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.12352108955383  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.47650218009949  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.99535298347473  seconds in total\n",
      "queries:  8 / 30 \t this took:  102.83566904067993  seconds in total\n",
      "queries:  9 / 30 \t this took:  116.3976731300354  seconds in total\n",
      "queries:  10 / 30 \t this took:  129.8623650074005  seconds in total\n",
      "queries:  11 / 30 \t this took:  143.204185962677  seconds in total\n",
      "queries:  12 / 30 \t this took:  156.60858511924744  seconds in total\n",
      "queries:  13 / 30 \t this took:  169.82802295684814  seconds in total\n",
      "queries:  14 / 30 \t this took:  183.2874870300293  seconds in total\n",
      "queries:  15 / 30 \t this took:  196.56796503067017  seconds in total\n",
      "queries:  16 / 30 \t this took:  210.01738500595093  seconds in total\n",
      "queries:  17 / 30 \t this took:  223.26659488677979  seconds in total\n",
      "queries:  18 / 30 \t this took:  236.7415850162506  seconds in total\n",
      "queries:  19 / 30 \t this took:  250.35444593429565  seconds in total\n",
      "queries:  20 / 30 \t this took:  263.950679063797  seconds in total\n",
      "queries:  21 / 30 \t this took:  277.32467699050903  seconds in total\n",
      "queries:  22 / 30 \t this took:  290.798113822937  seconds in total\n",
      "queries:  23 / 30 \t this took:  304.4549069404602  seconds in total\n",
      "queries:  24 / 30 \t this took:  318.0315189361572  seconds in total\n",
      "queries:  25 / 30 \t this took:  332.0138990879059  seconds in total\n",
      "queries:  26 / 30 \t this took:  345.4225571155548  seconds in total\n",
      "queries:  27 / 30 \t this took:  358.76263213157654  seconds in total\n",
      "queries:  28 / 30 \t this took:  372.25128984451294  seconds in total\n",
      "queries:  29 / 30 \t this took:  385.69550490379333  seconds in total\n",
      "queries:  30 / 30 \t this took:  398.99905586242676  seconds in total\n",
      "Retrieving using PLM_PASSAGE_500\n",
      "queries:  1 / 30 \t this took:  13.531024932861328  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.436167001724243  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.69484901428223  seconds in total\n",
      "queries:  4 / 30 \t this took:  50.93174505233765  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.162395000457764  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.40952396392822  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.76016998291016  seconds in total\n",
      "queries:  8 / 30 \t this took:  102.26416897773743  seconds in total\n",
      "queries:  9 / 30 \t this took:  115.4537239074707  seconds in total\n",
      "queries:  10 / 30 \t this took:  128.65306901931763  seconds in total\n",
      "queries:  11 / 30 \t this took:  141.80485200881958  seconds in total\n",
      "queries:  12 / 30 \t this took:  155.02992391586304  seconds in total\n",
      "queries:  13 / 30 \t this took:  168.06591200828552  seconds in total\n",
      "queries:  14 / 30 \t this took:  181.15955781936646  seconds in total\n",
      "queries:  15 / 30 \t this took:  194.36814379692078  seconds in total\n",
      "queries:  16 / 30 \t this took:  207.66216397285461  seconds in total\n",
      "queries:  17 / 30 \t this took:  220.7411720752716  seconds in total\n",
      "queries:  18 / 30 \t this took:  233.87116289138794  seconds in total\n",
      "queries:  19 / 30 \t this took:  247.1720631122589  seconds in total\n",
      "queries:  20 / 30 \t this took:  260.25121212005615  seconds in total\n",
      "queries:  21 / 30 \t this took:  273.5187180042267  seconds in total\n",
      "queries:  22 / 30 \t this took:  286.6902668476105  seconds in total\n",
      "queries:  23 / 30 \t this took:  299.9835629463196  seconds in total\n",
      "queries:  24 / 30 \t this took:  313.4498770236969  seconds in total\n",
      "queries:  25 / 30 \t this took:  327.26923394203186  seconds in total\n",
      "queries:  26 / 30 \t this took:  340.6196618080139  seconds in total\n",
      "queries:  27 / 30 \t this took:  353.67821288108826  seconds in total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries:  28 / 30 \t this took:  367.12260007858276  seconds in total\n",
      "queries:  29 / 30 \t this took:  380.3246428966522  seconds in total\n",
      "queries:  30 / 30 \t this took:  393.1503369808197  seconds in total\n",
      "Retrieving using PLM_PASSAGE_1000\n",
      "queries:  1 / 30 \t this took:  13.609263181686401  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.6216299533844  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.80552911758423  seconds in total\n",
      "queries:  4 / 30 \t this took:  51.06812906265259  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.17457699775696  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.40572214126587  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.58088517189026  seconds in total\n",
      "queries:  8 / 30 \t this took:  102.11972117424011  seconds in total\n",
      "queries:  9 / 30 \t this took:  115.29817605018616  seconds in total\n",
      "queries:  10 / 30 \t this took:  128.27443099021912  seconds in total\n",
      "queries:  11 / 30 \t this took:  141.23812890052795  seconds in total\n",
      "queries:  12 / 30 \t this took:  154.42694091796875  seconds in total\n",
      "queries:  13 / 30 \t this took:  167.6305091381073  seconds in total\n",
      "queries:  14 / 30 \t this took:  180.71939730644226  seconds in total\n",
      "queries:  15 / 30 \t this took:  193.74273705482483  seconds in total\n",
      "queries:  16 / 30 \t this took:  207.145122051239  seconds in total\n",
      "queries:  17 / 30 \t this took:  220.3635630607605  seconds in total\n",
      "queries:  18 / 30 \t this took:  233.62737202644348  seconds in total\n",
      "queries:  19 / 30 \t this took:  246.85326433181763  seconds in total\n",
      "queries:  20 / 30 \t this took:  259.87700510025024  seconds in total\n",
      "queries:  21 / 30 \t this took:  273.11925625801086  seconds in total\n",
      "queries:  22 / 30 \t this took:  286.3467810153961  seconds in total\n",
      "queries:  23 / 30 \t this took:  299.6560571193695  seconds in total\n",
      "queries:  24 / 30 \t this took:  313.0324251651764  seconds in total\n",
      "queries:  25 / 30 \t this took:  326.8292090892792  seconds in total\n",
      "queries:  26 / 30 \t this took:  340.22189593315125  seconds in total\n",
      "queries:  27 / 30 \t this took:  353.1761691570282  seconds in total\n",
      "queries:  28 / 30 \t this took:  366.5611310005188  seconds in total\n",
      "queries:  29 / 30 \t this took:  379.70022916793823  seconds in total\n",
      "queries:  30 / 30 \t this took:  392.64685702323914  seconds in total\n",
      "Retrieving using PLM_PASSAGE_1500\n",
      "queries:  1 / 30 \t this took:  13.54132890701294  seconds in total\n",
      "queries:  2 / 30 \t this took:  24.599353075027466  seconds in total\n",
      "queries:  3 / 30 \t this took:  37.76606011390686  seconds in total\n",
      "queries:  4 / 30 \t this took:  51.017311096191406  seconds in total\n",
      "queries:  5 / 30 \t this took:  62.26316809654236  seconds in total\n",
      "queries:  6 / 30 \t this took:  75.43540716171265  seconds in total\n",
      "queries:  7 / 30 \t this took:  88.64944100379944  seconds in total\n",
      "queries:  8 / 30 \t this took:  101.98859906196594  seconds in total\n",
      "queries:  9 / 30 \t this took:  115.13071703910828  seconds in total\n",
      "queries:  10 / 30 \t this took:  128.2041962146759  seconds in total\n",
      "queries:  11 / 30 \t this took:  141.21685004234314  seconds in total\n",
      "queries:  12 / 30 \t this took:  154.68575596809387  seconds in total\n",
      "queries:  13 / 30 \t this took:  167.62878012657166  seconds in total\n",
      "queries:  14 / 30 \t this took:  180.7577259540558  seconds in total\n",
      "queries:  15 / 30 \t this took:  193.7528851032257  seconds in total\n",
      "queries:  16 / 30 \t this took:  207.67671918869019  seconds in total\n",
      "queries:  17 / 30 \t this took:  220.64242005348206  seconds in total\n",
      "queries:  18 / 30 \t this took:  233.73625707626343  seconds in total\n",
      "queries:  19 / 30 \t this took:  246.93768906593323  seconds in total\n",
      "queries:  20 / 30 \t this took:  260.02880692481995  seconds in total\n",
      "queries:  21 / 30 \t this took:  273.1676540374756  seconds in total\n",
      "queries:  22 / 30 \t this took:  286.47940611839294  seconds in total\n",
      "queries:  23 / 30 \t this took:  299.88537406921387  seconds in total\n",
      "queries:  24 / 30 \t this took:  313.25040316581726  seconds in total\n",
      "queries:  25 / 30 \t this took:  326.9968481063843  seconds in total\n",
      "queries:  26 / 30 \t this took:  340.1890571117401  seconds in total\n",
      "queries:  27 / 30 \t this took:  353.4140510559082  seconds in total\n",
      "queries:  28 / 30 \t this took:  366.71479296684265  seconds in total\n",
      "queries:  29 / 30 \t this took:  379.8609240055084  seconds in total\n",
      "queries:  30 / 30 \t this took:  392.8312199115753  seconds in total\n"
     ]
    }
   ],
   "source": [
    "# ## Generate all PLM validation Values\n",
    "import functools\n",
    "PLM_GAUS_500 = (functools.partial(PLM_score_old, kernel_func = gaussian_kernel, mu = 500), 'PLM_Gaussian_500')\n",
    "PLM_GAUS_1000 = (functools.partial(PLM_score_old, kernel_func = gaussian_kernel, mu = 1000), 'PLM_GAUS_1000')\n",
    "PLM_GAUS_1500 = (functools.partial(PLM_score_old, kernel_func = gaussian_kernel, mu = 1500), 'PLM_GAUS_1500')\n",
    "\n",
    "PLM_TRIANGLE_500 = (functools.partial(PLM_score_old, kernel_func = triangle_kernel, mu = 500), 'PLM_TRIANGLE_500')\n",
    "PLM_TRIANGLE_1000 = (functools.partial(PLM_score_old, kernel_func = triangle_kernel, mu = 1000), 'PLM_TRIANGLE_1000')\n",
    "PLM_TRIANGLE_1500 = (functools.partial(PLM_score_old, kernel_func = triangle_kernel, mu = 1500), 'PLM_TRIANGLE_1500')\n",
    "\n",
    "PLM_COSINE_500 = (functools.partial(PLM_score_old, kernel_func = cosine_kernel, mu = 500), 'PLM_COSINE_500')\n",
    "PLM_COSINE_1000 = (functools.partial(PLM_score_old, kernel_func = cosine_kernel, mu = 1000), 'PLM_COSINE_1000')\n",
    "PLM_COSINE_1500 = (functools.partial(PLM_score_old, kernel_func = cosine_kernel, mu = 1500), 'PLM_COSINE_1500')\n",
    "\n",
    "PLM_CIRCLE_500 = (functools.partial(PLM_score_old, kernel_func = circle_kernel, mu = 500), 'PLM_CIRCLE_500')\n",
    "PLM_CIRCLE_1000 = (functools.partial(PLM_score_old, kernel_func = circle_kernel, mu = 1000), 'PLM_CIRCLE_1000')\n",
    "PLM_CIRCLE_1500 = (functools.partial(PLM_score_old, kernel_func = circle_kernel, mu = 1500), 'PLM_CIRCLE_1500')\n",
    "\n",
    "PLM_PASSAGE_500 = (functools.partial(PLM_score_old, kernel_func = passage_kernel, mu = 500), 'PLM_PASSAGE_500')\n",
    "PLM_PASSAGE_1000 = (functools.partial(PLM_score_old, kernel_func = passage_kernel, mu = 1000), 'PLM_PASSAGE_1000')\n",
    "PLM_PASSAGE_1500 = (functools.partial(PLM_score_old, kernel_func = passage_kernel, mu = 1500), 'PLM_PASSAGE_1500')\n",
    "\n",
    "\n",
    "smoothings_functions = [PLM_GAUS_1000, PLM_GAUS_1500,\n",
    "                        PLM_TRIANGLE_500,PLM_TRIANGLE_1000,PLM_TRIANGLE_1500,\n",
    "                        PLM_COSINE_500, PLM_COSINE_1000, PLM_COSINE_1500,\n",
    "                        PLM_CIRCLE_500,PLM_CIRCLE_1000,PLM_CIRCLE_1500,\n",
    "                        PLM_PASSAGE_500,PLM_PASSAGE_1000,PLM_PASSAGE_1500]\n",
    "# smoothings_functions = [PLM_GAUS_1000, PLM_GAUS_1500]\n",
    "\n",
    "# print(test_queries_ids)\n",
    "for smoothing_func, label in smoothings_functions:\n",
    "    run_retrieval(label, smoothing_func, \"Probabilistic\", validation_queries_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test which PLM $\\mu$-kernel combination works best on the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['PLM', 'CIRCLE', '1000', '.txt']\n",
      "['PLM', 'CIRCLE', '1500', '.txt']\n",
      "['PLM', 'CIRCLE', '500', '.txt']\n",
      "['PLM', 'COSINE', '1000', '.txt']\n",
      "['PLM', 'COSINE', '1500', '.txt']\n",
      "['PLM', 'COSINE', '500', '.txt']\n",
      "['PLM', 'GAUS', '1000', '.txt']\n",
      "['PLM', 'GAUS', '1500', '.txt']\n",
      "['PLM', 'GAUS', '500', '.txt']\n",
      "['PLM', 'PASSAGE', '1000', '.txt']\n",
      "['PLM', 'PASSAGE', '1500', '.txt']\n",
      "['PLM', 'PASSAGE', '500', '.txt']\n",
      "['PLM', 'TRIANGLE', '1000', '.txt']\n",
      "['PLM', 'TRIANGLE', '1500', '.txt']\n",
      "['PLM', 'TRIANGLE', '500', '.txt']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# #!/usr/bin/env python\n",
    "# import subprocess\n",
    "# from collections import defaultdict \n",
    "\n",
    "# # Run evaluation bash script...\n",
    "# subprocess.call([\"./assignment_evals.sh\"])\n",
    "\n",
    "\n",
    "# # ... And retrieve again\n",
    "eval_data_PLM = defaultdict(lambda: defaultdict(dict))\n",
    "\n",
    "for file in os.listdir(\"new_plm_run\"):\n",
    "    if file[-4:] == \".txt\":\n",
    "        chunks = file.split('_')\n",
    "        if chunks[0] == 'PLM':\n",
    "            print(chunks)\n",
    "            kernel_name = chunks[1]+chunks[2]\n",
    "            with open(\"new_plm_run/\" + file) as file:\n",
    "                content = [line.strip().split() for line in file.readlines()]\n",
    "                for metric, query, score in content:\n",
    "                    eval_data_PLM[kernel_name][metric][query] =score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nREQklv8P7XBqoJB/YOYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d55fef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best kernel is the Gaussian kernel. The ndcg@10 for the gaussian kernels are: [0.3629, 0.3525, 0.3489]\n",
      "The best kernel-mu combination is thus a gaussian kernel with a mu of 500\n"
     ]
    }
   ],
   "source": [
    "PLM_mus = [500,1000,1500]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "passage_ndcg10 = [float(eval_data_PLM['PASSAGE500']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['PASSAGE1000']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['PASSAGE1500']['ndcg_cut_10']['all'])]\n",
    "\n",
    "gaussian_ndcg10 = [float(eval_data_PLM['GAUS500']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['GAUS1000']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['GAUS1500']['ndcg_cut_10']['all'])]\n",
    "\n",
    "triangle_ndcg10 = [float(eval_data_PLM['TRIANGLE500']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['TRIANGLE1000']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['TRIANGLE1500']['ndcg_cut_10']['all'])]\n",
    "\n",
    "cosine_ndcg10 = [float(eval_data_PLM['COSINE500']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['COSINE1000']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['COSINE1500']['ndcg_cut_10']['all'])]\n",
    "\n",
    "circle_ndcg10 = [float(eval_data_PLM['CIRCLE500']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['CIRCLE1000']['ndcg_cut_10']['all']),\n",
    "                 float(eval_data_PLM['CIRCLE1500']['ndcg_cut_10']['all'])]\n",
    "\n",
    "\n",
    "\n",
    "plt.plot(PLM_mus, passage_ndcg10, label = 'Passage')\n",
    "plt.plot(PLM_mus, gaussian_ndcg10, label = 'Gaussian')\n",
    "plt.plot(PLM_mus, triangle_ndcg10, label = 'Triangle')\n",
    "plt.plot(PLM_mus, cosine_ndcg10, label = 'Cosine')\n",
    "plt.plot(PLM_mus, circle_ndcg10, label = 'Circle')\n",
    "\n",
    "plt.xlabel('MU')\n",
    "plt.ylabel('NDCG@10')\n",
    "plt.title('PLM: NDCG@10 for all kernel-mu combinations')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "print('The best kernel is the Gaussian kernel. The ndcg@10 for the gaussian kernels are:', gaussian_ndcg10)\n",
    "print('The best kernel-mu combination is thus a gaussian kernel with a mu of 500')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PLM with gaussian kernel and mu of 500 on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving using PLM_Gaussian_500_test_\n",
      "queries:  1 / 120 \t this took:  17.859498023986816  seconds in total\n",
      "queries:  2 / 120 \t this took:  38.56201910972595  seconds in total\n",
      "queries:  3 / 120 \t this took:  56.512171030044556  seconds in total\n",
      "queries:  4 / 120 \t this took:  73.89987683296204  seconds in total\n",
      "queries:  5 / 120 \t this took:  90.69850587844849  seconds in total\n",
      "queries:  6 / 120 \t this took:  106.69898390769958  seconds in total\n",
      "queries:  7 / 120 \t this took:  122.41614103317261  seconds in total\n",
      "queries:  8 / 120 \t this took:  138.52820777893066  seconds in total\n",
      "queries:  9 / 120 \t this took:  160.24165511131287  seconds in total\n",
      "queries:  10 / 120 \t this took:  176.73927998542786  seconds in total\n",
      "queries:  11 / 120 \t this took:  193.71289610862732  seconds in total\n",
      "queries:  12 / 120 \t this took:  210.43624091148376  seconds in total\n",
      "queries:  13 / 120 \t this took:  226.49324107170105  seconds in total\n",
      "queries:  14 / 120 \t this took:  242.12651181221008  seconds in total\n",
      "queries:  15 / 120 \t this took:  258.035493850708  seconds in total\n",
      "queries:  16 / 120 \t this took:  273.81293392181396  seconds in total\n",
      "queries:  17 / 120 \t this took:  285.95375990867615  seconds in total\n",
      "queries:  18 / 120 \t this took:  302.1295518875122  seconds in total\n",
      "queries:  19 / 120 \t this took:  317.96710896492004  seconds in total\n",
      "queries:  20 / 120 \t this took:  334.7578718662262  seconds in total\n",
      "queries:  21 / 120 \t this took:  346.5366940498352  seconds in total\n",
      "queries:  22 / 120 \t this took:  362.81859517097473  seconds in total\n",
      "queries:  23 / 120 \t this took:  373.9845597743988  seconds in total\n",
      "queries:  24 / 120 \t this took:  392.6184649467468  seconds in total\n",
      "queries:  25 / 120 \t this took:  409.2537558078766  seconds in total\n",
      "queries:  26 / 120 \t this took:  427.13462710380554  seconds in total\n",
      "queries:  27 / 120 \t this took:  443.19904685020447  seconds in total\n",
      "queries:  28 / 120 \t this took:  460.84300994873047  seconds in total\n",
      "queries:  29 / 120 \t this took:  479.0970108509064  seconds in total\n",
      "queries:  30 / 120 \t this took:  495.5097301006317  seconds in total\n",
      "queries:  31 / 120 \t this took:  512.516951084137  seconds in total\n",
      "queries:  32 / 120 \t this took:  531.5953469276428  seconds in total\n",
      "queries:  33 / 120 \t this took:  548.2842178344727  seconds in total\n",
      "queries:  34 / 120 \t this took:  564.7369680404663  seconds in total\n",
      "queries:  35 / 120 \t this took:  580.5612709522247  seconds in total\n",
      "queries:  36 / 120 \t this took:  596.7432568073273  seconds in total\n",
      "queries:  37 / 120 \t this took:  618.6884899139404  seconds in total\n",
      "queries:  38 / 120 \t this took:  641.8830878734589  seconds in total\n",
      "queries:  39 / 120 \t this took:  667.1912009716034  seconds in total\n",
      "queries:  40 / 120 \t this took:  687.5908300876617  seconds in total\n",
      "queries:  41 / 120 \t this took:  706.3633959293365  seconds in total\n",
      "queries:  42 / 120 \t this took:  725.0149059295654  seconds in total\n",
      "queries:  43 / 120 \t this took:  743.268985748291  seconds in total\n",
      "queries:  44 / 120 \t this took:  760.8569281101227  seconds in total\n",
      "queries:  45 / 120 \t this took:  779.7751109600067  seconds in total\n",
      "queries:  46 / 120 \t this took:  797.5143208503723  seconds in total\n",
      "queries:  47 / 120 \t this took:  820.8440639972687  seconds in total\n",
      "queries:  48 / 120 \t this took:  837.71328997612  seconds in total\n",
      "queries:  49 / 120 \t this took:  858.158744096756  seconds in total\n",
      "queries:  50 / 120 \t this took:  877.0297977924347  seconds in total\n",
      "queries:  51 / 120 \t this took:  893.9218528270721  seconds in total\n",
      "queries:  52 / 120 \t this took:  909.9194188117981  seconds in total\n",
      "queries:  53 / 120 \t this took:  925.9822180271149  seconds in total\n",
      "queries:  54 / 120 \t this took:  942.8752310276031  seconds in total\n",
      "queries:  55 / 120 \t this took:  960.8757088184357  seconds in total\n",
      "queries:  56 / 120 \t this took:  978.2641637325287  seconds in total\n",
      "queries:  57 / 120 \t this took:  994.5141530036926  seconds in total\n",
      "queries:  58 / 120 \t this took:  1012.1073610782623  seconds in total\n",
      "queries:  59 / 120 \t this took:  1029.7123348712921  seconds in total\n",
      "queries:  60 / 120 \t this took:  1050.1461808681488  seconds in total\n",
      "queries:  61 / 120 \t this took:  1067.0090579986572  seconds in total\n",
      "queries:  62 / 120 \t this took:  1084.0480630397797  seconds in total\n",
      "queries:  63 / 120 \t this took:  1101.7021791934967  seconds in total\n",
      "queries:  64 / 120 \t this took:  1118.7937819957733  seconds in total\n",
      "queries:  65 / 120 \t this took:  1134.4340538978577  seconds in total\n",
      "queries:  66 / 120 \t this took:  1152.0877938270569  seconds in total\n",
      "queries:  67 / 120 \t this took:  1168.3238110542297  seconds in total\n",
      "queries:  68 / 120 \t this took:  1184.8182110786438  seconds in total\n",
      "queries:  69 / 120 \t this took:  1201.8820009231567  seconds in total\n",
      "queries:  70 / 120 \t this took:  1221.3570079803467  seconds in total\n",
      "queries:  71 / 120 \t this took:  1239.7620379924774  seconds in total\n",
      "queries:  72 / 120 \t this took:  1256.5221791267395  seconds in total\n",
      "queries:  73 / 120 \t this took:  1273.7975060939789  seconds in total\n",
      "queries:  74 / 120 \t this took:  1292.7731409072876  seconds in total\n",
      "queries:  75 / 120 \t this took:  1312.2744331359863  seconds in total\n",
      "queries:  76 / 120 \t this took:  1332.0706808567047  seconds in total\n",
      "queries:  77 / 120 \t this took:  1349.5879650115967  seconds in total\n",
      "queries:  78 / 120 \t this took:  1366.3610360622406  seconds in total\n",
      "queries:  79 / 120 \t this took:  1383.116536140442  seconds in total\n",
      "queries:  80 / 120 \t this took:  1416.1337201595306  seconds in total\n",
      "queries:  81 / 120 \t this took:  1447.6812479496002  seconds in total\n",
      "queries:  82 / 120 \t this took:  1470.038192987442  seconds in total\n",
      "queries:  83 / 120 \t this took:  1488.0523149967194  seconds in total\n",
      "queries:  84 / 120 \t this took:  1506.8283877372742  seconds in total\n",
      "queries:  85 / 120 \t this took:  1523.0707840919495  seconds in total\n",
      "queries:  86 / 120 \t this took:  1540.6123578548431  seconds in total\n",
      "queries:  87 / 120 \t this took:  1558.3674261569977  seconds in total\n",
      "queries:  88 / 120 \t this took:  1578.029783964157  seconds in total\n",
      "queries:  89 / 120 \t this took:  1594.2513070106506  seconds in total\n",
      "queries:  90 / 120 \t this took:  1613.080342054367  seconds in total\n",
      "queries:  91 / 120 \t this took:  1630.3454349040985  seconds in total\n",
      "queries:  92 / 120 \t this took:  1646.7837929725647  seconds in total\n",
      "queries:  93 / 120 \t this took:  1662.3140280246735  seconds in total\n",
      "queries:  94 / 120 \t this took:  1681.9417870044708  seconds in total\n",
      "queries:  95 / 120 \t this took:  1699.9864211082458  seconds in total\n",
      "queries:  96 / 120 \t this took:  1718.0397839546204  seconds in total\n",
      "queries:  97 / 120 \t this took:  1736.9323389530182  seconds in total\n",
      "queries:  98 / 120 \t this took:  1755.0420107841492  seconds in total\n",
      "queries:  99 / 120 \t this took:  1771.1087040901184  seconds in total\n",
      "queries:  100 / 120 \t this took:  1790.6445410251617  seconds in total\n",
      "queries:  101 / 120 \t this took:  1810.4962010383606  seconds in total\n",
      "queries:  102 / 120 \t this took:  1837.0382437705994  seconds in total\n",
      "queries:  103 / 120 \t this took:  1858.7372658252716  seconds in total\n",
      "queries:  104 / 120 \t this took:  1878.6465411186218  seconds in total\n",
      "queries:  105 / 120 \t this took:  1900.609913110733  seconds in total\n",
      "queries:  106 / 120 \t this took:  1919.5449109077454  seconds in total\n",
      "queries:  107 / 120 \t this took:  1940.7323870658875  seconds in total\n",
      "queries:  108 / 120 \t this took:  1956.8188140392303  seconds in total\n",
      "queries:  109 / 120 \t this took:  1972.747547864914  seconds in total\n",
      "queries:  110 / 120 \t this took:  1988.7149329185486  seconds in total\n",
      "queries:  111 / 120 \t this took:  2005.7500360012054  seconds in total\n",
      "queries:  112 / 120 \t this took:  2021.9083850383759  seconds in total\n",
      "queries:  113 / 120 \t this took:  2039.558897972107  seconds in total\n",
      "queries:  114 / 120 \t this took:  2056.536843061447  seconds in total\n",
      "queries:  115 / 120 \t this took:  2075.289571046829  seconds in total\n",
      "queries:  116 / 120 \t this took:  2095.582676887512  seconds in total\n",
      "queries:  117 / 120 \t this took:  2112.380786895752  seconds in total\n",
      "queries:  118 / 120 \t this took:  2128.51921582222  seconds in total\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "queries:  119 / 120 \t this took:  2145.181890964508  seconds in total\n",
      "queries:  120 / 120 \t this took:  2163.5937609672546  seconds in total\n"
     ]
    }
   ],
   "source": [
    "# ## Generate all PLM validation Values\n",
    "PLM_GAUS_500 = (functools.partial(PLM_score_old, kernel_func = gaussian_kernel, mu = 500), 'PLM_Gaussian_500_test_')\n",
    "\n",
    "smoothing_func = PLM_GAUS_500[0]\n",
    "label = PLM_GAUS_500[1]\n",
    "run_retrieval(label, smoothing_func, \"Probabilistic\", test_queries_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significance testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def create_datastructure(queryset, model = None):\n",
    "    '''\n",
    "    input: queryset: test or validation\n",
    "    optional input: create it for a specific model\n",
    "    output: dict of dict of dicts. All trec output for either the test or validation TREC results\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    \n",
    "    data = defaultdict(lambda: defaultdict(dict))\n",
    "    \n",
    "    if queryset == 'validation':\n",
    "        path = 'run/already_run'\n",
    "    if queryset == 'test':\n",
    "        path = 'run/TREC_results_on_test_set'\n",
    "\n",
    "    for file in os.listdir(path):\n",
    "        if file[-4:] == \".txt\":\n",
    "            chunks = file.split('_')\n",
    "            if queryset == 'test':\n",
    "                model_name = chunks[0]\n",
    "                print(model_name)\n",
    "            if queryset == 'validation':\n",
    "                if chunks[2] or chunks[3] == 'val':\n",
    "                    if chunks[0] == 'PLM':\n",
    "                        model_name = chunks[0]+chunks[1]+chunks[2]\n",
    "                    else:\n",
    "                        model_name = chunks[0]+chunks[1]\n",
    "                    model_name = chunks\n",
    "            \n",
    "            with open(path +'/'+ file) as file:\n",
    "                content = [line.strip().split() for line in file.readlines()]\n",
    "                for metric, query, score in content:\n",
    "                    data[model_name][metric][query] =float(score)\n",
    "\n",
    "\n",
    "    return data\n",
    "\n",
    "\n",
    "def pairwise_significance_tests(test_data, metric = None, alpha = 0.05):\n",
    "    '''\n",
    "    input: \n",
    "    - the TREC test values of all models.\n",
    "    \n",
    "    optional input: \n",
    "    - specific metric to perform the t-test on. If none => it will be performed on all\n",
    "    - the alpha value \n",
    "    \n",
    "    output: \n",
    "    - print statement(s) with t-tests\n",
    "    \n",
    "    '''\n",
    "     \n",
    "    # Correctig alpha because of the multiple comparison problem\n",
    "    m= 0 # number of hypothesis tests \n",
    "    \n",
    "    # First calculate m in the ugliest way thinkable\n",
    "    # Test all model combinations\n",
    "    models = ['BM25','TF-IDF', 'jelinek', 'dirichlet','absolute','PLM']\n",
    "    metrics = ['P_5','ndcg_cut_10','map','recall_1000']\n",
    "    tested_combinations = []\n",
    "    for metric in metrics:\n",
    "        for model_1 in models:\n",
    "            for model_2 in models:\n",
    "                if model_1 != model_2 and (model_1,model_2,metric) not in tested_combinations and (model_2,model_1,metric) not in tested_combinations:\n",
    "                    # append to tested combinations so it won't test the same thing twice\n",
    "                    tested_combinations.append((model_1,model_2,metric))\n",
    "                    tested_combinations.append((model_2,model_1,metric))\n",
    "                    \n",
    "                    # another hypothesis test\n",
    "                    m +=1\n",
    "    print('The number of hypotheses that will be tested is:', m)\n",
    "    \n",
    "    # Sidak correction (slightly less conservative, solves for family wise err rate)\n",
    "    sidak_alpha = 1-(1-alpha)**(1/m)\n",
    "    \n",
    "    # Bonferoni correction (free of dependence and distrivutional assumptions)\n",
    "    bonferoni_alpha = alpha/m \n",
    "    \n",
    "    alphas = [bonferoni_alpha, sidak_alpha]\n",
    "    # empty it again\n",
    "    tested_combinations = []\n",
    "\n",
    "    \n",
    "    # Test all model combinations\n",
    "    statistically_different = []\n",
    "    for metric in metrics:\n",
    "        for model_1 in models:\n",
    "            for model_2 in models:\n",
    "                if model_1 != model_2 and (model_1,model_2,metric) not in tested_combinations and (model_2,model_1,metric) not in tested_combinations:\n",
    "                    # don't use the 'all' test result\n",
    "                    print(metric, model_1, model_2)\n",
    "                    t_test = scipy.stats.ttest_rel(list(test_data[model_1][metric].values())[:-1],\n",
    "                                                            list(test_data[model_2][metric].values())[:-1])\n",
    "                    t_statistic = t_test[0]\n",
    "                    p_value = t_test[1]\n",
    "\n",
    "                    # append to tested combinations so it won't test the same thing twice\n",
    "                    tested_combinations.append((model_1,model_2,metric))\n",
    "                    tested_combinations.append((model_2,model_1,metric))\n",
    "\n",
    "                    # Print for the different corrections\n",
    "                    for num, corrected_alpha in enumerate(alphas):\n",
    "                        if num == 0:\n",
    "                            correction_method = 'Bonferoni'\n",
    "                        if num == 1:\n",
    "                            correction_method = 'Sidak'\n",
    "                        print()\n",
    "                        print(\"The t-test of %s and %s for the %s metric, conducted with an alpha of %f and a %s corrected alpha of %.4f has a p-value of: %.4f\"%(model_1, model_2, metric, float(alpha),correction_method, float(corrected_alpha), float(p_value)))\n",
    "\n",
    "                        if p_value < corrected_alpha:\n",
    "                            print('The means of these models for this metric are thus statistically significant different')\n",
    "                            statistically_different.append((model_1, model_2, metric, correction_method))\n",
    "                        else:\n",
    "                            print('The means of these models for this metric are thus NOT statistically significant different')\n",
    "\n",
    "\n",
    "    return statistically_different\n",
    "    \n",
    "def specific_query_testing():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF\n",
      "BM25\n",
      "PLM\n",
      "dirichlet\n",
      "jelinek\n",
      "absolute\n",
      "The number of hypotheses that will be tested is: 60\n",
      "P_5 BM25 TF-IDF\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.8871\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.8871\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "P_5 BM25 jelinek\n",
      "\n",
      "The t-test of BM25 and jelinek for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and jelinek for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 BM25 dirichlet\n",
      "\n",
      "The t-test of BM25 and dirichlet for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and dirichlet for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 BM25 absolute\n",
      "\n",
      "The t-test of BM25 and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 BM25 PLM\n",
      "\n",
      "The t-test of BM25 and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 TF-IDF jelinek\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 TF-IDF dirichlet\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 TF-IDF absolute\n",
      "\n",
      "The t-test of TF-IDF and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 TF-IDF PLM\n",
      "\n",
      "The t-test of TF-IDF and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 jelinek dirichlet\n",
      "\n",
      "The t-test of jelinek and dirichlet for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and dirichlet for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 jelinek absolute\n",
      "\n",
      "The t-test of jelinek and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 jelinek PLM\n",
      "\n",
      "The t-test of jelinek and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.1027\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of jelinek and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.1027\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "P_5 dirichlet absolute\n",
      "\n",
      "The t-test of dirichlet and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0708\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of dirichlet and absolute for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0708\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "P_5 dirichlet PLM\n",
      "\n",
      "The t-test of dirichlet and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of dirichlet and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "P_5 absolute PLM\n",
      "\n",
      "The t-test of absolute and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of absolute and PLM for the P_5 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 BM25 TF-IDF\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.9906\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.9906\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "ndcg_cut_10 BM25 jelinek\n",
      "\n",
      "The t-test of BM25 and jelinek for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and jelinek for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 BM25 dirichlet\n",
      "\n",
      "The t-test of BM25 and dirichlet for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and dirichlet for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 BM25 absolute\n",
      "\n",
      "The t-test of BM25 and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 BM25 PLM\n",
      "\n",
      "The t-test of BM25 and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 TF-IDF jelinek\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 TF-IDF dirichlet\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 TF-IDF absolute\n",
      "\n",
      "The t-test of TF-IDF and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 TF-IDF PLM\n",
      "\n",
      "The t-test of TF-IDF and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 jelinek dirichlet\n",
      "\n",
      "The t-test of jelinek and dirichlet for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and dirichlet for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 jelinek absolute\n",
      "\n",
      "The t-test of jelinek and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 jelinek PLM\n",
      "\n",
      "The t-test of jelinek and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.8351\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of jelinek and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.8351\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "ndcg_cut_10 dirichlet absolute\n",
      "\n",
      "The t-test of dirichlet and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.2069\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of dirichlet and absolute for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.2069\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "ndcg_cut_10 dirichlet PLM\n",
      "\n",
      "The t-test of dirichlet and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of dirichlet and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "ndcg_cut_10 absolute PLM\n",
      "\n",
      "The t-test of absolute and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of absolute and PLM for the ndcg_cut_10 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map BM25 TF-IDF\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.8906\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.8906\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "map BM25 jelinek\n",
      "\n",
      "The t-test of BM25 and jelinek for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and jelinek for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map BM25 dirichlet\n",
      "\n",
      "The t-test of BM25 and dirichlet for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and dirichlet for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map BM25 absolute\n",
      "\n",
      "The t-test of BM25 and absolute for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and absolute for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map BM25 PLM\n",
      "\n",
      "The t-test of BM25 and PLM for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and PLM for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map TF-IDF jelinek\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map TF-IDF dirichlet\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map TF-IDF absolute\n",
      "\n",
      "The t-test of TF-IDF and absolute for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and absolute for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map TF-IDF PLM\n",
      "\n",
      "The t-test of TF-IDF and PLM for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and PLM for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map jelinek dirichlet\n",
      "\n",
      "The t-test of jelinek and dirichlet for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and dirichlet for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map jelinek absolute\n",
      "\n",
      "The t-test of jelinek and absolute for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and absolute for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map jelinek PLM\n",
      "\n",
      "The t-test of jelinek and PLM for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.1301\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of jelinek and PLM for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.1301\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "map dirichlet absolute\n",
      "\n",
      "The t-test of dirichlet and absolute for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.1053\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of dirichlet and absolute for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.1053\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "map dirichlet PLM\n",
      "\n",
      "The t-test of dirichlet and PLM for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of dirichlet and PLM for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "map absolute PLM\n",
      "\n",
      "The t-test of absolute and PLM for the map metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of absolute and PLM for the map metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 BM25 TF-IDF\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.7602\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of BM25 and TF-IDF for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.7602\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "recall_1000 BM25 jelinek\n",
      "\n",
      "The t-test of BM25 and jelinek for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and jelinek for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 BM25 dirichlet\n",
      "\n",
      "The t-test of BM25 and dirichlet for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and dirichlet for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 BM25 absolute\n",
      "\n",
      "The t-test of BM25 and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 BM25 PLM\n",
      "\n",
      "The t-test of BM25 and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of BM25 and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 TF-IDF jelinek\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and jelinek for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 TF-IDF dirichlet\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and dirichlet for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 TF-IDF absolute\n",
      "\n",
      "The t-test of TF-IDF and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 TF-IDF PLM\n",
      "\n",
      "The t-test of TF-IDF and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of TF-IDF and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 jelinek dirichlet\n",
      "\n",
      "The t-test of jelinek and dirichlet for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and dirichlet for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 jelinek absolute\n",
      "\n",
      "The t-test of jelinek and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of jelinek and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 jelinek PLM\n",
      "\n",
      "The t-test of jelinek and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.4743\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of jelinek and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.4743\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "recall_1000 dirichlet absolute\n",
      "\n",
      "The t-test of dirichlet and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0457\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "\n",
      "The t-test of dirichlet and absolute for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0457\n",
      "The means of these models for this metric are thus NOT statistically significant different\n",
      "recall_1000 dirichlet PLM\n",
      "\n",
      "The t-test of dirichlet and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of dirichlet and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "recall_1000 absolute PLM\n",
      "\n",
      "The t-test of absolute and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Bonferoni corrected alpha of 0.0008 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n",
      "\n",
      "The t-test of absolute and PLM for the recall_1000 metric, conducted with an alpha of 0.050000 and a Sidak corrected alpha of 0.0009 has a p-value of: 0.0000\n",
      "The means of these models for this metric are thus statistically significant different\n"
     ]
    }
   ],
   "source": [
    "test_data = create_datastructure('test')\n",
    "# len(list(test_data['PLM']['P_5'].values())[:-1])\n",
    "statistically_different = pairwise_significance_tests(test_data, metric = None, alpha = 0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('BM25', 'jelinek', 'P_5', 'Bonferoni')\n",
      "('BM25', 'jelinek', 'P_5', 'Sidak')\n",
      "('BM25', 'dirichlet', 'P_5', 'Bonferoni')\n",
      "('BM25', 'dirichlet', 'P_5', 'Sidak')\n",
      "('BM25', 'absolute', 'P_5', 'Bonferoni')\n",
      "('BM25', 'absolute', 'P_5', 'Sidak')\n",
      "('BM25', 'PLM', 'P_5', 'Bonferoni')\n",
      "('BM25', 'PLM', 'P_5', 'Sidak')\n",
      "('TF-IDF', 'jelinek', 'P_5', 'Bonferoni')\n",
      "('TF-IDF', 'jelinek', 'P_5', 'Sidak')\n",
      "('TF-IDF', 'dirichlet', 'P_5', 'Bonferoni')\n",
      "('TF-IDF', 'dirichlet', 'P_5', 'Sidak')\n",
      "('TF-IDF', 'absolute', 'P_5', 'Bonferoni')\n",
      "('TF-IDF', 'absolute', 'P_5', 'Sidak')\n",
      "('TF-IDF', 'PLM', 'P_5', 'Bonferoni')\n",
      "('TF-IDF', 'PLM', 'P_5', 'Sidak')\n",
      "('jelinek', 'dirichlet', 'P_5', 'Bonferoni')\n",
      "('jelinek', 'dirichlet', 'P_5', 'Sidak')\n",
      "('jelinek', 'absolute', 'P_5', 'Bonferoni')\n",
      "('jelinek', 'absolute', 'P_5', 'Sidak')\n",
      "('dirichlet', 'PLM', 'P_5', 'Bonferoni')\n",
      "('dirichlet', 'PLM', 'P_5', 'Sidak')\n",
      "('absolute', 'PLM', 'P_5', 'Bonferoni')\n",
      "('absolute', 'PLM', 'P_5', 'Sidak')\n",
      "('BM25', 'jelinek', 'ndcg_cut_10', 'Bonferoni')\n",
      "('BM25', 'jelinek', 'ndcg_cut_10', 'Sidak')\n",
      "('BM25', 'dirichlet', 'ndcg_cut_10', 'Bonferoni')\n",
      "('BM25', 'dirichlet', 'ndcg_cut_10', 'Sidak')\n",
      "('BM25', 'absolute', 'ndcg_cut_10', 'Bonferoni')\n",
      "('BM25', 'absolute', 'ndcg_cut_10', 'Sidak')\n",
      "('BM25', 'PLM', 'ndcg_cut_10', 'Bonferoni')\n",
      "('BM25', 'PLM', 'ndcg_cut_10', 'Sidak')\n",
      "('TF-IDF', 'jelinek', 'ndcg_cut_10', 'Bonferoni')\n",
      "('TF-IDF', 'jelinek', 'ndcg_cut_10', 'Sidak')\n",
      "('TF-IDF', 'dirichlet', 'ndcg_cut_10', 'Bonferoni')\n",
      "('TF-IDF', 'dirichlet', 'ndcg_cut_10', 'Sidak')\n",
      "('TF-IDF', 'absolute', 'ndcg_cut_10', 'Bonferoni')\n",
      "('TF-IDF', 'absolute', 'ndcg_cut_10', 'Sidak')\n",
      "('TF-IDF', 'PLM', 'ndcg_cut_10', 'Bonferoni')\n",
      "('TF-IDF', 'PLM', 'ndcg_cut_10', 'Sidak')\n",
      "('jelinek', 'dirichlet', 'ndcg_cut_10', 'Bonferoni')\n",
      "('jelinek', 'dirichlet', 'ndcg_cut_10', 'Sidak')\n",
      "('jelinek', 'absolute', 'ndcg_cut_10', 'Bonferoni')\n",
      "('jelinek', 'absolute', 'ndcg_cut_10', 'Sidak')\n",
      "('dirichlet', 'PLM', 'ndcg_cut_10', 'Bonferoni')\n",
      "('dirichlet', 'PLM', 'ndcg_cut_10', 'Sidak')\n",
      "('absolute', 'PLM', 'ndcg_cut_10', 'Bonferoni')\n",
      "('absolute', 'PLM', 'ndcg_cut_10', 'Sidak')\n",
      "('BM25', 'jelinek', 'map', 'Bonferoni')\n",
      "('BM25', 'jelinek', 'map', 'Sidak')\n",
      "('BM25', 'dirichlet', 'map', 'Bonferoni')\n",
      "('BM25', 'dirichlet', 'map', 'Sidak')\n",
      "('BM25', 'absolute', 'map', 'Bonferoni')\n",
      "('BM25', 'absolute', 'map', 'Sidak')\n",
      "('BM25', 'PLM', 'map', 'Bonferoni')\n",
      "('BM25', 'PLM', 'map', 'Sidak')\n",
      "('TF-IDF', 'jelinek', 'map', 'Bonferoni')\n",
      "('TF-IDF', 'jelinek', 'map', 'Sidak')\n",
      "('TF-IDF', 'dirichlet', 'map', 'Bonferoni')\n",
      "('TF-IDF', 'dirichlet', 'map', 'Sidak')\n",
      "('TF-IDF', 'absolute', 'map', 'Bonferoni')\n",
      "('TF-IDF', 'absolute', 'map', 'Sidak')\n",
      "('TF-IDF', 'PLM', 'map', 'Bonferoni')\n",
      "('TF-IDF', 'PLM', 'map', 'Sidak')\n",
      "('jelinek', 'dirichlet', 'map', 'Bonferoni')\n",
      "('jelinek', 'dirichlet', 'map', 'Sidak')\n",
      "('jelinek', 'absolute', 'map', 'Bonferoni')\n",
      "('jelinek', 'absolute', 'map', 'Sidak')\n",
      "('dirichlet', 'PLM', 'map', 'Bonferoni')\n",
      "('dirichlet', 'PLM', 'map', 'Sidak')\n",
      "('absolute', 'PLM', 'map', 'Bonferoni')\n",
      "('absolute', 'PLM', 'map', 'Sidak')\n",
      "('BM25', 'jelinek', 'recall_1000', 'Bonferoni')\n",
      "('BM25', 'jelinek', 'recall_1000', 'Sidak')\n",
      "('BM25', 'dirichlet', 'recall_1000', 'Bonferoni')\n",
      "('BM25', 'dirichlet', 'recall_1000', 'Sidak')\n",
      "('BM25', 'absolute', 'recall_1000', 'Bonferoni')\n",
      "('BM25', 'absolute', 'recall_1000', 'Sidak')\n",
      "('BM25', 'PLM', 'recall_1000', 'Bonferoni')\n",
      "('BM25', 'PLM', 'recall_1000', 'Sidak')\n",
      "('TF-IDF', 'jelinek', 'recall_1000', 'Bonferoni')\n",
      "('TF-IDF', 'jelinek', 'recall_1000', 'Sidak')\n",
      "('TF-IDF', 'dirichlet', 'recall_1000', 'Bonferoni')\n",
      "('TF-IDF', 'dirichlet', 'recall_1000', 'Sidak')\n",
      "('TF-IDF', 'absolute', 'recall_1000', 'Bonferoni')\n",
      "('TF-IDF', 'absolute', 'recall_1000', 'Sidak')\n",
      "('TF-IDF', 'PLM', 'recall_1000', 'Bonferoni')\n",
      "('TF-IDF', 'PLM', 'recall_1000', 'Sidak')\n",
      "('jelinek', 'dirichlet', 'recall_1000', 'Bonferoni')\n",
      "('jelinek', 'dirichlet', 'recall_1000', 'Sidak')\n",
      "('jelinek', 'absolute', 'recall_1000', 'Bonferoni')\n",
      "('jelinek', 'absolute', 'recall_1000', 'Sidak')\n",
      "('dirichlet', 'PLM', 'recall_1000', 'Bonferoni')\n",
      "('dirichlet', 'PLM', 'recall_1000', 'Sidak')\n",
      "('absolute', 'PLM', 'recall_1000', 'Bonferoni')\n",
      "('absolute', 'PLM', 'recall_1000', 'Sidak')\n"
     ]
    }
   ],
   "source": [
    "for diff in statistically_different:\n",
    "    print(diff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Latent Semantic Models (LSMs) [15 points] ###\n",
    "\n",
    "In this task you will experiment with applying distributional semantics methods ([LSI](http://lsa3.colorado.edu/papers/JASIS.lsi.90.pdf) **[5 points]** and [LDA](https://www.cs.princeton.edu/~blei/papers/BleiNgJordan2003.pdf) **[5 points]**) for retrieval.\n",
    "\n",
    "You do not need to implement LSI or LDA on your own. Instead, you can use [gensim](http://radimrehurek.com/gensim/index.html). An example on how to integrate Pyndri with Gensim for word2vec can be found [here](https://github.com/cvangysel/pyndri/blob/master/examples/word2vec.py). For the remaining latent vector space models, you will need to implement connector classes (such as `IndriSentences`) by yourself.\n",
    "\n",
    "In order to use a latent semantic model for retrieval, you need to:\n",
    "   * build a representation of the query **q**,\n",
    "   * build a representation of the document **d**,\n",
    "   * calculate the similarity between **q** and **d** (e.g., cosine similarity, KL-divergence).\n",
    "     \n",
    "The exact implementation here depends on the latent semantic model you are using. \n",
    "   \n",
    "Each of these LSMs come with various hyperparameters to tune. Make a choice on the parameters, and explicitly mention the reasons that led you to these decisions. You can use the validation set to optimize hyper parameters you see fit; motivate your decisions. In addition, mention clearly how the query/document representations were constructed for each LSM and explain your choices.\n",
    "\n",
    "In this experiment, you will first obtain an initial top-1000 ranking for each query using TF-IDF in **Task 1**, and then re-rank the documents using the LSMs. Use TREC Eval to obtain the results and report on `NDCG@10`, Mean Average Precision (`MAP@1000`), `Precision@5` and `Recall@1000`.\n",
    "\n",
    "Perform significance testing **[5 points]** (similar as in Task 1) in the class of semantic matching methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import gensim.models\n",
    "import pickle\n",
    "from scipy.sparse import dok_matrix\n",
    "from scipy import spatial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the connector that ports Pyndri objects in a Gensim-friendly way.\n",
    "# Source: http://www.pythonexample.com/code/gensim-pyro/\n",
    "# Only updated return values from _doc2bow func; swapped key, value\n",
    "\n",
    "class LDALSISentences(gensim.interfaces.CorpusABC):\n",
    "    # Dictionary through task 2 = vocabulary\n",
    "    def __init__(self, index, dictionary, max_documents=None):\n",
    "        assert isinstance(index, pyndri.Index)\n",
    " \n",
    "        self.index = index\n",
    "        self.dictionary = dictionary\n",
    " \n",
    "        self.max_documents = max_documents\n",
    " \n",
    "    def _maximum_document(self):\n",
    "        if self.max_documents is None:\n",
    "            return self.index.maximum_document()\n",
    "        else:\n",
    "            return min(\n",
    "                self.max_documents + self.index.document_base(),\n",
    "                self.index.maximum_document())\n",
    " \n",
    "    def _doc2bow(self, doc):\n",
    " \n",
    "        di = collections.defaultdict(int)\n",
    " \n",
    "        for token_id in doc:\n",
    "            di[token_id] += 1\n",
    "    \n",
    "        return [(key, value) for key, value in di.items()]\n",
    " \n",
    "    def __iter__(self):\n",
    "\n",
    "        for int_doc_id in range(self.index.document_base(),\n",
    "                                self._maximum_document()):\n",
    "            ext_doc_id, tokens = self.index.document(int_doc_id)\n",
    " \n",
    "            tokens = tuple(\n",
    "                token_id\n",
    "                for token_id in tokens\n",
    "                if token_id > 0 and token_id in self.dictionary)\n",
    "\n",
    "            yield self._doc2bow(tokens)\n",
    " \n",
    "    def __len__(self):\n",
    "        return self._maximum_document() - self.index.document_base()\n",
    "    \n",
    "# Use this class if you want to create a gensim BOW representation, without passing a Pyndri index\n",
    "class MyConnecterForTop1000(gensim.interfaces.CorpusABC):\n",
    "    \n",
    "    \"\"\"\n",
    "    :index = a list of lists; where each list is a document\n",
    "    :dictionary = a dictionary of token2id and id2token\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, index, dictionary, max_documents=None):\n",
    "        \n",
    "        self.index = index\n",
    "        self.dictionary = dictionary\n",
    " \n",
    "        self.max_documents = max_documents\n",
    "    \n",
    "    def _doc2bow(self, doc):\n",
    " \n",
    "        di = collections.defaultdict(int)\n",
    " \n",
    "        for token_id in doc:\n",
    "            di[token_id] += 1\n",
    "    \n",
    "        return [(key, value) for key, value in di.items()]\n",
    "    \n",
    "    def __iter__(self):\n",
    "\n",
    "        for ext_doc_id, tokens in self.index:\n",
    " \n",
    "            tokens = tuple(\n",
    "                token_id\n",
    "                for token_id in tokens\n",
    "                if token_id > 0 and token_id in self.dictionary)\n",
    "\n",
    "            yield self._doc2bow(tokens)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.models\n",
    "\n",
    "    \n",
    "def LSI(corpus, dictionary, num_topics, store=False):\n",
    "    \n",
    "    lsi = gensim.models.lsimodel.LsiModel(corpus, id2word=dictionary, num_topics=num_topics)\n",
    "    \n",
    "    if store == True:\n",
    "        file_name = \"\"\n",
    "        full_file_name = file_name + \".p\"\n",
    "        \n",
    "        if full_file_name.exists():\n",
    "            print(\"This file already exists, pick another...\")\n",
    "            return\n",
    "        \n",
    "        pickle.dump(lsi, open(full_file_name, \"wb\"))\n",
    "        \n",
    "    return lsi\n",
    "\n",
    "\n",
    "def LDA(corpus, dictionary, num_topics, update_every=1, chunksize=500, passes=5, store=False):\n",
    "    \n",
    "    #print(\"Start training LDA model...\")\n",
    "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus, \n",
    "                                          id2word=dictionary, \n",
    "                                          num_topics=num_topics, \n",
    "                                          update_every=update_every, \n",
    "                                          chunksize=chunksize, \n",
    "                                          passes=passes)\n",
    "    \n",
    "    #print(\"Done training\")\n",
    "    \n",
    "    if store == True:\n",
    "        file_name = \"lda_model_tfidf100\"\n",
    "        full_file_name = file_name + \".p\"\n",
    "        \n",
    "        if full_file_name.exists():\n",
    "            print(\"This file already exists, pick another...\")\n",
    "            return\n",
    "        \n",
    "        try:    \n",
    "            pickle.dump(lda, open(full_file_name, \"wb\" ))\n",
    "        except:\n",
    "            print(\"Storing LDA model failed...\")\n",
    "        \n",
    "    return lda\n",
    "    \n",
    "def print_model_topics(model, nr_of_topics, words_per_topic):\n",
    "    print(model.print_topics(nr_of_topics, num_words=words_per_topic))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Import dependencies:\n",
    "\n",
    "# Step 0: Convert corpus into gensim dictionary object\n",
    "def init_corpus(store=False):\n",
    "    \n",
    "    #index = pyndri.Index('index/')\n",
    "    print(\"Building dictionary...\")\n",
    "    dictionary = pyndri.extract_dictionary(index)\n",
    "    \n",
    "    print(\"Building corpus...\")\n",
    "    corpus = LDALSISentences(index, dictionary)\n",
    "    \n",
    "    # For our own TF IDF, skip those doc ids that are not in given list.\n",
    "    print(\"Building TF-Corpus...\")\n",
    "    corpus = [doc for doc in corpus]\n",
    "    \n",
    "    print(\"Storing dictionary and corpus...\")\n",
    "    \n",
    "    if store == True:\n",
    "        pickle.dump(dictionary, open( \"dictionary.p\", \"wb\" ))\n",
    "        pickle.dump(corpus, open( \"corpus_tf.p\", \"wb\" ))\n",
    "    \n",
    "    return corpus, dictionary\n",
    "\n",
    "# Create our own TFIDF corpus based on task 1\n",
    "def transform_corpus(corpus, store=False):\n",
    "    print(\"Initializing TFIDF model...\")\n",
    "    tfidf_model = gensim.models.TfidfModel(corpus)\n",
    "    \n",
    "    print(\"Training TFIDF model...\")\n",
    "    corpus_tfidf = tfidf_model[corpus]\n",
    "    \n",
    "    if store == True:\n",
    "        pickle.dump(corpus_tfidf, open( \"corpus_tfidf.p\", \"wb\" ))\n",
    "    \n",
    "    return corpus_tfidf\n",
    "\n",
    "def load_from_pickle(corp_bow=\"\", q_bow=\"\", sem_model=\"\", sim_model=\"\"):\n",
    "    \n",
    "    corpus_bow, query_bows, semantic_model, similarity_model = None, None, None, None\n",
    "    \n",
    "    if corp_bow != \"\":\n",
    "        try:\n",
    "            print(\"Loading corpus BOW: %s...\".format(corp_bow))\n",
    "            with open(corp_bow, 'rb') as f:\n",
    "                corpus_bow = pickle.load(f)\n",
    "            print(\"Load successful\")\n",
    "        except:\n",
    "            print(\"Load unsuccesful\")\n",
    "            \n",
    "    if q_bow != \"\":\n",
    "        try:\n",
    "            print(\"Loading query BOW: %s...\".format(q_bow))\n",
    "            with open(q_bow, 'rb') as f:\n",
    "                query_bows = pickle.load(f)\n",
    "            print(\"Load successful\")\n",
    "        except:\n",
    "            print(\"Load unsuccessful\")\n",
    "    \n",
    "    if sem_model != \"\":\n",
    "        try:\n",
    "            print(\"Loading semantic model: %s...\".format(sem_model))\n",
    "            with open(sem_model, 'rb') as f:\n",
    "                semantic_model = pickle.load(f)\n",
    "            print(\"Load successful\")\n",
    "        except:\n",
    "            print(\"Load unsuccessful\")\n",
    "        \n",
    "    if sim_model != \"\":\n",
    "        try:\n",
    "            print(\"Loading similarity model: %s...\".format(sim_model))\n",
    "            with open(sem_model, 'rb') as f:\n",
    "                similarity_model = pickle.load(f)\n",
    "            print(\"Load successful\")\n",
    "        except:\n",
    "            print(\"Load unsuccessful\")\n",
    "        \n",
    "    return corpus_bow, query_bows, semantic_model, similarity_model\n",
    "\n",
    "\n",
    "# Step 1: Build a representation q of the query\n",
    "def query_representation(dictionary):\n",
    "    \n",
    "    with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "        queries = parse_topics([f_topics])\n",
    "        \n",
    "    tokenized_queries = {\n",
    "        query_id: [dictionary.translate_token(token)\n",
    "                   for token in index.tokenize(query_string)\n",
    "                   if dictionary.has_token(token)]\n",
    "        for query_id, query_string in queries.items()}\n",
    "\n",
    "    unique_query_ids = set(\n",
    "        query_term_id\n",
    "        for query_term_ids in tokenized_queries.values()\n",
    "        for query_term_id in query_term_ids)\n",
    "    \n",
    "    #print(tokenized_queries)\n",
    "    \n",
    "    query_bows = {}\n",
    "    \n",
    "    for query_nr in tokenized_queries.keys():\n",
    "        query_bows[query_nr] = dictionary.doc2bow(tokenized_queries[query_nr])\n",
    "    \n",
    "    return tokenized_queries, unique_query_ids, query_bows\n",
    "\n",
    "def init_similarity_model(model, corpus, num_features=300, store=False):\n",
    "    \n",
    "    sim_index = gensim.similarities.MatrixSimilarity(model[corpus], num_features=num_features)\n",
    "    \n",
    "    if store == True:\n",
    "        pickle.dump(sim_index, open(\"sim_index_lsi_tf.p\", \"wb\"))\n",
    "    \n",
    "    return sim_model\n",
    "    \n",
    "# Generates a weird error:\n",
    "def gensim_similarity(sim_model, model, query_bow, top_num=0):\n",
    "    \n",
    "    query_representation = model[query_bow]\n",
    "    \n",
    "    similarities = sim_model[query_representation]\n",
    "    \n",
    "    sorted_similarities = sorted(enumerate(similarities), key=lambda item: -item[1])\n",
    "    \n",
    "    if top_num != 0:\n",
    "        sorted_similarities = sorted_similarities[:top_n]\n",
    "\n",
    "    return sorted_similarities\n",
    "\n",
    "def get_tfidf_ranking_list():\n",
    "    top_1000_per_test_query = defaultdict(list)\n",
    "\n",
    "    with open('run/already_run/TF-IDF.run', 'r') as top_docs_per_query:\n",
    "        for line in top_docs_per_query:\n",
    "            query_id = line.split(' ')[0]\n",
    "            document_name = line.split(' ')[2]\n",
    "            top_1000_per_test_query[query_id].append(document_name)\n",
    "            \n",
    "    return top_1000_per_test_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.866684913635254\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "docid_2_docnr = {}\n",
    "for document_idx in range(index.document_base(), index.maximum_document()):\n",
    "    docid_2_docnr[index.document(document_idx)[0]] = document_idx\n",
    "    \n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries:  30\n",
      "Queries processed:  0  at  1.2175724506378174  seconds...\n",
      "Query nr  51 not in validation set, skipping...\n",
      "Query nr  52 not in validation set, skipping...\n",
      "Query nr  54 not in validation set, skipping...\n",
      "Query nr  55 not in validation set, skipping...\n",
      "Queries processed:  5  at  95.7053861618042  seconds...\n",
      "Query nr  56 not in validation set, skipping...\n",
      "Query nr  58 not in validation set, skipping...\n",
      "Query nr  59 not in validation set, skipping...\n",
      "Query nr  60 not in validation set, skipping...\n",
      "Queries processed:  10  at  204.19544506072998  seconds...\n",
      "Query nr  61 not in validation set, skipping...\n",
      "Query nr  62 not in validation set, skipping...\n",
      "Query nr  63 not in validation set, skipping...\n",
      "Query nr  64 not in validation set, skipping...\n",
      "Query nr  65 not in validation set, skipping...\n",
      "Queries processed:  15  at  204.2714216709137  seconds...\n",
      "Query nr  66 not in validation set, skipping...\n",
      "Query nr  67 not in validation set, skipping...\n",
      "Query nr  68 not in validation set, skipping...\n",
      "Query nr  70 not in validation set, skipping...\n",
      "Queries processed:  20  at  330.4071629047394  seconds...\n",
      "Query nr  71 not in validation set, skipping...\n",
      "Query nr  72 not in validation set, skipping...\n",
      "Query nr  73 not in validation set, skipping...\n",
      "Query nr  75 not in validation set, skipping...\n",
      "Queries processed:  25  at  456.7100751399994  seconds...\n",
      "Query nr  76 not in validation set, skipping...\n",
      "Query nr  77 not in validation set, skipping...\n",
      "Query nr  79 not in validation set, skipping...\n",
      "Query nr  80 not in validation set, skipping...\n",
      "Queries processed:  30  at  567.704583644867  seconds...\n",
      "Query nr  81 not in validation set, skipping...\n",
      "Query nr  82 not in validation set, skipping...\n",
      "Query nr  83 not in validation set, skipping...\n",
      "Query nr  84 not in validation set, skipping...\n",
      "Query nr  85 not in validation set, skipping...\n",
      "Queries processed:  35  at  567.7237646579742  seconds...\n",
      "Query nr  87 not in validation set, skipping...\n",
      "Query nr  88 not in validation set, skipping...\n",
      "Queries processed:  40  at  936.7380375862122  seconds...\n",
      "Query nr  91 not in validation set, skipping...\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-3b9d59038553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LSI_validation_topics_300\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-33-3b9d59038553>\u001b[0m in \u001b[0;36mtask_2\u001b[0;34m(model_name, num_topics_lsi, num_topics_lda, run, mode, retfidf)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Build LSI model for the query's corpus:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# The idea here is to narrow the topic-creating scope down to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mlsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsimodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics_lsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Build similarity matrix for LSI:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim-3.2.0-py3.6-linux-x86_64.egg/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, chunksize, decay, distributed, onepass, power_iters, extra_samples, dtype)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 343\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim-3.2.0-py3.6-linux-x86_64.egg/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36madd_documents\u001b[0;34m(self, corpus, chunksize, decay)\u001b[0m\n\u001b[1;32m    404\u001b[0m                         update = Projection(\n\u001b[1;32m    405\u001b[0m                             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextra_dims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextra_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 406\u001b[0;31m                             \u001b[0mpower_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_iters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    407\u001b[0m                         )\n\u001b[1;32m    408\u001b[0m                         \u001b[0;32mdel\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim-3.2.0-py3.6-linux-x86_64.egg/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, m, k, docs, use_svdlibc, power_iters, extra_dims, dtype)\u001b[0m\n\u001b[1;32m    126\u001b[0m                     \u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaxsize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                     \u001b[0mnum_terms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpower_iters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower_iters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m                     extra_dims=self.extra_dims, dtype=dtype)\n\u001b[0m\u001b[1;32m    129\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim-3.2.0-py3.6-linux-x86_64.egg/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36mstochastic_svd\u001b[0;34m(corpus, rank, num_terms, chunksize, extra_dims, power_iters, dtype, eps)\u001b[0m\n\u001b[1;32m    778\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mkeep\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0mu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Work here to load all documents\n",
    "def task_2(model_name, num_topics_lsi, num_topics_lda, run=False, mode=\"validation\", retfidf=False):\n",
    "    \n",
    "    if task_2 == False:\n",
    "        return\n",
    "    \n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "    \n",
    "    num_features_lsi = num_topics_lsi\n",
    "    num_features_lda = num_topics_lda\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fetch the top 1000 ranking using our own implementation of TF-IDF (task 1)\n",
    "    tfidf1000 = get_tfidf_ranking_list()\n",
    "\n",
    "    # Narrowing queries down to appropriate dataset:\n",
    "    if mode == \"validation\":\n",
    "        validation_set = {}\n",
    "        for query_nr in tfidf1000.keys():\n",
    "            if str(query_nr) in validation_queries_ids:\n",
    "                validation_set[query_nr] = tfidf1000[query_nr]\n",
    "        print(\"Number of queries: \", len(validation_set))\n",
    "    else:\n",
    "        test_set = {}\n",
    "        for query_nr in tfidf1000.keys():\n",
    "            if str(query_nr) in test_queries_ids:\n",
    "                validation_set[query_nr] = tfidf1000[query_nr]\n",
    "        print(\"Number of queries: \", len(test_set))\n",
    "    \n",
    "    # Get the dictionary of the entire index:\n",
    "    dictionary = pyndri.extract_dictionary(index)\n",
    "    \n",
    "    # Get the query bow representations:\n",
    "    _, _, query_bows = query_representation(dictionary)\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # For each query...\n",
    "    for i, query_nr in enumerate(query_bows.keys()):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(\"Queries processed: \", i, \" at \", time.time() - start_time, \" seconds...\")\n",
    "        \n",
    "        if mode == \"validation\":\n",
    "            if query_nr not in validation_set.keys():\n",
    "                print(\"Query nr \", query_nr, \"not in validation set, skipping...\")\n",
    "                continue \n",
    "            else:\n",
    "                original_ranking = validation_set[query_nr]\n",
    "        else:\n",
    "            if query_nr not in test_set.keys():\n",
    "                print(\"Query nr \", query_nr, \"not in test set, skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                original_ranking = test_set[query_nr]\n",
    "        \n",
    "        query_bow = query_bows[query_nr]\n",
    "        \n",
    "        # Get the list of documents that will build the corpus\n",
    "        doc_list = [index.document(docid_2_docnr[doc]) for doc in original_ranking]\n",
    "        \n",
    "        query_corpus = MyConnecterForTop1000(doc_list, dictionary)\n",
    "        \n",
    "        #TF-IDF transformation:\n",
    "        if retfidf == True:\n",
    "            query_corpus = transform_corpus(query_corpus)\n",
    "        \n",
    "        # Build LSI model for the query's corpus:\n",
    "        # The idea here is to narrow the topic-creating scope down to \n",
    "        lsi = gensim.models.lsimodel.LsiModel(query_corpus, id2word=dictionary, num_topics=num_topics_lsi)\n",
    "        \n",
    "        # Build similarity matrix for LSI:\n",
    "        sim_index = gensim.similarities.MatrixSimilarity(lsi[query_corpus], num_features=num_features_lsi)\n",
    "        \n",
    "        # Find LSI representation for query:\n",
    "        query_lsi = lsi[query_bow]\n",
    "\n",
    "        # Find similarities using the index matrix and the \n",
    "        similarities = sim_index[query_lsi]\n",
    "        \n",
    "        data[query_nr] = tuple(zip(similarities, original_ranking))\n",
    "        \n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "    \"\"\"\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "sims = task_2(\"LSI_validation_topics_300\", 300, 300, run=True, mode=\"validation\")\n",
    "print(\"4 done\")\n",
    "# sims = task_2(\"LSI_validation_topics_500\", 500, 500, run=True, mode=\"validation\")\n",
    "# print(\"5 done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries:  30\n",
      "Queries processed:  0  at  0.48021602630615234  seconds...\n",
      "Query nr  51 not in validation set, skipping...\n",
      "Query nr  52 not in validation set, skipping...\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-96-3b9d59038553>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LSI_validation_topics_300\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-96-3b9d59038553>\u001b[0m in \u001b[0;36mtask_2\u001b[0;34m(model_name, num_topics_lsi, num_topics_lda, run, mode, retfidf)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;31m# Build LSI model for the query's corpus:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# The idea here is to narrow the topic-creating scope down to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mlsi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlsimodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLsiModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics_lsi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Build similarity matrix for LSI:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/gensim/models/lsimodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, chunksize, decay, distributed, onepass, power_iters, extra_samples, dtype)\u001b[0m\n\u001b[1;32m    307\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocs_processed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pyndri/dictionary.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pyndri/dictionary.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "# Work here to load all documents\n",
    "def task_2(model_name, num_topics_lsi, num_topics_lda, run=False, mode=\"validation\", retfidf=False):\n",
    "    \n",
    "    if task_2 == False:\n",
    "        return\n",
    "    \n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "    \n",
    "    num_features_lsi = num_topics_lsi\n",
    "    num_features_lda = num_topics_lda\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fetch the top 1000 ranking using our own implementation of TF-IDF (task 1)\n",
    "    tfidf1000 = get_tfidf_ranking_list()\n",
    "\n",
    "    # Narrowing queries down to appropriate dataset:\n",
    "    if mode == \"validation\":\n",
    "        validation_set = {}\n",
    "        for query_nr in tfidf1000.keys():\n",
    "            if str(query_nr) in validation_queries_ids:\n",
    "                validation_set[query_nr] = tfidf1000[query_nr]\n",
    "        print(\"Number of queries: \", len(validation_set))\n",
    "    else:\n",
    "        test_set = {}\n",
    "        for query_nr in tfidf1000.keys():\n",
    "            if str(query_nr) in test_queries_ids:\n",
    "                validation_set[query_nr] = tfidf1000[query_nr]\n",
    "        print(\"Number of queries: \", len(test_set))\n",
    "    \n",
    "    # Get the dictionary of the entire index:\n",
    "    dictionary = pyndri.extract_dictionary(index)\n",
    "    \n",
    "    # Get the query bow representations:\n",
    "    _, _, query_bows = query_representation(dictionary)\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # For each query...\n",
    "    for i, query_nr in enumerate(query_bows.keys()):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(\"Queries processed: \", i, \" at \", time.time() - start_time, \" seconds...\")\n",
    "        \n",
    "        if mode == \"validation\":\n",
    "            if query_nr not in validation_set.keys():\n",
    "                print(\"Query nr \", query_nr, \"not in validation set, skipping...\")\n",
    "                continue \n",
    "            else:\n",
    "                original_ranking = validation_set[query_nr]\n",
    "        else:\n",
    "            if query_nr not in test_set.keys():\n",
    "                print(\"Query nr \", query_nr, \"not in test set, skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                original_ranking = test_set[query_nr]\n",
    "        \n",
    "        query_bow = query_bows[query_nr]\n",
    "        \n",
    "        # Get the list of documents that will build the corpus\n",
    "        doc_list = [index.document(docid_2_docnr[doc]) for doc in original_ranking]\n",
    "        \n",
    "        query_corpus = MyConnecterForTop1000(doc_list, dictionary)\n",
    "        \n",
    "        #TF-IDF transformation:\n",
    "        if retfidf == True:\n",
    "            query_corpus = transform_corpus(query_corpus)\n",
    "        \n",
    "        # Build LSI model for the query's corpus:\n",
    "        # The idea here is to narrow the topic-creating scope down to \n",
    "        lsi = gensim.models.lsimodel.LsiModel(query_corpus, id2word=dictionary, num_topics=num_topics_lsi)\n",
    "        \n",
    "        # Build similarity matrix for LSI:\n",
    "        sim_index = gensim.similarities.MatrixSimilarity(lsi[query_corpus], num_features=num_features_lsi)\n",
    "        \n",
    "        # Find LSI representation for query:\n",
    "        query_lsi = lsi[query_bow]\n",
    "\n",
    "        # Find similarities using the index matrix and the \n",
    "        similarities = sim_index[query_lsi]\n",
    "        \n",
    "        data[query_nr] = tuple(zip(similarities, original_ranking))\n",
    "        \n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "    \n",
    "    \"\"\"\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "    \"\"\"\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "sims = task_2(\"LSI_validation_topics_300\", 300, 300, run=True, mode=\"validation\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of queries:  30\n",
      "Queries processed:  0  at  0.4815385341644287  seconds...\n",
      "Query nr  51 not in validation set, skipping...\n",
      "Query nr  52 not in validation set, skipping...\n",
      "Start training LDA model...\n"
     ]
    },
    {
     "ename": "RecursionError",
     "evalue": "maximum recursion depth exceeded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRecursionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-e11da444a43b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m \u001b[0msims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask_2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LDA_validation_topics_100\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"1 done\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-63-e11da444a43b>\u001b[0m in \u001b[0;36mtask_2\u001b[0;34m(model_name, num_topics_lsi, num_topics_lda, run, mode)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Build LSI model for the query's corpus:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m         \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_corpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_topics_lda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Build similarity matrix for LSI:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-e5740bd7e2a8>\u001b[0m in \u001b[0;36mLDA\u001b[0;34m(corpus, dictionary, num_topics, update_every, chunksize, passes, store)\u001b[0m\n\u001b[1;32m     27\u001b[0m                                           \u001b[0mupdate_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mupdate_every\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m                                           \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                                           passes=passes)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Done training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/gensim/models/ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pyndri/dictionary.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "... last 1 frames repeated, from the frame below ...\n",
      "\u001b[0;32m~/miniconda3/lib/python3.6/site-packages/pyndri/dictionary.py\u001b[0m in \u001b[0;36mkeys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0miterkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRecursionError\u001b[0m: maximum recursion depth exceeded"
     ]
    }
   ],
   "source": [
    "# Work here to load all documents\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format='%(levelname)s : %(message)s', level=logging.INFO)\n",
    "logging.root.level = logging.INFO\n",
    "\n",
    "def task_2(model_name, num_topics_lsi, num_topics_lda, run=False, mode=\"validation\"):\n",
    "    \n",
    "    if task_2 == False:\n",
    "        return\n",
    "    \n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "    \n",
    "    num_features_lsi = num_topics_lsi\n",
    "    num_features_lda = num_topics_lda\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Fetch the top 1000 ranking using our own implementation of TF-IDF (task 1)\n",
    "    tfidf1000 = get_tfidf_ranking_list()\n",
    "\n",
    "    # Narrowing queries down to appropriate dataset:\n",
    "    if mode == \"validation\":\n",
    "        validation_set = {}\n",
    "        for query_nr in tfidf1000.keys():\n",
    "            if str(query_nr) in validation_queries_ids:\n",
    "                validation_set[query_nr] = tfidf1000[query_nr]\n",
    "        print(\"Number of queries: \", len(validation_set))\n",
    "    else:\n",
    "        test_set = {}\n",
    "        for query_nr in tfidf1000.keys():\n",
    "            if str(query_nr) in test_queries_ids:\n",
    "                validation_set[query_nr] = tfidf1000[query_nr]\n",
    "        print(\"Number of queries: \", len(test_set))\n",
    "    \n",
    "    # Get the dictionary of the entire index:\n",
    "    dictionary = pyndri.extract_dictionary(index)\n",
    "    \n",
    "    # Get the query bow representations:\n",
    "    _, _, query_bows = query_representation(dictionary)\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # For each query...\n",
    "    for i, query_nr in enumerate(query_bows.keys()):\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(\"Queries processed: \", i, \" at \", time.time() - start_time, \" seconds...\")\n",
    "        \n",
    "        if mode == \"validation\":\n",
    "            if query_nr not in validation_set.keys():\n",
    "                #print(\"Query nr \", query_nr, \"not in validation set, skipping...\")\n",
    "                continue \n",
    "            else:\n",
    "                original_ranking = validation_set[query_nr]\n",
    "        else:\n",
    "            if query_nr not in test_set.keys():\n",
    "                #print(\"Query nr \", query_nr, \"not in test set, skipping...\")\n",
    "                continue\n",
    "            else:\n",
    "                original_ranking = test_set[query_nr]\n",
    "        \n",
    "        query_bow = query_bows[query_nr]\n",
    "        \n",
    "        # Get the list of documents that will build the corpus\n",
    "        doc_list = [index.document(docid_2_docnr[doc]) for doc in original_ranking]\n",
    "        \n",
    "        query_corpus = MyConnecterForTop1000(doc_list, dictionary)\n",
    "        \n",
    "        # Build LSI model for the query's corpus:\n",
    "        lda = LDA(query_corpus, dictionary, num_topics=num_topics_lda, update_every=1, chunksize=500, passes=5)\n",
    "        \n",
    "        # Build similarity matrix for LSI:\n",
    "        sim_index = gensim.similarities.MatrixSimilarity(lda[query_corpus], num_features=num_features_lda)\n",
    "        \n",
    "        # Find LSI representation for query:\n",
    "        query_lda = lda[query_bow]\n",
    "\n",
    "        # Find similarities using the index matrix and the \n",
    "        similarities = sim_index[query_lda]\n",
    "        \n",
    "        data[query_nr] = tuple(zip(similarities, original_ranking))\n",
    "        \n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "    \n",
    "    return data\n",
    "\n",
    "sims = task_2(\"LDA_validation_topics_100\", 100, 100, run=True, mode=\"validation\")\n",
    "print(\"1 done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3:  Word embeddings for ranking [20 points] (open-ended) ###\n",
    "\n",
    "First create word embeddings on the corpus we provided using [word2vec](http://arxiv.org/abs/1411.2738) -- [gensim implementation](https://radimrehurek.com/gensim/models/word2vec.html). You should extract the indexed documents using pyndri and provide them to gensim for training a model (see example [here](https://github.com/nickvosk/pyndri/blob/master/examples/word2vec.py)).\n",
    "   \n",
    "This is an open-ended task. It is left up you to decide how you will combine word embeddings to derive query and document representations. Note that since we provide the implementation for training word2vec, you will be graded based on your creativity on combining word embeddings for building query and document representations.\n",
    "\n",
    "Note: If you want to experiment with pre-trained word embeddings on a different corpus, you can use the word embeddings we provide alongside the assignment (./data/reduced_vectors_google.txt.tar.gz). These are the [google word2vec word embeddings](https://code.google.com/archive/p/word2vec/), reduced to only the words that appear in the document collection we use in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyndri.compat\n",
    "import copy\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from scipy import spatial\n",
    "\n",
    "def build_w2v_model(file=\"\", train=False, epochs=5):\n",
    "    \n",
    "    if train == True:\n",
    "        word2vec = gensim.models.Word2Vec(\n",
    "        size=300,  # Embedding size\n",
    "        window=5,  # One-sided window size\n",
    "        sg=True,  # Skip-gram.\n",
    "        min_count=5,  # Minimum word frequency.\n",
    "        sample=1e-3,  # Sub-sample threshold.\n",
    "        hs=False,  # Hierarchical softmax.\n",
    "        negative=10,  # Number of negative examples.\n",
    "        iter=1,  # Number of iterations.\n",
    "        workers=8,  # Number of workers.\n",
    "    )\n",
    "\n",
    "        print(\"Fetching dictionary...\")\n",
    "        dictionary = pyndri.extract_dictionary(index)\n",
    "\n",
    "        print(\"Fetching sentences...\")\n",
    "        sentences = pyndri.compat.IndriSentences(index, dictionary)\n",
    "\n",
    "        print(\"building vectors...\")\n",
    "        %time word2vec.build_vocab(sentences, trim_rule=None)\n",
    "\n",
    "        print(\"Training...\")\n",
    "        w2v_models = [word2vec]\n",
    "\n",
    "        N_EPOCHS = epochs\n",
    "\n",
    "        for epoch in range(N_EPOCHS):\n",
    "            print('Epoch ', epoch)\n",
    "\n",
    "            w2v_model = copy.deepcopy(w2v_models[-1])\n",
    "            w2v_model.train(sentences, total_examples=word2vec.corpus_count, epochs=1)\n",
    "\n",
    "            w2v_models.append(w2v_model)\n",
    "        \n",
    "    else:\n",
    "        if file != \"\":\n",
    "            with open(file, 'rb') as f:\n",
    "                w2v_model = pickle.load(f)\n",
    "        else:\n",
    "            print(\"Enter file name or train the model (i.e set train=True)\")\n",
    "            return None\n",
    "    \n",
    "    return w2v_model\n",
    "        \n",
    "        \n",
    "def build_query_vectors(word2vec, dictionary, mode=\"validation\"):\n",
    "    \n",
    "    dictionary = pyndri.extract_dictionary(index)\n",
    "    \n",
    "    with open('./ap_88_89/topics_title', 'r') as f_topics:\n",
    "        queries = parse_topics([f_topics])\n",
    "        \n",
    "    tokenized_queries = {\n",
    "        query_id: [token\n",
    "                   for token in index.tokenize(query_string)\n",
    "                   if dictionary.has_token(token)]\n",
    "        for query_id, query_string in queries.items()}\n",
    "    \n",
    "    not_found = []\n",
    "    query2vec = {}\n",
    "    for query in tokenized_queries.keys():\n",
    "        words = np.array(tokenized_queries[query])\n",
    "        \n",
    "        embeddings = []\n",
    "        for word in words:\n",
    "            try:\n",
    "                embeddings.append(word2vec.wv[word])\n",
    "            except:\n",
    "                not_found.append(word)\n",
    "        \n",
    "        query2vec[query] = np.average(embeddings, axis=0)\n",
    "        \n",
    "    return query2vec, not_found\n",
    "\n",
    "def build_doc_vectors(w2v, sentences, not_found=[], mode=\"validation\"):\n",
    "    \n",
    "    doc2vec = {}\n",
    "    \n",
    "    for i, sentence in enumerate(sentences):\n",
    "        if i % 50000 == 0:\n",
    "            print(i, \"sentences processed\")\n",
    "        \n",
    "        embeddings = []\n",
    "        for word in sentence:\n",
    "            try:\n",
    "                embeddings.append(word2vec.wv[word])\n",
    "            except:\n",
    "                not_found.append(word)\n",
    "                \n",
    "        doc2vec[index.document(i + 1)[0]] = np.average(embeddings, axis=0)\n",
    " \n",
    "    return doc2vec, not_found\n",
    "\n",
    "def get_ranking(model_name, query2vec, doc2vec, mode=\"validation\"):\n",
    "    \n",
    "    ranking_by_query = {}\n",
    "    \n",
    "    if mode == \"validation\":\n",
    "        queries = [query for query in query2vec.keys() if query in validation_queries_ids]\n",
    "    else:\n",
    "        queries = [query for query in query2vec.keys() if query in test_queries_ids]\n",
    "        \n",
    "    issues = []\n",
    "    ranking = defaultdict(list)\n",
    "    for i, query in enumerate(queries):\n",
    "        print(\"Query nr\", i, \"/\", len(queries), )\n",
    "        q_embedding = query2vec[query]\n",
    "        \n",
    "        for document in doc2vec.keys():\n",
    "            d_embedding = doc2vec[document]\n",
    "            if d_embedding.shape == (300,):\n",
    "                score = 1 - spatial.distance.cosine(q_embedding, d_embedding)\n",
    "            else:\n",
    "                issues.append(document)\n",
    "                score = 0.0\n",
    "            \n",
    "            ranking[query].append((score, document))\n",
    "\n",
    "    run_out_path = '{}.run'.format(model_name)\n",
    "\n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=ranking,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)\n",
    "    \n",
    "    return ranking, issues\n",
    "\n",
    "%time w2v_model2 = build_w2v_model(file=\"self_trained_word2vec.pickle\")\n",
    "\n",
    "#%time query2vec, not_found = build_query_vectors(w2v_model, dictionary)\n",
    "\n",
    "#%time doc2vec, words_not_found = build_doc_vectors(w2v_model, sentences, not_found=not_found)\n",
    "\n",
    "#%time ranking, doc_issues = get_ranking(query2vec, doc2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'AP880326-0192',\n",
       " 'AP880729-0280',\n",
       " 'AP880920-0244',\n",
       " 'AP880929-0045',\n",
       " 'AP881003-0308',\n",
       " 'AP881010-0249',\n",
       " 'AP881012-0242',\n",
       " 'AP881023-0111',\n",
       " 'AP881023-0114',\n",
       " 'AP881103-0278',\n",
       " 'AP881230-0234'}"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "set(issues)\n",
    "# Somehow words were not found in the w2v model... These are the first 10 (use for verifying fix):\n",
    "#print(\"Total words not found:\", len(list(set(words_not_found))))\n",
    "#list(set(words_not_found))[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Learning to rank (LTR) [15 points] (open-ended) ###\n",
    "\n",
    "In this task you will get an introduction into learning to rank for information retrieval.\n",
    "\n",
    "You can explore different ways for devising features for the model. Obviously, you can use the retrieval methods you implemented in Task 1, Task 2 and Task 3 as features. Think about other features you can use (e.g. query/document length). Creativity on devising new features and providing motivation for them will be taken into account when grading.\n",
    "\n",
    "For every query, first create a document candidate set using the top-1000 documents using TF-IDF, and subsequently compute features given a query and a document. Note that the feature values of different retrieval methods are likely to be distributed differently.\n",
    "\n",
    "You are adviced to start some pointwise learning to rank algorithm e.g. logistic regression, implemented in [scikit-learn](http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html).\n",
    "Train your LTR model using 10-fold cross validation on the test set. More advanced learning to rank algorithms will be appreciated when grading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possible features:\n",
    "# - Query/Document Feature\n",
    "#  - TF/IDF - done\n",
    "#  - BM25 - done \n",
    "#  - PLM-score - done\n",
    "#   - Positie van PLM score in het document\n",
    "#  - a Language Model - done\n",
    "#  - Topical matching\n",
    "#  - Correlation of relevance matrix?\n",
    "# - Document Features\n",
    "#  - Document Length\n",
    "# - Query Features\n",
    "#  - Presence of given name in query\n",
    "#  - Query Length\n",
    "\n",
    "# Normalization:\n",
    "# We compute all the features and then scale to zero-mean and unit variance\n",
    "# Can be done with StandardScaler from scikit learn.\n",
    "# For D/Q features: read from .run files\n",
    "# Query level feature normalization is needed\n",
    "\n",
    "# MACHINE LEARNING\n",
    "\n",
    "# Computing Loss:\n",
    "# Read from ap_88_89/qrel_*\n",
    "\n",
    "from sklearn.preprocessing import normalize, StandardScaler, MaxAbsScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "def read_run(path_to_run, top1000, empty_queries):\n",
    "    '''\n",
    "    Read document scores from a .run file\n",
    "    \n",
    "    :param path_to_run: where to find the .run file\n",
    "    '''\n",
    "    \n",
    "    scores = defaultdict(dict)\n",
    "    \n",
    "    with open(path_to_run) as run_file:\n",
    "        for i, line in enumerate(run_file.readlines()):\n",
    "            query_id, _, ext_doc_id, document_rank, score, label = line.split()\n",
    "            \n",
    "            # Skip q/d pairs that don't share words\n",
    "            if score == '0' or score == '-inf':\n",
    "                continue\n",
    "            \n",
    "            # Only look at top1000 document for the query\n",
    "            if top1000 and not ext_doc_id in top_1000_per_test_query[query_id]:\n",
    "                continue\n",
    "                \n",
    "            scores[int(query_id)][ext2int[ext_doc_id]] = float(score)\n",
    "    \n",
    "    filter_queries = list(scores.keys()) if empty_queries else None\n",
    "    \n",
    "    return matrix_from_two_level_dict(scores, filter_top_1000=top1000, filter_queries=filter_queries)\n",
    "\n",
    "def unique_docs_top_1000(top_1000):\n",
    "    unique_top_docs = set()\n",
    "    for top in top_1000.values():\n",
    "        for doc in top:\n",
    "            unique_top_docs.add(ext2int[doc])\n",
    "    return unique_top_docs\n",
    "    \n",
    "def indices_of_all_top_1000(top_1000):\n",
    "    unique_top_docs = unique_docs_top_1000(top_1000)      \n",
    "    indices = np.array(sorted(list(unique_top_docs))) - 1\n",
    "    return indices\n",
    "    \n",
    "def build_relevance_matrix(path_to_relavance_labels, top1000, empty_queries, sparse = True):\n",
    "    '''\n",
    "    Constructs a sparse matrix where the relevant query/document pairs are 1's and the rest 0's\n",
    "    \n",
    "    :param path_to_relevance_labels: where to find the relevance file\n",
    "    '''\n",
    "    \n",
    "    relevance_labels_validation = defaultdict(dict)\n",
    "\n",
    "    # Read from relevance file\n",
    "    with open(path_to_relavance_labels) as valid_file:\n",
    "        for i, line in enumerate(valid_file.readlines()):\n",
    "            query_id, _, ext_doc_id, relevance = line.split()\n",
    "            \n",
    "            if top1000 and not ext_doc_id in top_1000_per_test_query[query_id]:\n",
    "                continue\n",
    "                \n",
    "            relevance_labels_validation[int(query_id)][ext2int[ext_doc_id]] = int(relevance)\n",
    "    \n",
    "    filter_queries = list(relevance_labels_validation.keys()) if empty_queries else None\n",
    "    \n",
    "    relevance_matrix = matrix_from_two_level_dict(relevance_labels_validation, \n",
    "                                                  make_sparse=sparse,\n",
    "                                                  filter_top_1000=top1000, \n",
    "                                                  filter_queries=filter_queries)\n",
    "\n",
    "    \n",
    "    return np.ravel(relevance_matrix)\n",
    "\n",
    "def matrix_from_two_level_dict(dictionary, make_sparse=False, filter_top_1000=False, filter_queries=None):\n",
    "    \n",
    "    matrix = np.zeros((max(dictionary.keys()) + 1, len(ext2int)))\n",
    "    \n",
    "    for key, sub_dict in dictionary.items():\n",
    "        for sub_key, value in sub_dict.items():\n",
    "            matrix[key, sub_key] = value\n",
    "    \n",
    "    if filter_top_1000:\n",
    "        doc_idxs = indices_of_all_top_1000(top_1000_per_test_query)\n",
    "        matrix = matrix[:, doc_idxs]\n",
    "        \n",
    "    if np.any(filter_queries):\n",
    "        q_idxs = np.array(sorted(filter_queries))\n",
    "        matrix = matrix[q_idxs, :]\n",
    "        \n",
    "    if make_sparse:\n",
    "        matrix = sparse.csr_matrix(matrix)\n",
    "        \n",
    "    print(\"Matrix size: \", matrix.shape)\n",
    "            \n",
    "    return matrix\n",
    "\n",
    "def normalize_negative_values(matrix):\n",
    "    real_probs = np.exp(matrix)\n",
    "#     return real_probs\n",
    "    return normalize(real_probs)\n",
    "\n",
    "def is_validation_run(file_name):\n",
    "    return '.run' in file_name and 'test' not in file_name and 'TF' not in file_name\n",
    "    \n",
    "def is_test_run(file_name):\n",
    "    raise NotImplementedError()\n",
    "\n",
    "def load_features(run_dir, top1000, empty_queries, add_document_features=False, make_sparse=True):\n",
    "    '''Build a matrix based on features for all documents and queries'''\n",
    "    \n",
    "    run_file_names = [\"{}/{}\".format(run_dir,file_name) for file_name in os.listdir(run_dir)]\n",
    "    \n",
    "    print(\"Reading data into matrices\")\n",
    "    features_per_pair = [read_run(file_name, top1000=top1000, empty_queries=empty_queries) for file_name in run_file_names]\n",
    "    \n",
    "    # Save dimensions\n",
    "    n_features = len(features_per_pair)\n",
    "    n_queries = features_per_pair[0].shape[0]\n",
    "    n_docs = features_per_pair[0].shape[1]\n",
    "\n",
    "    print(\"Ascending to 3rd dimension\")\n",
    "    # Combine query/doc matrices for each feature into 3D array\n",
    "    features = np.concatenate(features_per_pair, axis=0)\n",
    "    features = features.reshape(n_features, n_queries, n_docs)\n",
    "    \n",
    "    if np.any(add_document_features):\n",
    "        print(\"Adding document features...\")\n",
    "        doc_features = document_features(top_1000_per_test_query)\n",
    "        \n",
    "        if top1000:\n",
    "            doc_idxs = indices_of_all_top_1000(top_1000_per_test_query)\n",
    "            doc_features = doc_features[doc_idxs]\n",
    "        \n",
    "        assert n_docs == doc_features.shape[0], \"The returned document features are the wrong size. \\\n",
    "            Got [ {} {} ]\".format(n_docs, doc_features.shape[0])\n",
    "        \n",
    "        doc_features = np.tile(doc_features, n_queries).reshape(n_queries, n_docs)\n",
    "        \n",
    "        print(features.shape, np.expand_dims(doc_features, axis=0).shape)\n",
    "        \n",
    "        features = np.concatenate((features, np.expand_dims(doc_features, axis=0)), axis=0)\n",
    "    \n",
    "    print(\"Going through a wormhole\")\n",
    "    # Transform from (features, queries, documents) to (queries, documents, features)\n",
    "    # so that features per doc/query pair are aligned in a single vector\n",
    "    features = np.transpose(features, (1, 2, 0))\n",
    "    \n",
    "    if make_sparse:\n",
    "        print(\"Back to earth...\")\n",
    "        features = sparse.csr_matrix(np.vstack(features), dtype=np.float64)\n",
    "    \n",
    "    return features\n",
    "\n",
    "def document_features(top_1000):\n",
    "    \n",
    "    feature_values = np.zeros(len(ext2int))\n",
    "    \n",
    "    for doc_id in unique_docs_top_1000(top_1000):\n",
    "        # Document length\n",
    "        doc_length = document_lengths[doc_id]\n",
    "        feature_values[doc_id] = doc_length\n",
    "    \n",
    "    return feature_values\n",
    "\n",
    "def index_of_plm(top_1000):\n",
    "    \n",
    "    data = defaultdict(dict)\n",
    "    \n",
    "    for query_id in top_1000:\n",
    "        for doc_id in top_1000[query_id]:\n",
    "            index = PLM_score_old(tokenized_queries[query_id], \n",
    "                                                   ext2int[doc_id], \n",
    "                                                   gaussian_kernel, \n",
    "                                                   mu=500, \n",
    "                                                   return_argmax=True)\n",
    "            \n",
    "            data[query_id][doc_id] = index\n",
    "        \n",
    "        print(list(data[query_id].values())[::3])\n",
    "        \n",
    "    \n",
    "    return matrix_from_two_level_dict(data)\n",
    "\n",
    "def learn_ranking(features, relevance_labels, reg):\n",
    "    \n",
    "    assert features.shape[0] == relevance_labels.shape[0], \"Mismatch between shape of feature \\\n",
    "     n_queries/n_docs between features and labels: {} <-> {}\".format(features.shape[0], relevance_labels.shape[0])\n",
    "    \n",
    "\n",
    "    # TODO: Tune Hyper Parameters, for now use defaults\n",
    "    # C: regularization strength\n",
    "    # class_weight\n",
    "    model = LogisticRegression(penalty='l2', \n",
    "                               C=reg, \n",
    "                               solver='sag', \n",
    "                               max_iter=1000,\n",
    "                               fit_intercept=True)\n",
    "    \n",
    "    model.fit(features, relevance_labels)\n",
    "    \n",
    "    return model\n",
    "\n",
    "def compute_ratio(majority_share, y):\n",
    "    n_positive = np.sum(y).astype(np.int32)\n",
    "    n_negative = (majority_share * n_positive).astype(np.int32)\n",
    "    \n",
    "    return {0 : n_negative, 1: n_positive}\n",
    "\n",
    "def standardize_sparse_matrix(scaler, train, test=None):\n",
    "    '''\n",
    "    Center mean by casting back and forth to dense matrix. Mean centering\n",
    "    not possible on sparse matrix.\n",
    "    '''\n",
    "    \n",
    "    train=train.todense()\n",
    "    scaler.fit(train)\n",
    "    train=scaler.transform(train)\n",
    "    \n",
    "    print(train[:,0].mean(), train[:,4].mean())\n",
    "    print(train[:,0].std(), train[:,4].std())\n",
    "\n",
    "    test = test.todense()\n",
    "    test = scaler.transform(test)\n",
    "        \n",
    "    return scaler, sparse.csr_matrix(train), sparse.csr_matrix(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(282,) 0\n",
      "(335,) 0\n",
      "(254,) 253\n",
      "(412,) 411\n",
      "(106,) 0\n",
      "(151,) 150\n",
      "(393,) 392\n",
      "(595,) 594\n",
      "(257,) 0\n",
      "(44,) 0\n",
      "(383,) 0\n",
      "(151,) 150\n",
      "(361,) 360\n",
      "(131,) 0\n",
      "(164,) 163\n",
      "(389,) 0\n",
      "(218,) 217\n",
      "(541,) 0\n",
      "(351,) 350\n",
      "(133,) 132\n",
      "(199,) 198\n",
      "(217,) 216\n",
      "(310,) 0\n",
      "(162,) 0\n",
      "(175,) 174\n",
      "(638,) 637\n",
      "(99,) 0\n",
      "(220,) 219\n",
      "(210,) 209\n",
      "(176,) 0\n",
      "(98,) 97\n",
      "(445,) 444\n",
      "(142,) 141\n",
      "(228,) 227\n",
      "(575,) 0\n",
      "(234,) 233\n",
      "(197,) 0\n",
      "(318,) 317\n",
      "(193,) 0\n",
      "(158,) 157\n",
      "(322,) 321\n",
      "(519,) 518\n",
      "(383,) 382\n",
      "(203,) 202\n",
      "(153,) 152\n",
      "(250,) 249\n",
      "(276,) 275\n",
      "(169,) 168\n",
      "(424,) 423\n",
      "(191,) 190\n",
      "(247,) 246\n",
      "(312,) 311\n",
      "(109,) 108\n",
      "(430,) 0\n",
      "(256,) 255\n",
      "(164,) 163\n",
      "(878,) 877\n",
      "(560,) 559\n",
      "(177,) 176\n",
      "(374,) 373\n",
      "(261,) 260\n",
      "(494,) 493\n",
      "(226,) 225\n",
      "(288,) 287\n",
      "(830,) 0\n",
      "(789,) 0\n",
      "(125,) 124\n",
      "(782,) 781\n",
      "(244,) 243\n",
      "(358,) 0\n",
      "(83,) 0\n",
      "(490,) 489\n",
      "(182,) 0\n",
      "(521,) 0\n",
      "(241,) 240\n",
      "(313,) 312\n",
      "(154,) 0\n",
      "(455,) 454\n",
      "(755,) 754\n",
      "(115,) 114\n",
      "(352,) 351\n",
      "(289,) 288\n",
      "(106,) 105\n",
      "(302,) 301\n",
      "(411,) 0\n",
      "(798,) 797\n",
      "(396,) 395\n",
      "(406,) 405\n",
      "(421,) 420\n",
      "(1096,) 1095\n",
      "(185,) 0\n",
      "(366,) 365\n",
      "(191,) 0\n",
      "(641,) 640\n",
      "(160,) 159\n",
      "(207,) 206\n",
      "(166,) 0\n",
      "(147,) 0\n",
      "(225,) 224\n",
      "(167,) 166\n",
      "(86,) 0\n",
      "(453,) 0\n",
      "(311,) 0\n",
      "(264,) 263\n",
      "(168,) 0\n",
      "(102,) 0\n",
      "(326,) 0\n",
      "(531,) 0\n",
      "(685,) 0\n",
      "(476,) 475\n",
      "(351,) 350\n",
      "(286,) 285\n",
      "(307,) 306\n",
      "(117,) 0\n",
      "(289,) 0\n",
      "(328,) 0\n",
      "(873,) 0\n",
      "(355,) 354\n",
      "(434,) 0\n",
      "(575,) 0\n",
      "(226,) 225\n",
      "(130,) 129\n",
      "(321,) 0\n",
      "(293,) 292\n",
      "(238,) 237\n",
      "(725,) 0\n",
      "(728,) 0\n",
      "(1059,) 0\n",
      "(377,) 376\n",
      "(711,) 710\n",
      "(566,) 0\n",
      "(464,) 0\n",
      "(592,) 591\n",
      "(437,) 0\n",
      "(259,) 258\n",
      "(104,) 103\n",
      "(681,) 0\n",
      "(232,) 231\n",
      "(495,) 0\n",
      "(202,) 201\n",
      "(307,) 0\n",
      "(684,) 0\n",
      "(813,) 812\n",
      "(340,) 339\n",
      "(125,) 124\n",
      "(360,) 0\n",
      "(374,) 373\n",
      "(243,) 0\n",
      "(721,) 0\n",
      "(141,) 140\n",
      "(453,) 452\n",
      "(229,) 0\n",
      "(660,) 659\n",
      "(631,) 630\n",
      "(513,) 0\n",
      "(540,) 0\n",
      "(437,) 0\n",
      "(383,) 0\n",
      "(554,) 0\n",
      "(271,) 270\n",
      "(657,) 656\n",
      "(535,) 0\n",
      "(188,) 0\n",
      "(460,) 0\n",
      "(909,) 0\n",
      "(549,) 0\n",
      "(296,) 295\n",
      "(766,) 765\n",
      "(597,) 596\n",
      "(449,) 448\n",
      "(409,) 408\n",
      "(385,) 0\n",
      "(689,) 688\n",
      "(450,) 449\n",
      "(489,) 0\n",
      "(798,) 0\n",
      "(756,) 0\n",
      "(746,) 745\n",
      "(244,) 243\n",
      "(964,) 0\n",
      "(376,) 375\n",
      "(446,) 0\n",
      "(446,) 0\n",
      "(564,) 0\n",
      "(444,) 443\n",
      "(174,) 0\n",
      "(500,) 0\n",
      "(382,) 381\n",
      "(376,) 375\n",
      "(198,) 0\n",
      "(530,) 0\n",
      "(428,) 427\n",
      "(371,) 370\n",
      "(389,) 388\n",
      "(265,) 0\n",
      "(761,) 0\n",
      "(309,) 0\n",
      "(191,) 190\n",
      "(227,) 0\n",
      "(203,) 202\n",
      "(1000,) 999\n",
      "(643,) 0\n",
      "(320,) 0\n",
      "(581,) 580\n",
      "(433,) 432\n",
      "(205,) 0\n",
      "(254,) 253\n",
      "(494,) 493\n",
      "(236,) 235\n",
      "(329,) 328\n",
      "(882,) 0\n",
      "(380,) 379\n",
      "(169,) 0\n",
      "(250,) 0\n",
      "(745,) 0\n",
      "(855,) 854\n",
      "(516,) 515\n",
      "(793,) 0\n",
      "(326,) 325\n",
      "(560,) 0\n",
      "(549,) 548\n",
      "(558,) 557\n",
      "(350,) 349\n",
      "(406,) 405\n",
      "(322,) 0\n",
      "(413,) 412\n",
      "(590,) 589\n",
      "(278,) 277\n",
      "(340,) 339\n",
      "(474,) 0\n",
      "(538,) 0\n",
      "(735,) 734\n",
      "(475,) 474\n",
      "(189,) 0\n",
      "(617,) 616\n",
      "(616,) 615\n",
      "(351,) 350\n",
      "(629,) 628\n",
      "(659,) 658\n",
      "(310,) 0\n",
      "(339,) 0\n",
      "(361,) 0\n",
      "(411,) 410\n",
      "(325,) 324\n",
      "(617,) 616\n",
      "(617,) 616\n",
      "(441,) 0\n",
      "(573,) 0\n",
      "(629,) 0\n",
      "(266,) 265\n",
      "(320,) 0\n",
      "(742,) 741\n",
      "(347,) 0\n",
      "(728,) 727\n",
      "(646,) 0\n",
      "(438,) 0\n",
      "(318,) 317\n",
      "(707,) 706\n",
      "(483,) 0\n",
      "(1133,) 0\n",
      "(256,) 255\n",
      "(830,) 0\n",
      "(344,) 0\n",
      "(866,) 865\n",
      "(323,) 322\n",
      "(592,) 591\n",
      "(310,) 309\n",
      "(960,) 959\n",
      "(925,) 924\n",
      "(623,) 622\n",
      "(521,) 0\n",
      "(468,) 467\n",
      "(607,) 606\n",
      "(503,) 502\n",
      "(814,) 813\n",
      "(517,) 516\n",
      "(309,) 0\n",
      "(568,) 567\n",
      "(590,) 589\n",
      "(580,) 579\n",
      "(673,) 0\n",
      "(441,) 0\n",
      "(783,) 0\n",
      "(341,) 340\n",
      "(957,) 956\n",
      "(385,) 384\n",
      "(313,) 0\n",
      "(331,) 330\n",
      "(655,) 654\n",
      "(265,) 264\n",
      "(522,) 521\n",
      "(537,) 536\n",
      "(537,) 536\n",
      "(805,) 804\n",
      "(270,) 0\n",
      "(448,) 447\n",
      "(268,) 0\n",
      "(437,) 0\n",
      "(249,) 0\n",
      "(161,) 0\n",
      "(582,) 581\n",
      "(289,) 288\n",
      "(591,) 590\n",
      "(708,) 707\n",
      "(745,) 744\n",
      "(411,) 0\n",
      "(1181,) 1180\n",
      "(542,) 541\n",
      "(1021,) 0\n",
      "(420,) 419\n",
      "(378,) 377\n",
      "(338,) 337\n",
      "(562,) 561\n",
      "(766,) 765\n",
      "(600,) 599\n",
      "(665,) 0\n",
      "(599,) 598\n",
      "(668,) 667\n",
      "(584,) 583\n",
      "(547,) 546\n",
      "(688,) 0\n",
      "(765,) 764\n",
      "(317,) 316\n",
      "(485,) 0\n",
      "(294,) 293\n",
      "(345,) 0\n",
      "(712,) 711\n",
      "(741,) 740\n",
      "(745,) 744\n",
      "(306,) 0\n",
      "(303,) 0\n",
      "(651,) 650\n",
      "(869,) 868\n",
      "(152,) 0\n",
      "(651,) 650\n",
      "(418,) 0\n",
      "(142,) 0\n",
      "(671,) 670\n",
      "(386,) 385\n",
      "(576,) 575\n",
      "(576,) 575\n",
      "(269,) 268\n",
      "(189,) 188\n",
      "(476,) 0\n",
      "(594,) 593\n",
      "(844,) 843\n",
      "(793,) 792\n",
      "(524,) 523\n",
      "(794,) 793\n",
      "(578,) 577\n",
      "(265,) 264\n",
      "(625,) 624\n",
      "(544,) 0\n",
      "(466,) 465\n",
      "(536,) 535\n",
      "(197,) 196\n",
      "(424,) 423\n",
      "(685,) 684\n",
      "(926,) 0\n",
      "(254,) 0\n",
      "(407,) 0\n",
      "(340,) 0\n",
      "(434,) 433\n",
      "(249,) 248\n",
      "(556,) 555\n",
      "(538,) 537\n",
      "(572,) 0\n",
      "(506,) 505\n",
      "(513,) 512\n",
      "(220,) 219\n",
      "(524,) 0\n",
      "(882,) 881\n",
      "(178,) 177\n",
      "(497,) 0\n",
      "(603,) 602\n",
      "(278,) 0\n",
      "(747,) 746\n",
      "(487,) 486\n",
      "(767,) 766\n",
      "(817,) 816\n",
      "(529,) 528\n",
      "(609,) 0\n",
      "(421,) 0\n",
      "(516,) 515\n",
      "(446,) 0\n",
      "(985,) 984\n",
      "(524,) 523\n",
      "(406,) 405\n",
      "(565,) 0\n",
      "(425,) 424\n",
      "(423,) 0\n",
      "(738,) 737\n",
      "(756,) 755\n",
      "(132,) 131\n",
      "(183,) 0\n",
      "(657,) 656\n",
      "(661,) 660\n",
      "(1186,) 1185\n",
      "(812,) 811\n",
      "(179,) 178\n",
      "(1196,) 1195\n",
      "(861,) 860\n",
      "(518,) 517\n",
      "(381,) 0\n",
      "(548,) 547\n",
      "(523,) 522\n",
      "(177,) 0\n",
      "(225,) 0\n",
      "(877,) 876\n",
      "(103,) 0\n",
      "(570,) 569\n",
      "(545,) 544\n",
      "(444,) 443\n",
      "(523,) 522\n",
      "(561,) 560\n",
      "(590,) 0\n",
      "(571,) 570\n",
      "(160,) 0\n",
      "(557,) 556\n",
      "(312,) 0\n",
      "(521,) 0\n",
      "(702,) 701\n",
      "(889,) 0\n",
      "(268,) 0\n",
      "(397,) 0\n",
      "(295,) 294\n",
      "(883,) 882\n",
      "(339,) 338\n",
      "(434,) 433\n",
      "(305,) 304\n",
      "(285,) 0\n",
      "(302,) 0\n",
      "(475,) 0\n",
      "(247,) 0\n",
      "(570,) 0\n",
      "(896,) 895\n",
      "(559,) 0\n",
      "(555,) 554\n",
      "(378,) 0\n",
      "(1160,) 1159\n",
      "(181,) 0\n",
      "(662,) 661\n",
      "(551,) 0\n",
      "(325,) 0\n",
      "(175,) 0\n",
      "(252,) 0\n",
      "(573,) 572\n",
      "(845,) 0\n",
      "(391,) 0\n",
      "(491,) 490\n",
      "(345,) 344\n",
      "(956,) 0\n",
      "(797,) 0\n",
      "(561,) 0\n",
      "(548,) 547\n",
      "(305,) 0\n",
      "(131,) 130\n",
      "(763,) 0\n",
      "(623,) 622\n",
      "(639,) 638\n",
      "(763,) 0\n",
      "(344,) 343\n",
      "(684,) 683\n",
      "(474,) 473\n",
      "(941,) 940\n",
      "(523,) 0\n",
      "(320,) 0\n",
      "(187,) 186\n",
      "(154,) 153\n",
      "(421,) 420\n",
      "(159,) 0\n",
      "(416,) 415\n",
      "(919,) 918\n",
      "(481,) 480\n",
      "(862,) 861\n",
      "(445,) 0\n",
      "(785,) 0\n",
      "(477,) 0\n",
      "(1092,) 1091\n",
      "(388,) 0\n",
      "(738,) 0\n",
      "(487,) 0\n",
      "(389,) 388\n",
      "(560,) 0\n",
      "(481,) 480\n",
      "(982,) 981\n",
      "(637,) 636\n",
      "(377,) 0\n",
      "(247,) 246\n",
      "(523,) 522\n",
      "(506,) 505\n",
      "(247,) 0\n",
      "(278,) 0\n",
      "(377,) 0\n",
      "(836,) 835\n",
      "(828,) 827\n",
      "(705,) 704\n",
      "(705,) 0\n",
      "(498,) 0\n",
      "(628,) 627\n",
      "(752,) 0\n",
      "(752,) 0\n",
      "(657,) 656\n",
      "(1143,) 0\n",
      "(383,) 0\n",
      "(782,) 781\n",
      "(1114,) 1113\n",
      "(587,) 586\n",
      "(414,) 0\n",
      "(470,) 469\n",
      "(724,) 0\n",
      "(662,) 0\n",
      "(739,) 0\n",
      "(565,) 564\n",
      "(364,) 363\n",
      "(665,) 664\n",
      "(839,) 0\n",
      "(1157,) 0\n",
      "(534,) 0\n",
      "(281,) 0\n",
      "(842,) 841\n",
      "(879,) 878\n",
      "(455,) 0\n",
      "(682,) 681\n",
      "(768,) 0\n",
      "(529,) 0\n",
      "(690,) 0\n",
      "(551,) 0\n",
      "(877,) 876\n",
      "(553,) 0\n",
      "(783,) 0\n",
      "(433,) 0\n",
      "(771,) 0\n",
      "(406,) 0\n",
      "(468,) 467\n",
      "(466,) 465\n",
      "(287,) 0\n",
      "(406,) 405\n",
      "(799,) 0\n",
      "(463,) 0\n",
      "(1024,) 0\n",
      "(889,) 888\n",
      "(641,) 0\n",
      "(400,) 0\n",
      "(633,) 632\n",
      "(936,) 935\n",
      "(686,) 0\n",
      "(447,) 446\n",
      "(775,) 774\n",
      "(393,) 392\n",
      "(480,) 479\n",
      "(451,) 450\n",
      "(775,) 0\n",
      "(564,) 0\n",
      "(441,) 0\n",
      "(973,) 972\n",
      "(743,) 0\n",
      "(159,) 0\n",
      "(347,) 346\n",
      "(259,) 0\n",
      "(668,) 0\n",
      "(321,) 0\n",
      "(369,) 368\n",
      "(948,) 947\n",
      "(490,) 0\n",
      "(278,) 0\n",
      "(307,) 0\n",
      "(631,) 630\n",
      "(602,) 601\n",
      "(648,) 647\n",
      "(408,) 0\n",
      "(161,) 0\n",
      "(689,) 688\n",
      "(642,) 641\n",
      "(418,) 417\n",
      "(259,) 258\n",
      "(371,) 0\n",
      "(541,) 540\n",
      "(379,) 0\n",
      "(728,) 0\n",
      "(595,) 0\n",
      "(608,) 607\n",
      "(609,) 0\n",
      "(795,) 794\n",
      "(329,) 328\n",
      "(640,) 639\n",
      "(855,) 0\n",
      "(235,) 234\n",
      "(821,) 820\n",
      "(524,) 523\n",
      "(643,) 642\n",
      "(162,) 0\n",
      "(625,) 624\n",
      "(495,) 494\n",
      "(545,) 0\n",
      "(688,) 0\n",
      "(545,) 0\n",
      "(421,) 0\n",
      "(707,) 0\n",
      "(478,) 0\n",
      "(488,) 487\n",
      "(214,) 0\n",
      "(868,) 867\n",
      "(461,) 460\n",
      "(487,) 486\n",
      "(1307,) 1306\n",
      "(850,) 0\n",
      "(919,) 0\n",
      "(156,) 155\n",
      "(456,) 0\n",
      "(555,) 554\n",
      "(380,) 379\n",
      "(438,) 0\n",
      "(493,) 0\n",
      "(561,) 560\n",
      "(656,) 655\n",
      "(410,) 409\n",
      "(228,) 227\n",
      "(859,) 0\n",
      "(391,) 0\n",
      "(816,) 815\n",
      "(550,) 549\n",
      "(978,) 0\n",
      "(611,) 0\n",
      "(141,) 0\n",
      "(499,) 0\n",
      "(361,) 0\n",
      "(795,) 794\n",
      "(403,) 0\n",
      "(406,) 405\n",
      "(318,) 0\n",
      "(241,) 0\n",
      "(1222,) 1221\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-181-30289835e179>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_of_plm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_1000_per_test_query\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-174-acfda94dc424>\u001b[0m in \u001b[0;36mindex_of_plm\u001b[0;34m(top_1000)\u001b[0m\n\u001b[1;32m    197\u001b[0m                                                    \u001b[0mgaussian_kernel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                                                    \u001b[0mmu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                                                    return_argmax=True)\n\u001b[0m\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquery_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdoc_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-180-76f8a4186302>\u001b[0m in \u001b[0;36mPLM_score_old\u001b[0;34m(query_id_tokens, int_document_id, kernel_func, mu, sigma, return_argmax)\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0;31m# for positions where i is a query word\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmax_usefull_range\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_sided_kernel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdoc_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m                     \u001b[0mc_wi_prime_matrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mkernel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;31m# Go through all positions in the document again now all the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(index_of_plm(top_1000_per_test_query))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data into matrices\n",
      "Matrix size:  (120, 98548)\n",
      "Matrix size:  (120, 98548)\n",
      "Ascending to 3rd dimension\n",
      "Going through a wormhole\n",
      "Back to earth...\n",
      "Reading data into matrices\n",
      "Matrix size:  (120, 98548)\n",
      "Matrix size:  (120, 98548)\n",
      "Matrix size:  (120, 98548)\n",
      "Ascending to 3rd dimension\n",
      "Going through a wormhole\n",
      "Back to earth...\n",
      "Reading data into matrices\n",
      "Matrix size:  (120, 98548)\n",
      "Ascending to 3rd dimension\n",
      "Adding document features...\n",
      "(1, 120, 98548) (1, 120, 98548)\n",
      "Going through a wormhole\n",
      "Back to earth...\n",
      "Matrix size:  (120, 98548)\n",
      "\n",
      "Amount of relevant pairs: 3630.0\n",
      "Percentage of positive examples: 0.00030695701587\n",
      "Dataset of size: (11825760, 7)\n"
     ]
    }
   ],
   "source": [
    "# Read validation data\n",
    "\n",
    "split = 'test'\n",
    "\n",
    "vector_space_features = load_features('letor_data/{}/vector_space'.format(split), \n",
    "                                            top1000=True, empty_queries=True, \n",
    "                                            make_sparse=True)\n",
    "\n",
    "language_model_features = load_features('letor_data/{}/lang_model'.format(split), \n",
    "                                              top1000=True, empty_queries=True, \n",
    "                                              make_sparse=True)\n",
    "\n",
    "# We add the document features in with the last batch because this is most convenient in our implementation\n",
    "positional_model_features = load_features('letor_data/{}/positional'.format(split), \n",
    "                                                top1000=True, empty_queries=True, \n",
    "                                                make_sparse=True, add_document_features=True)\n",
    "\n",
    "# Concatenate raw features\n",
    "feature_matrix = sparse.hstack([vector_space_features, language_model_features, positional_model_features])\n",
    "\n",
    "\n",
    "del(vector_space_features)\n",
    "del(language_model_features)\n",
    "del(positional_model_features)\n",
    "\n",
    "relevance_labels = build_relevance_matrix('ap_88_89/qrel_{}'.format(split), top1000=True, empty_queries=True, sparse=False)\n",
    "\n",
    "print()\n",
    "print(\"Amount of relevant pairs:\", np.sum(relevance_labels))\n",
    "print(\"Percentage of positive examples:\", np.sum(relevance_labels) / len(relevance_labels))\n",
    "print(\"Dataset of size:\", feature_matrix.shape)\n",
    "\n",
    "positive_ratio = np.sum(relevance_labels) / len(relevance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating re-sampled dataset\n",
      "New frequencies: Counter({0.0: 36300, 1.0: 3630})\n",
      "Splitting data...\n",
      "4.71559792077e-17 -3.67015875909e-18\n",
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "print(\"Generating re-sampled dataset\")\n",
    "rus = RandomUnderSampler(random_state=0, ratio=compute_ratio(10, relevance_labels))\n",
    "X_resampled, y_resampled = rus.fit_sample(feature_matrix, relevance_labels)\n",
    "\n",
    "print(\"New frequencies:\", collections.Counter(y_resampled))\n",
    "\n",
    "print(\"Splitting data...\")\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(X_resampled, \n",
    "                                                                            y_resampled, \n",
    "                                                                            test_size=0.2)\n",
    "\n",
    "\n",
    "# Convert to dense representation for centering the mean\n",
    "# scaler is re-used later to standardise features for ranking\n",
    "scaler = StandardScaler()\n",
    "scaler, train_features, test_features = standardize_sparse_matrix(scaler, train_features, test_features)\n",
    "\n",
    "# Clear memory locations of original data matrices\n",
    "del(feature_matrix)\n",
    "del(relevance_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t-0.298340732993\n",
      "  (0, 1)\t-0.306298369463\n",
      "  (0, 2)\t0.266892430203\n",
      "  (0, 3)\t0.264996094427\n",
      "  (0, 4)\t0.0977166219152\n",
      "  (0, 5)\t0.0692830563855\n",
      "  (1, 0)\t-0.298340732993\n",
      "  (1, 1)\t-0.306298369463\n",
      "  (1, 2)\t0.266892430203\n",
      "  (1, 3)\t0.264996094427\n",
      "  (1, 4)\t0.0977166219152\n",
      "  (1, 5)\t0.0692830563855\n",
      "  (2, 0)\t-0.298340732993\n",
      "  (2, 1)\t-0.306298369463\n",
      "  (2, 2)\t0.266892430203\n",
      "  (2, 3)\t0.264996094427\n",
      "  (2, 4)\t0.0977166219152\n",
      "  (2, 5)\t0.0692830563855\n",
      "  (3, 0)\t-0.298340732993\n",
      "  (3, 1)\t-0.306298369463\n",
      "  (3, 2)\t0.266892430203\n",
      "  (3, 3)\t0.264996094427\n",
      "  (3, 4)\t0.0977166219152\n",
      "  (3, 5)\t0.0692830563855\n",
      "  (4, 0)\t3.12550183643\n",
      "  :\t:\n",
      "  (31939, 5)\t0.0692830563855\n",
      "  (31940, 0)\t-0.298340732993\n",
      "  (31940, 1)\t-0.306298369463\n",
      "  (31940, 2)\t0.266892430203\n",
      "  (31940, 3)\t0.264996094427\n",
      "  (31940, 4)\t0.0977166219152\n",
      "  (31940, 5)\t0.0692830563855\n",
      "  (31941, 0)\t-0.298340732993\n",
      "  (31941, 1)\t-0.306298369463\n",
      "  (31941, 2)\t0.266892430203\n",
      "  (31941, 3)\t0.264996094427\n",
      "  (31941, 4)\t0.0977166219152\n",
      "  (31941, 5)\t0.0692830563855\n",
      "  (31942, 0)\t-0.298340732993\n",
      "  (31942, 1)\t-0.306298369463\n",
      "  (31942, 2)\t0.266892430203\n",
      "  (31942, 3)\t0.264996094427\n",
      "  (31942, 4)\t0.0977166219152\n",
      "  (31942, 5)\t0.0692830563855\n",
      "  (31943, 0)\t-0.298340732993\n",
      "  (31943, 1)\t-0.306298369463\n",
      "  (31943, 2)\t0.266892430203\n",
      "  (31943, 3)\t0.264996094427\n",
      "  (31943, 4)\t0.0977166219152\n",
      "  (31943, 5)\t0.0692830563855\n"
     ]
    }
   ],
   "source": [
    "print(train_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with: 0.1\n",
      "\n",
      "--------\n",
      "\n",
      "CPU times: user 14 s, sys: 116 ms, total: 14.2 s\n",
      "Wall time: 14.3 s\n",
      "Precision: [ 0.99807083  0.9478738 ]\n",
      "Recall: [ 0.99478094  0.98014184]\n",
      "F-score: [ 0.99642317  0.9637378 ]\n",
      "Support: [7281  705]\n",
      "Mean Accuracy: 0.993488605059\n",
      "Weights [[-0.04893208  3.05878184 -0.42459014 -0.07921913 -0.03007039 -0.10100856]]\n",
      "[ 0.0031001  0.0031001  0.0031001 ...,  0.0031001  0.0031001  0.0031001]\n",
      "\n",
      "--------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for regularization_term in [1e-1, 1e-2, 1e-3]:\n",
    "    if regularization_term != 1e-1:\n",
    "        continue\n",
    "        \n",
    "    print(\"Training with: {}\".format(regularization_term))\n",
    "    print()\n",
    "    print('--------')\n",
    "    print()\n",
    "    %time learned_scoring_func = learn_ranking(train_features, train_labels, regularization_term)\n",
    "    \n",
    "    predicted_classes = learned_scoring_func.predict(test_features)\n",
    "    precision, recall, f_score, support = precision_recall_fscore_support(test_labels, predicted_classes)\n",
    "\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F-score:\", f_score)\n",
    "    print(\"Support:\", support)\n",
    "    \n",
    "    print(\"Mean Accuracy:\", learned_scoring_func.score(test_features, test_labels))\n",
    "    print(\"Weights\", learned_scoring_func.coef_)\n",
    "    \n",
    "    print(learned_scoring_func.predict_proba(test_features)[:, 1])\n",
    "    \n",
    "#     for i, feat in enumerate(test_features[::182, :]):\n",
    "#         if test_labels[i] or test_labels[i-1] or test_labels[i+1]:\n",
    "#             pred = learned_scoring_func.predict(feat)\n",
    "#             score = learned_scoring_func.predict_proba(feat)\n",
    "#             print('{}: predicted class {} for ground truth {} with score of {}'.format(i, pred, test_labels[i], score))\n",
    "#             print(learned_scoring_func.decision_function(feat))\n",
    "\n",
    "    print()\n",
    "    print('--------')\n",
    "    print()\n",
    "# print(\"Evaluating model:\")\n",
    "# print(learned_scoring_func.score(test_features[::200, :], test_labels[::200]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method performs exceptionally well on the balanced set as opposed to the imbalanced set. Now check of this generalizes to the unseen (and imbalanced) test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.999921872483\n"
     ]
    }
   ],
   "source": [
    "probabilities = learned_scoring_func.predict_proba(test_features[::20])\n",
    "print(probabilities[:, 1].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Re-rank top-1000 using the LETOR models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data into matrices\n",
      "Matrix size:  (193, 164597)\n",
      "Matrix size:  (193, 164597)\n",
      "Ascending to 3rd dimension\n",
      "Going through a wormhole\n",
      "Reading data into matrices\n",
      "Matrix size:  (193, 164597)\n",
      "Matrix size:  (193, 164597)\n",
      "Matrix size:  (193, 164597)\n",
      "Ascending to 3rd dimension\n",
      "Going through a wormhole\n",
      "Reading data into matrices\n",
      "Matrix size:  (193, 164597)\n",
      "Ascending to 3rd dimension\n",
      "Going through a wormhole\n",
      "Standardizing data...\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Now we need complete matrices so coordinates are aligned with topic/document indices\n",
    "'''\n",
    "\n",
    "split = 'validation'\n",
    "prune_docs = False\n",
    "prune_queries = False\n",
    "\n",
    "# Read validation data\n",
    "vector_space_features = load_features('letor_data/{}/vector_space'.format(split), \n",
    "                                            top1000=prune_docs, empty_queries=prune_queries, \n",
    "                                            make_sparse=False)\n",
    "\n",
    "language_model_features = load_features('letor_data/{}/lang_model'.format(split), \n",
    "                                              top1000=prune_docs, empty_queries=prune_queries,\n",
    "                                              make_sparse=False)\n",
    "\n",
    "positional_model_features = load_features('letor_data/{}/positional'.format(split), \n",
    "                                                top1000=prune_docs, empty_queries=prune_queries,\n",
    "                                                make_sparse=False)\n",
    "\n",
    "# Concatenate raw features\n",
    "full_feature_matrix = np.concatenate([vector_space_features, language_model_features, positional_model_features],\n",
    "                                     axis=2)\n",
    "\n",
    "print(\"Standardizing data...\")\n",
    "\n",
    "n_queries, n_docs, n_feats = full_feature_matrix.shape\n",
    "\n",
    "full_feature_matrix = scaler.transform(np.vstack(full_feature_matrix)).reshape(n_queries, n_docs, n_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_letor_ranking(model_name, run_type, full_feature_matrix, letor_model):\n",
    "    \n",
    "    run_out_path = 'letor_run/{}_{}.run'.format(model_name, run_type)\n",
    "    if os.path.exists(run_out_path):\n",
    "        print(\"File already exists; exiting...\")\n",
    "        return\n",
    "    \n",
    "    data = defaultdict(list)\n",
    "    \n",
    "    if run_type == 'validation':\n",
    "        subset = validation_queries_ids\n",
    "    elif run_typ == 'test':\n",
    "        subset = test_queries_ids\n",
    "    else:\n",
    "        print('Invalid run type. Should be either \"valiation\" or \"test\".')\n",
    "        return\n",
    "    \n",
    "    print(\"Calculating scores...\")\n",
    "    \n",
    "    for query_id, feature_matrix in enumerate(full_feature_matrix):\n",
    "        \n",
    "        if str(query_id) in subset:\n",
    "            sparse_feat = sparse.csr_matrix(feature_matrix)\n",
    "            predicted_probabilities = letor_model.predict_proba(sparse_feat)\n",
    "            for doc_id, score in enumerate(predicted_probabilities):\n",
    "                data[str(query_id)].append((score[1], int2ext[doc_id + 1]))\n",
    "    \n",
    "    print(\"Writing to file...\")\n",
    "    \n",
    "    with open(run_out_path, 'w') as f_out:\n",
    "        write_run(\n",
    "            model_name=model_name,\n",
    "            data=data,\n",
    "            out_f=f_out,\n",
    "            max_objects_per_query=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating scores...\n",
      "Writing to file...\n"
     ]
    }
   ],
   "source": [
    "run_letor_ranking('pointwise', split, full_feature_matrix, learned_scoring_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Task 4: Write a report [15 points; instant FAIL if not provided] ###\n",
    "\n",
    "The report should be a PDF file created using the [sigconf ACM template](https://www.acm.org/publications/proceedings-template) and will determine a significant part of your grade.\n",
    "\n",
    "   * It should explain what you have implemented, motivate your experiments and detail what you expect to learn from them. **[10 points]**\n",
    "   * Lastly, provide a convincing analysis of your results and conclude the report accordingly. **[10 points]**\n",
    "      * Do all methods perform similarly on all queries? Why?\n",
    "      * Is there a single retrieval model that outperforms all other retrieval models (i.e., silver bullet)?\n",
    "      * ...\n",
    "\n",
    "**Hand in the report and your self-contained implementation source files.** Only send us the files that matter, organized in a well-documented zip/tgz file with clear instructions on how to reproduce your results. That is, we want to be able to regenerate all your results with minimal effort. You can assume that the index and ground-truth information is present in the same file structure as the one we have provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "ml1labs",
   "language": "python",
   "name": "ml1labs"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
